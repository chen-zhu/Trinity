{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaNeo for Max Length of 3 (depth of 4)\n",
    "\n",
    "```\n",
    "tensorboard --logdir runs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG_VAR = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import fcntl\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.interpreter import Interpreter, PostOrderInterpreter, GeneralError, InterpreterError\n",
    "from tyrell.enumerator import Enumerator, SmtEnumerator, RandomEnumerator, DesignatedEnumerator, RandomEnumeratorS, ExhaustiveEnumerator\n",
    "from tyrell.decider import Example, ExampleConstraintPruningDecider, ExampleDecider, TestDecider\n",
    "from tyrell.synthesizer import Synthesizer\n",
    "from tyrell.logger import get_logger\n",
    "from sexpdata import Symbol\n",
    "from tyrell import dsl as D\n",
    "from typing import Callable, NamedTuple, List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: False\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "import dill as pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morpheus Version\n",
    "from utils_morpheus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListModule(object):\n",
    "    def __init__(self, module, prefix, *args):\n",
    "        self.module = module\n",
    "        self.prefix = prefix\n",
    "        self.num_module = 0\n",
    "        for new_module in args:\n",
    "            self.append(new_module)\n",
    "    \n",
    "    def append(self, new_module):\n",
    "        if not isinstance(new_module, nn.Module):\n",
    "            raise ValueError('Not a Module')\n",
    "        else:\n",
    "            self.module.add_module(self.prefix + str(self.num_module), new_module)\n",
    "            self.num_module += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.num_module\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i<0 or i>=self.num_module:\n",
    "            raise IndexError('Out of bound')\n",
    "        return getattr(self.module, self.prefix+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(AlphaNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.lstm = nn.LSTMCell(\n",
    "            input_size = self.config[\"lstm_input_size\"],\n",
    "            hidden_size = self.config[\"fcs\"][0],\n",
    "            bias = True,\n",
    "        )\n",
    "        \n",
    "        self.fcs = ListModule(self, \"fc_\")\n",
    "        for i in range(1,len(self.config[\"fcs\"])):\n",
    "            self.fcs.append(\n",
    "                nn.Linear(self.config[\"fcs\"][i-1], self.config[\"fcs\"][i])\n",
    "            )\n",
    "    \n",
    "    '''\n",
    "    single batch behavior, no batch dim expected\n",
    "    '''\n",
    "    def forward(self, p1, p2, hc=None):\n",
    "        # p1, p2: (1, ?)\n",
    "        # hc: previous hidden state, if None, start a new sequence\n",
    "        \n",
    "        # [(1, ?), (1, ?), ...] -> (1, ?*k), flatten\n",
    "        d_known = torch.cat([p1,p2], dim=1)\n",
    "        \n",
    "        if hc is None:\n",
    "            hc = self.init_hidden()\n",
    "        \n",
    "        h_t, c_t = self.lstm(d_known, hc)\n",
    "        \n",
    "        tmp1 = h_t\n",
    "        for i in range(len(self.fcs)-1):\n",
    "            tmp1 = F.relu(self.fcs[i](tmp1))\n",
    "        \n",
    "        # (1, #production_rules)\n",
    "        tmp1 = F.log_softmax(self.fcs[len(self.fcs)-1](tmp1), dim=1)\n",
    "        \n",
    "        # hidden states can be reused\n",
    "        return tmp1, (h_t,c_t)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        if use_cuda:\n",
    "            return (torch.zeros(1,self.config[\"fcs\"][0]).cuda(),\n",
    "                    torch.zeros(1,self.config[\"fcs\"][0]).cuda())\n",
    "        else:\n",
    "            return (torch.zeros(1,self.config[\"fcs\"][0]),\n",
    "                    torch.zeros(1,self.config[\"fcs\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramSpaceChainOneNB(object):\n",
    "    # NOTICE:\n",
    "    # Due to the nature of rpy2, never deep copy an interpreter\n",
    "    # Interpreter is always shared\n",
    "    def __init__(self, p_spec, p_interpreter, p_eq, p_input, p_output):\n",
    "        self.spec = p_spec\n",
    "        self.builder = D.Builder(self.spec)\n",
    "        self.interpreter = p_interpreter\n",
    "        self.eq = p_eq\n",
    "        self.input = p_input\n",
    "        self.output = p_output\n",
    "        \n",
    "        self.outv_list = [] # list of Example.output: [output1, output2, ....]\n",
    "        self.prog_list = [] # list of Nodes\n",
    "        self.sexp_list = [] # list of sexps: [Symbol(...),...]\n",
    "        \n",
    "        self.PARAM_NODE = self.builder._from_sexp([Symbol('@param'), 0])\n",
    "        \n",
    "        # generate shells (of depth 1)\n",
    "        tmp_enumerator = ExhaustiveEnumerator(m_spec, max_depth=2)\n",
    "        self.shell_list = [] # list of shells (prog/Nodes)\n",
    "        while True:\n",
    "            tmp_shell = tmp_enumerator.next()\n",
    "            if tmp_shell is None:\n",
    "                break\n",
    "            \n",
    "            if len(tmp_shell.children)>0:\n",
    "                # should have at least one child\n",
    "                self.shell_list.append(tmp_shell)\n",
    "        # NOTICE: str(prog) is NOT sexp\n",
    "        self.str_shell_list = [str(p) for p in self.shell_list]\n",
    "        self.str_shell_dict = {\n",
    "            self.str_shell_list[i]:i \n",
    "            for i in range(len(self.str_shell_list))\n",
    "        }\n",
    "        \n",
    "    '''\n",
    "    convert the prog_list to a full program\n",
    "    (chain program is assumed)\n",
    "    '''\n",
    "    def get_full_prog(self, prog_list):\n",
    "        prog_list = copy.deepcopy(prog_list)\n",
    "        pnode = prog_list[0]\n",
    "        for i in range(1,len(prog_list)):\n",
    "            d_prog = prog_list[i]\n",
    "            for j in range(len(d_prog.children)):\n",
    "                if d_prog.children[j].is_param():\n",
    "                    # replace with pnode\n",
    "                    d_prog.children[j] = pnode\n",
    "                    pnode = d_prog\n",
    "                    continue\n",
    "        return pnode\n",
    "    \n",
    "    '''\n",
    "    convert a full program to prog_list\n",
    "    (chain program is assumed)\n",
    "    '''\n",
    "    def get_prog_list(self, full_prog):\n",
    "        def dfs_traverse(dnode):\n",
    "            # convert to sexp to avoid pointers\n",
    "            pl = []\n",
    "            for i in range(len(dnode.children)):\n",
    "                cnode = dnode.children[i]\n",
    "                if cnode.is_apply():\n",
    "                    pl += dfs_traverse(cnode)\n",
    "                    # change the ApplyNode to ParamNode and for a prog again\n",
    "                    dnode.children[i] = self.PARAM_NODE\n",
    "                    break\n",
    "            pl.append(dnode.to_sexp())\n",
    "            return pl\n",
    "        full_prog = copy.deepcopy(full_prog)\n",
    "        d_sexp_list = dfs_traverse(full_prog)\n",
    "        d_prog_list = [self.builder._from_sexp(p) for p in d_sexp_list]\n",
    "        return d_prog_list\n",
    "        \n",
    "    '''\n",
    "    compare the current output with the designated output\n",
    "    calling the eq function\n",
    "    '''\n",
    "    def out_eq(self):\n",
    "        if len(self.outv_list)==0:\n",
    "            return False\n",
    "        return self.eq(self.output, self.outv_list[-1][0]) # access 0 since it's in input format\n",
    "    \n",
    "    '''\n",
    "    return the last output (aka. the current input)\n",
    "    '''\n",
    "    def get_frontier(self):\n",
    "        if len(self.outv_list)==0:\n",
    "            return self.input\n",
    "        else:\n",
    "            return self.outv_list[-1]\n",
    "        \n",
    "    '''\n",
    "    add an sexp, execute and generate intermediate outputs\n",
    "    if succeeded return True, otherwise return False\n",
    "    '''\n",
    "    def add_sexp(self, p_sexp):\n",
    "        assert len(self.outv_list)==\\\n",
    "               len(self.prog_list)==\\\n",
    "               len(self.sexp_list)\n",
    "        \n",
    "        tmp_input = self.get_frontier()\n",
    "        tmp_prog = self.builder._from_sexp(p_sexp)\n",
    "        \n",
    "        try:\n",
    "            tmp_outv = self.interpreter.eval(tmp_prog,tmp_input)\n",
    "        except InterpreterError as e:\n",
    "            # failed to add sexp\n",
    "            return False\n",
    "        \n",
    "        # succeed\n",
    "        self.prog_list.append(tmp_prog)\n",
    "        self.sexp_list.append(p_sexp)\n",
    "        # NOTICE: wrap output in [] to be in the input format\n",
    "        self.outv_list.append([tmp_outv])\n",
    "        return True\n",
    "    \n",
    "    '''\n",
    "    make a copy of the current instance, with shared interpreter\n",
    "    '''\n",
    "    def make_copy(self):\n",
    "        new_ps = ProgramSpaceChainOneNB(\n",
    "            self.spec,\n",
    "            self.interpreter,\n",
    "            self.eq,\n",
    "            self.input,\n",
    "            self.output,\n",
    "        )\n",
    "        new_ps.outv_list = copy.deepcopy(self.outv_list)\n",
    "        new_ps.prog_list = copy.deepcopy(self.prog_list)\n",
    "        new_ps.sexp_list = copy.deepcopy(self.sexp_list)\n",
    "        new_ps.shell_list = copy.deepcopy(self.shell_list)\n",
    "        new_ps.str_shell_list = copy.deepcopy(self.str_shell_list)\n",
    "        new_ps.str_shell_dict = copy.deepcopy(self.str_shell_dict)\n",
    "        return new_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlphaNeoTrainer(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer):\n",
    "    global DBG_VAR\n",
    "    reward_list = []\n",
    "    n_batch = 32\n",
    "    batch_loss = 0.\n",
    "    c_nth = 0\n",
    "    \n",
    "    total_ac = {1:0,2:0,3:0}\n",
    "    total_sp = {1:0,2:0,3:0}\n",
    "    # one program each step\n",
    "    for d_step in range(p_config[\"n_steps\"]):\n",
    "        p_model.train()\n",
    "        \n",
    "        p_input = p_interpreter.random_table()\n",
    "        while True:\n",
    "            p_prog, p_example = p_generator.generate(\n",
    "                max_depth=p_config[\"max_depth\"],\n",
    "                example=Example(input=[p_input], output=None),\n",
    "                probs=(1,5),\n",
    "            )\n",
    "            # make sure at least one function call\n",
    "            if p_prog.is_apply():\n",
    "                break\n",
    "                \n",
    "        # construct the full program\n",
    "        ps_full = ProgramSpaceChainOneNB(\n",
    "            p_spec, p_interpreter, eq_r, p_example.input, p_example.output,\n",
    "        )\n",
    "        p_prog_list = ps_full.get_prog_list(p_prog)\n",
    "        for p in p_prog_list:\n",
    "            ps_full.add_sexp(p.to_sexp())\n",
    "        total_sp[len(ps_full.prog_list)] += 1\n",
    "        # start from the first state\n",
    "        ps_current = ProgramSpaceChainOneNB(\n",
    "            p_spec, p_interpreter, eq_r, p_example.input, p_example.output,\n",
    "        )\n",
    "        d_reward = None\n",
    "        selected_edges = []\n",
    "        \n",
    "        # if true, the problem turns into supervised problem\n",
    "        if random.random()<=p_config[\"hint_rate\"](d_step,len(ps_full.prog_list)):\n",
    "            need_hints = True\n",
    "        else:\n",
    "            need_hints = False\n",
    "\n",
    "        # roll till the ending condition\n",
    "        hc_t = None\n",
    "        while True:\n",
    "            outv_current = ps_current.get_frontier()\n",
    "            # generate dense rep for known nodes\n",
    "            d_vertex = morpheus_perspective1(outv_current[0])\n",
    "            # generate dense rep for target\n",
    "            d_target = morpheus_perspective1(ps_current.output)\n",
    "\n",
    "            if use_cuda:\n",
    "                td_vertex = Variable(torch.FloatTensor( [d_vertex] )).cuda()\n",
    "                td_target = Variable(torch.FloatTensor( [d_target] )).cuda()\n",
    "            else:\n",
    "                td_vertex = Variable(torch.FloatTensor( [d_vertex] ))\n",
    "                td_target = Variable(torch.FloatTensor( [d_target] ))\n",
    "                                     \n",
    "            # (1, LIST_PAD_LENGTH+#production_rules)\n",
    "            td_output, hc_t = p_model(td_vertex, td_target, hc_t)\n",
    "            cnd_list = ps_full.shell_list\n",
    "\n",
    "            DBG_VAR = [ps_full, ps_current]\n",
    "            if need_hints:\n",
    "                # just assign the correct solution\n",
    "                selected_id = ps_full.str_shell_dict[\n",
    "                    str(ps_full.prog_list[len(ps_current.prog_list)])\n",
    "                ]\n",
    "            else:\n",
    "                if random.random()<=p_config[\"exploration_rate\"](d_step):\n",
    "                    # exploration\n",
    "                    selected_id = random.choice(range(len(cnd_list)))\n",
    "                else:\n",
    "                    # exploitation\n",
    "                    selected_id = torch.multinomial(td_output.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "            # keep track of selected edges\n",
    "            selected_edges.append(td_output[0, selected_id])\n",
    "            # add selected edges and fill\n",
    "            ret = ps_current.add_sexp(ps_current.shell_list[selected_id].to_sexp())\n",
    "            \n",
    "            if ret==False:\n",
    "                # failed\n",
    "                d_reward = 0.\n",
    "                hc_t = None # cut off sequence\n",
    "                break\n",
    "            else:\n",
    "                # succeeded\n",
    "                if ps_current.out_eq():\n",
    "                    # solved in depth less than or equal to max_depth\n",
    "                    d_reward = 1.\n",
    "                    total_ac[len(ps_current.prog_list)] += 1\n",
    "                    hc_t = None # cut off sequence\n",
    "                    break\n",
    "                # NOTICE: Trinity depth is # of layers of nodes, AlphaNeo depth is # of edges (height)\n",
    "                elif len(ps_current.prog_list)>=p_config[\"max_depth\"]-1:\n",
    "                    d_reward = 0.\n",
    "                    hc_t = None # cut off sequence\n",
    "                    break\n",
    "\n",
    "        # finally compute the loss\n",
    "        d_loss = 0.\n",
    "        ns = len(selected_edges)\n",
    "        for i in range(ns):\n",
    "            d_decay = p_config[\"gamma\"]**(ns-1-i)\n",
    "            # should negate the log probabilities\n",
    "            d_loss += d_decay*d_reward*(-selected_edges[i])\n",
    "\n",
    "        reward_list.append(d_reward)\n",
    "        batch_loss += d_loss\n",
    "\n",
    "        print(\"\\r# STEP{}, size:c{}/f{}, reward:{:.4f}, avg.reward:{:.4f}, ac/sp: 1->{}/{}, 2->{}/{}, 3->{}/{}\".format(\n",
    "            d_step,\n",
    "            len(ps_current.prog_list), len(ps_full.prog_list), d_reward, sum(reward_list)/len(reward_list),\n",
    "            total_ac[1], total_sp[1], total_ac[2], total_sp[2], total_ac[3], total_sp[3],\n",
    "        ), end=\"\")\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\n",
    "                'avg.reward/step',\n",
    "                sum(reward_list)/len(reward_list),\n",
    "                d_step,\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                'reward/step',\n",
    "                d_reward,\n",
    "                d_step,\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                'sol.length/step',\n",
    "                ns,\n",
    "                d_step,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        c_nth += 1\n",
    "        if c_nth%n_batch==0:\n",
    "            c_nth = 0\n",
    "            # perform gradient in every batch\n",
    "            batch_loss.backward()\n",
    "            p_optim.step()\n",
    "            p_optim.zero_grad()\n",
    "            batch_loss = 0.\n",
    "            \n",
    "        if d_step%10000==0:\n",
    "            torch.save(p_model.state_dict(), \"./saved_models/AlphaNeo_Morpheus_n3.pt\".format(d_step))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/mChainOneNB.tyrell')\n",
    "m_eq = eq_r\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    "    sfn=m_interpreter.sanity_check,\n",
    ")\n",
    "m_ps = ProgramSpaceChainOneNB(\n",
    "    m_spec, m_interpreter, m_eq, None, None,\n",
    ")\n",
    "# m_config = {\n",
    "#     'n_steps': 1000000,\n",
    "#     'gamma': 0.618,\n",
    "#     'exploration_rate': lambda x:0.9-0.8*(min(1, x/10000)),\n",
    "#     'hint_rate': lambda x,n:{1:1,2:0.5,3:0.8}[n]*(1-(min(0.7, x/10000))),\n",
    "#     'max_depth': 4,\n",
    "#     'gen1_length': 27,\n",
    "# }\n",
    "m_config = {\n",
    "    'n_steps': 1000000,\n",
    "    'gamma': 0.618,\n",
    "    'exploration_rate': lambda x:0.9-0.8*(min(1, x/10000)),\n",
    "    'hint_rate': lambda x,n:{1:0.8,2:0.8,3:0.8}[n]*(1-(min(0.7, x/10000))),\n",
    "    'max_depth': 4,\n",
    "    'gen1_length': 27,\n",
    "}\n",
    "m_config['lstm_input_size'] = 2*m_config[\"gen1_length\"]\n",
    "m_config[\"fcs\"] = [\n",
    "    128,\n",
    "    len(m_ps.shell_list),\n",
    "]\n",
    "\n",
    "alpha_neo = AlphaNeo(p_config=m_config)\n",
    "optimizer = torch.optim.Adam(list(alpha_neo.parameters()))\n",
    "writer = SummaryWriter(\"runs/AlphaNeo_Morpheus_n3\")\n",
    "# writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_ps.shell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# STEP145, size:c1/f3, reward:1.0000, avg.reward:0.8493, ac: 1->38/37, 2->11/6, 3->75/103"
     ]
    }
   ],
   "source": [
    "AlphaNeoTrainer(m_config, m_spec, m_interpreter, m_generator, alpha_neo, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG_VAR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG_VAR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG_VAR[1].out_eq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG_VAR[0].out_eq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(robjects.r(DBG_VAR[0].output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(robjects.r(DBG_VAR[0].outv_list[-1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_obj = numpy.asarray(robjects.r(DBG_VAR[0].outv_list[-1][0])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DBG_VAR[0].prog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DBG_VAR[1].prog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(DBG_VAR[0].prog_list[len(DBG_VAR[1].prog_list)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
