{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeqNeo\n",
    "- Stage: Cambrian\n",
    "- Version: Pomoria\n",
    "\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(SeqNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.fn_embedding = nn.Embedding(\n",
    "            self.config[\"fn_vocab_size\"],\n",
    "            self.config[\"fn_dim\"],\n",
    "            padding_idx=0,\n",
    "        )\n",
    "        \n",
    "        self.encoder1 = nn.Linear(\n",
    "            self.config[\"encoder\"][\"input_dim\"],\n",
    "            2048,\n",
    "        )\n",
    "        self.encoder2 = nn.Linear(\n",
    "            2048,\n",
    "            self.config[\"encoder\"][\"output_dim\"],\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.GRUCell(\n",
    "            self.config[\"decoder\"][\"input_dim\"],\n",
    "            self.config[\"decoder\"][\"hidden_dim\"],\n",
    "            bias=True,\n",
    "        )\n",
    "        self.classifier = nn.Linear(\n",
    "            self.config[\"decoder\"][\"hidden_dim\"],\n",
    "            self.config[\"decoder\"][\"output_dim\"],\n",
    "        )\n",
    "        \n",
    "    def decode(self, pin_exp, pout_exp, p_hidden, pfn_context):\n",
    "        tmp_exp = self.encode(pin_exp, pout_exp) # (B=1, encoder_output_dim)\n",
    "        tmp_fn = self.fn_embedding(pfn_context) # (B=1, fn_dim)\n",
    "        tmp_input = torch.cat([tmp_exp,tmp_fn],dim=1)\n",
    "        \n",
    "        if p_hidden is None:\n",
    "            # very first\n",
    "            tmp_hidden = self.decoder(tmp_input)\n",
    "        else:\n",
    "            # not the very first\n",
    "            tmp_hidden = self.decoder(tmp_input, p_hidden)\n",
    "        # (B=1, decoder_hidden_dim)\n",
    "        \n",
    "        tmp_output = torch.log_softmax(\n",
    "            self.classifier(tmp_hidden),\n",
    "            dim=1\n",
    "        ) # (B=1, decoder_output_dim)\n",
    "        \n",
    "        # first hidden, then output\n",
    "        return (tmp_hidden, tmp_output)\n",
    "        \n",
    "        \n",
    "    def encode(self, pin_exp, pout_exp):\n",
    "        # pin_exp/pout_exp: (B=1, abs_dim)\n",
    "        tmp_exp = torch.cat([pin_exp,pout_exp],dim=1) # (B=1, encoder_input_dim=abs_dim*2)\n",
    "        tmp_out1 = F.relu(self.encoder1(tmp_exp))\n",
    "        tmp_out2 = F.relu(self.encoder2(tmp_out1))\n",
    "        return tmp_out2 # (B=1, encoder_output_dim)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))\n",
    "\n",
    "def SeqTrain(p_config, p_sourceps, p_model, p_dataset, p_optim):\n",
    "    print(\"# Start SeqTrain...\")\n",
    "    \n",
    "    for d_epoch in range(p_config[\"train\"][\"n_epoch\"]):\n",
    "        epoch_loss_list = []\n",
    "        for d_episode in range(p_config[\"train\"][\"n_episode\"]):\n",
    "            print(\"\\r# EP:{}/{}, loss:{:.2f}\".format(\n",
    "                d_epoch, d_episode,\n",
    "                sum(epoch_loss_list)/len(epoch_loss_list) if len(epoch_loss_list)>0 else -1,\n",
    "            ),end=\"\")\n",
    "            p_model.train()\n",
    "            \n",
    "            if isinstance(p_dataset,list):\n",
    "                # ====== option 1: sample from dataset ====== #\n",
    "                eid = random.choice(range(len(p_dataset)))\n",
    "                data_prog, data_str_example = p_dataset[eid]\n",
    "                data_example = Example(\n",
    "                    input=[p_sourceps.interpreter.load_data_into_var(p) for p in data_str_example.input],\n",
    "                    output=p_sourceps.interpreter.load_data_into_var(data_str_example.output),\n",
    "                )\n",
    "                ps_solution = ProgramSpace(\n",
    "                    p_sourceps.spec, p_sourceps.interpreter, data_example.input, data_example.output,\n",
    "                )\n",
    "                ps_solution.init_by_prog(data_prog)\n",
    "            else:\n",
    "                # ====== option 2: sample from generator ====== #\n",
    "                ps_solution = p_dataset.get_new_chain_program(\n",
    "                    p_config[\"train\"][\"n_size\"] + 1 # depth=size+1\n",
    "                )\n",
    "\n",
    "            # solution self-check\n",
    "            if ps_solution.check_eq() is None:\n",
    "                continue\n",
    "                print(\"ERROR, SOLUTION NOT CONSISTENT!\")\n",
    "\n",
    "            selected_neurons = []\n",
    "\n",
    "            # initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_sourceps.spec, p_sourceps.interpreter, ps_solution.inputs, ps_solution.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "\n",
    "            hidden_current = None # hidden state, initialized to None\n",
    "            fn_context = 0\n",
    "            for d_step in range(len(ps_solution.shells)):\n",
    "\n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                id_current = ps_current.get_strict_frontiers()[0]\n",
    "                var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "                var_output = ps_current.output\n",
    "\n",
    "                map_current = p_sourceps.interpreter.camb_get_ventogyrus(var_current)\n",
    "                map_output = p_sourceps.interpreter.camb_get_ventogyrus(var_output)\n",
    "\n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                current_shell_list = [None] + current_shell_list # None for <SOS> in nn embedding\n",
    "\n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float)).cuda()\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float)).cuda()\n",
    "                    td_context = Variable(torch.tensor([fn_context],dtype=torch.long)).cuda()\n",
    "                else:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float))\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float))\n",
    "                    td_context = Variable(torch.tensor([fn_context],dtype=torch.long))\n",
    "\n",
    "                # (B=1, fn_vocab_size)\n",
    "                hidden_current, td_pred = p_model.decode(td_current, td_output, hidden_current, td_context)\n",
    "                # supervised, assign selection directly\n",
    "                tmp_id = current_shell_list.index(ps_solution.shells[d_step])\n",
    "                fn_context = tmp_id\n",
    "\n",
    "                # update ps_current\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if not update_status:\n",
    "                    # something wrong\n",
    "                    raise Exception(\"Can't even update PS under supervision?\")\n",
    "                \n",
    "                selected_neurons.append(td_pred[0,tmp_id])\n",
    "\n",
    "            # <END_FOR_STEP>\n",
    "            if ps_current.check_eq() is None:\n",
    "                # something wrong, should've been solved under supervision\n",
    "                raise Exception(\"Can't even solve under supervision?\")\n",
    "\n",
    "            episode_loss_list = []\n",
    "            for i in range(len(selected_neurons)):\n",
    "                episode_loss_list.append(\n",
    "                    (+1.0)*(-selected_neurons[i])\n",
    "                )\n",
    "            episode_loss = sum(episode_loss_list)\n",
    "            epoch_loss_list.append(episode_loss)\n",
    "            p_optim.zero_grad()\n",
    "            episode_loss.backward()\n",
    "            p_optim.step()\n",
    "\n",
    "                \n",
    "        # <END_FOR_EPISODE>  \n",
    "        print()\n",
    "        if d_epoch % 10 == 0:\n",
    "            torch.save(p_model.state_dict(),\"./saved_models/0811CambAgent_Thomas_Size3_ep{}.pt\".format(d_epoch))\n",
    "    # <END_FOR_EPOCH>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeqBeam(p_config, p_sourceps, p_model, p_dataset):\n",
    "    print(\"# Start Beam Search...\")\n",
    "    \n",
    "    for d_episode in range(p_config[\"train\"][\"n_episode\"]):\n",
    "        p_model.eval()\n",
    "\n",
    "        if isinstance(p_dataset,list):\n",
    "            # ====== option 1: sample from dataset ====== #\n",
    "            eid = random.choice(range(len(p_dataset)))\n",
    "            data_prog, data_str_example = p_dataset[eid]\n",
    "            data_example = Example(\n",
    "                input=[p_sourceps.interpreter.load_data_into_var(p) for p in data_str_example.input],\n",
    "                output=p_sourceps.interpreter.load_data_into_var(data_str_example.output),\n",
    "            )\n",
    "            ps_solution = ProgramSpace(\n",
    "                p_sourceps.spec, p_sourceps.interpreter, data_example.input, data_example.output,\n",
    "            )\n",
    "            ps_solution.init_by_prog(data_prog)\n",
    "        else:\n",
    "            # ====== option 2: sample from generator ====== #\n",
    "            ps_solution = p_dataset.get_new_chain_program(\n",
    "                p_config[\"train\"][\"n_size\"] + 1 # depth=size+1\n",
    "            )\n",
    "\n",
    "        # solution self-check\n",
    "        if ps_solution.check_eq() is None:\n",
    "            continue\n",
    "            print(\"ERROR, SOLUTION NOT CONSISTENT!\")\n",
    "        else:\n",
    "            print(\"==== Problem ====\")\n",
    "            print(str(ps_solution.node_list[-1]))\n",
    "\n",
    "        selected_neurons = []\n",
    "\n",
    "        # initialize a new Program Space\n",
    "        ps_current = ProgramSpace(\n",
    "            p_sourceps.spec, p_sourceps.interpreter, ps_solution.inputs, ps_solution.output,\n",
    "        )\n",
    "        # then initialize a shell template\n",
    "        tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "        tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "        # replace the Param Node id in shells with -1 to make them templates\n",
    "        template_list = [\n",
    "            modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "            for i in range(len(tmp_shell_list))\n",
    "        ]\n",
    "        \n",
    "        beam_list = [\n",
    "            # (score, hidden, fn_context, ProgramSpace)\n",
    "            (0.0, None, 0, ps_current.make_copy())\n",
    "        ]\n",
    "\n",
    "        for d_step in range(len(ps_solution.shells)):\n",
    "            sprout_list = []\n",
    "            for d_bid in range(len(beam_list)):\n",
    "                dd_score, dd_hidden, dd_context, dd_ps = beam_list[d_bid]\n",
    "                ps_current = dd_ps\n",
    "                \n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                id_current = ps_current.get_strict_frontiers()[0]\n",
    "                var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "                var_output = ps_current.output\n",
    "\n",
    "                map_current = p_sourceps.interpreter.camb_get_ventogyrus(var_current)\n",
    "                map_output = p_sourceps.interpreter.camb_get_ventogyrus(var_output)\n",
    "\n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                current_shell_list = [None] + current_shell_list # None for <SOS> in nn embedding\n",
    "\n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float)).cuda()\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float)).cuda()\n",
    "                    td_context = Variable(torch.tensor([dd_context],dtype=torch.long)).cuda()\n",
    "                else:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float))\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float))\n",
    "                    td_context = Variable(torch.tensor([dd_context],dtype=torch.long))\n",
    "\n",
    "                # (B=1, fn_vocab_size)\n",
    "                hidden_current, td_pred = p_model.decode(td_current, td_output, dd_hidden, td_context)\n",
    "                \n",
    "                # start sprouting\n",
    "                np_pred = td_pred.data.cpu().numpy().flatten()\n",
    "                as_pred = np.argsort(np_pred)[::-1]\n",
    "                for i in range(p_config[\"test\"][\"sprout_size\"]):\n",
    "                    ppps = ps_current.make_copy()\n",
    "                    tmp_id = as_pred[i]\n",
    "                    fn_context = tmp_id\n",
    "                    # try to update\n",
    "                    update_status = ppps.add_neighboring_shell(\n",
    "                        current_shell_list[tmp_id]\n",
    "                    )\n",
    "                    if update_status:\n",
    "                        # success, put into sprout list\n",
    "                        sprout_list.append(\n",
    "                            (\n",
    "                                dd_score+np_pred[tmp_id],\n",
    "                                hidden_current,\n",
    "                                fn_context,\n",
    "                                ppps,\n",
    "                            )\n",
    "                        )\n",
    "                    # else: do nothing\n",
    "                # <END_FOR_SPROUT>\n",
    "            # <END_FOR_BEAM>\n",
    "            sorted_sprout_list = sorted(\n",
    "                sprout_list,\n",
    "                key=lambda x:x[0],\n",
    "                reverse=True,\n",
    "            )\n",
    "            if len(sorted_sprout_list)>p_config[\"test\"][\"beam_size\"]:\n",
    "                beam_list = sorted_sprout_list[:p_config[\"test\"][\"beam_size\"]]\n",
    "            else:\n",
    "                beam_list = sorted_sprout_list\n",
    "        # <END_FOR_STEP>\n",
    "        \n",
    "        # then print and seek for correct solutions\n",
    "        print(\"==== beam search ====\")\n",
    "        for i in range(len(beam_list)):\n",
    "            dd_score, dd_hidden, dd_context, dd_ps = beam_list[i]\n",
    "            print(\"#{}{}, {:.4f}, {}\".format(\n",
    "                \"(solved)\" if dd_ps.check_eq() is not None else \"\",\n",
    "                i+1,\n",
    "                dd_score,\n",
    "                str(dd_ps.node_list[-1])\n",
    "            ))\n",
    "        \n",
    "        input(\"==== Press to enter next problem ====\")\n",
    "\n",
    "    # <END_FOR_EPISODE>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb6.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    ")\n",
    "# dumb variable to help infer the shells\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_config = {\n",
    "    \"abs_dim\": 15*7+1,\n",
    "    \"fn_dim\": 128,\n",
    "    \"fn_vocab_size\": len(m_ps.get_neighboring_shells())+1, # with one more <SOS>\n",
    "    \"encoder\":{\n",
    "        \"input_dim\": None,\n",
    "        \"output_dim\": 1024, # hidden state\n",
    "    },\n",
    "    \"decoder\":{\n",
    "        \"input_dim\": None,\n",
    "        \"hidden_dim\": None,\n",
    "        \"output_dim\": None,\n",
    "    },\n",
    "    \"train\":{\n",
    "        \"n_epoch\":500, # #epoches in total\n",
    "        \"n_episode\": 100, # #problems per epoch\n",
    "        \"n_size\": 3,\n",
    "    },\n",
    "    \"test\":{\n",
    "        \"beam_size\": 40,\n",
    "        \"sprout_size\": 20,\n",
    "    },\n",
    "}\n",
    "m_config[\"encoder\"][\"input_dim\"] = m_config[\"abs_dim\"]*2\n",
    "m_config[\"decoder\"][\"input_dim\"] = \\\n",
    "    m_config[\"encoder\"][\"output_dim\"] + \\\n",
    "    m_config[\"fn_dim\"]\n",
    "m_config[\"decoder\"][\"hidden_dim\"] = m_config[\"encoder\"][\"output_dim\"]\n",
    "m_config[\"decoder\"][\"output_dim\"] = m_config[\"fn_vocab_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./0811Size3.pkl\",\"rb\") as f:\n",
    "    m_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_neo = SeqNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    seq_neo = seq_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(seq_neo.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start SeqTrain...\n",
      "# EP:0/34, loss:16.46"
     ]
    }
   ],
   "source": [
    "# SeqTrain(m_config, m_ps, seq_neo, m_generator, optimizer)\n",
    "SeqTrain(m_config, m_ps, seq_neo, m_dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start Beam Search...\n",
      "==== Problem ====\n",
      "neg_select(separate(gather(@param0, ['1', '5']), 6), ['3'])\n",
      "==== beam search ====\n",
      "#1, -4.0667, neg_select(gather(separate(@param0, 3), ['1', '3']), ['1', '2'])\n",
      "#2, -4.8805, unite(gather(separate(@param0, 1), ['1', '4']), 3, 4)\n",
      "#(solved)3, -5.7962, neg_select(separate(gather(@param0, ['1', '5']), 6), ['3'])\n",
      "#4, -6.1559, unite(gather(gather(@param0, ['1', '5']), ['1', '4']), 3, 4)\n",
      "#5, -6.2042, gather(gather(separate(@param0, 1), ['1', '4']), ['1', '4'])\n",
      "#6, -6.4143, neg_select(gather(separate(@param0, 3), ['3', '4']), ['1', '2'])\n",
      "#7, -6.5979, neg_select(gather(separate(@param0, 3), ['3', '4']), ['3', '6'])\n",
      "#8, -7.0793, summarise(group_by(separate(@param0, 1), ['1', '4']), min, 3)\n",
      "#9, -7.2556, neg_select(gather(separate(@param0, 1), ['1', '5']), ['1', '2'])\n",
      "#10, -7.3576, select(gather(separate(@param0, 1), ['1', '4']), ['2', '3'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "==== Press to enter next problem ==== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Problem ====\n",
      "neg_select(spread(gather(@param0, ['3', '4']), 4, 5), ['2', '4'])\n",
      "==== beam search ====\n",
      "#1, -7.5909, select(summarise(group_by(@param0, ['1']), sum, 1), ['2'])\n",
      "#2, -7.7589, mutate(summarise(group_by(@param0, ['1']), sum, 1), /, 1, 2)\n",
      "#3, -7.9501, mutate(summarise(group_by(@param0, ['1']), min, 1), /, 1, 2)\n",
      "#4, -8.0817, neg_gather(summarise(group_by(@param0, ['3', '4']), sum, 1), ['3'])\n",
      "#5, -8.1234, mutate(summarise(group_by(@param0, ['1']), mean, 1), /, 1, 2)\n",
      "#6, -8.2006, neg_gather(summarise(group_by(@param0, ['3', '5']), sum, 1), ['3'])\n",
      "#7, -8.2213, neg_select(summarise(group_by(@param0, ['1']), sum, 1), ['1'])\n",
      "#8, -8.4102, select(summarise(group_by(@param0, ['1']), mean, 1), ['2'])\n",
      "#9, -8.5070, gather(summarise(group_by(@param0, ['3', '5']), sum, 1), ['1', '2'])\n",
      "#10, -8.9388, select(summarise(group_by(@param0, ['1']), min, 1), ['2'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "==== Press to enter next problem ==== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Problem ====\n",
      "select(mutate(gather(@param0, ['3', '4']), /, 4, 2), ['3', '5'])\n",
      "==== beam search ====\n",
      "#1, -6.2143, neg_select(summarise(group_by(@param0, ['1', '4']), sum, 2), ['3'])\n",
      "#2, -6.6083, neg_select(summarise(group_by(@param0, ['1', '4']), min, 3), ['3'])\n",
      "#3, -6.9513, neg_select(summarise(group_by(@param0, ['1', '3']), min, 3), ['1', '3'])\n",
      "#4, -7.0731, neg_select(summarise(group_by(@param0, ['1', '3']), min, 3), ['1', '2'])\n",
      "#5, -7.2298, neg_select(neg_gather(gather(@param0, ['2', '4']), ['2', '4']), ['2'])\n",
      "#6, -7.2924, neg_select(summarise(group_by(@param0, ['1', '4']), sum, 3), ['3'])\n",
      "#7, -7.4381, neg_select(summarise(group_by(@param0, ['1', '4']), max, 2), ['3'])\n",
      "#8, -7.7452, neg_select(unite(gather(@param0, ['2', '4']), 3, 1), ['2', '3'])\n",
      "#9, -7.9352, neg_select(summarise(group_by(@param0, ['1', '3']), min, 3), ['3'])\n",
      "#10, -8.2295, neg_select(summarise(group_by(@param0, ['1', '3']), sum, 3), ['1', '2'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "==== Press to enter next problem ==== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Problem ====\n",
      "summarise(group_by(separate(@param0, 6), ['1']), mean, 1)\n",
      "==== beam search ====\n",
      "#1, -6.6255, select(summarise(group_by(@param0, ['3', '5']), sum, 1), ['1', '3'])\n",
      "#(solved)2, -6.7935, select(summarise(group_by(@param0, ['1', '5']), mean, 1), ['1', '3'])\n",
      "#(solved)3, -6.9181, select(summarise(group_by(@param0, ['1']), mean, 1), ['1', '2'])\n",
      "#4, -6.9246, select(summarise(group_by(@param0, ['4']), mean, 1), ['1', '2'])\n",
      "#5, -7.0415, neg_select(summarise(group_by(@param0, ['1']), sum, 1), ['1'])\n",
      "#6, -7.1012, select(summarise(group_by(@param0, ['3', '4']), min, 5), ['1', '2'])\n",
      "#7, -7.2389, neg_select(summarise(group_by(@param0, ['3', '4']), min, 5), ['1'])\n",
      "#8, -7.2662, neg_select(summarise(group_by(@param0, ['1']), mean, 1), ['1'])\n",
      "#9, -7.2873, select(summarise(group_by(@param0, ['3', '4']), min, 5), ['2', '3'])\n",
      "#(solved)10, -7.3074, select(summarise(group_by(@param0, ['1']), sum, 1), ['1', '2'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "==== Press to enter next problem ==== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Problem ====\n",
      "select(summarise(mutate(@param0, /, 1, 2), sum, 1), ['1'])\n",
      "==== beam search ====\n",
      "#1, -5.7483, neg_select(summarise(group_by(@param0, ['1', '3']), min, 3), ['1', '2'])\n",
      "#2, -6.5523, neg_select(summarise(group_by(@param0, ['1', '3']), min, 3), ['1', '3'])\n",
      "#3, -6.5812, neg_select(summarise(group_by(@param0, ['1', '3']), sum, 3), ['1', '2'])\n",
      "#4, -6.6168, select(summarise(group_by(@param0, ['1', '3']), sum, 3), ['3'])\n",
      "#5, -6.7748, neg_select(summarise(group_by(@param0, ['3', '5']), max, 2), ['1', '2'])\n",
      "#6, -6.9724, neg_select(summarise(group_by(@param0, ['3', '4']), min, 3), ['1', '3'])\n",
      "#7, -7.0206, neg_select(summarise(group_by(@param0, ['1', '4']), sum, 2), ['3'])\n",
      "#8, -7.0438, select(summarise(group_by(@param0, ['3']), sum, 1), ['2'])\n",
      "#9, -7.1583, select(summarise(group_by(@param0, ['1']), sum, 3), ['2'])\n",
      "#10, -7.1602, select(summarise(group_by(@param0, ['1']), sum, 1), ['2'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "==== Press to enter next problem ==== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Problem ====\n",
      "select(gather(neg_gather(@param0, ['1', '2']), ['2', '3']), ['4'])\n",
      "==== beam search ====\n",
      "#1, -8.0037, select(gather(separate(@param0, 2), ['2', '3']), ['4'])\n",
      "#2, -8.8808, separate(unite(separate(@param0, 2), 3, 2), 2)\n",
      "#3, -9.2636, summarise(group_by(gather(@param0, ['1', '3']), ['2', '4']), max, 2)\n",
      "#4, -9.3646, summarise(group_by(gather(@param0, ['1', '3']), ['1', '4']), max, 2)\n",
      "#5, -9.5317, summarise(group_by(gather(@param0, ['1', '3']), ['1', '2']), max, 2)\n",
      "#6, -9.5625, neg_select(gather(separate(@param0, 2), ['2', '3']), ['1', '2'])\n",
      "#7, -9.6291, neg_select(spread(gather(@param0, ['1', '3']), 3, 4), ['3'])\n",
      "#8, -9.6335, neg_select(gather(separate(@param0, 2), ['2', '3']), ['1', '5'])\n",
      "#9, -9.6730, summarise(group_by(separate(@param0, 2), ['1', '4']), mean, 4)\n",
      "#10, -9.6880, summarise(group_by(separate(@param0, 2), ['1', '4']), mean, 5)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "==== Press to enter next problem ==== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Problem ====\n",
      "summarise(mutate(neg_gather(@param0, ['1', '2']), /, 4, 2), min, 1)\n",
      "==== beam search ====\n",
      "#1, -5.6735, neg_select(summarise(group_by(@param0, ['1', '3']), min, 3), ['1', '2'])\n",
      "#2, -5.7599, select(summarise(group_by(@param0, ['1']), sum, 1), ['2'])\n",
      "#3, -6.1907, select(summarise(group_by(@param0, ['1', '3']), sum, 3), ['3'])\n",
      "#4, -6.2728, neg_select(summarise(group_by(@param0, ['1', '3']), min, 3), ['1', '3'])\n",
      "#5, -6.3810, select(summarise(group_by(@param0, ['3']), sum, 1), ['2'])\n",
      "#6, -6.4087, select(summarise(group_by(@param0, ['1']), mean, 1), ['2'])\n",
      "#7, -6.4778, select(summarise(group_by(@param0, ['1']), sum, 3), ['2'])\n",
      "#8, -6.5092, select(summarise(group_by(@param0, ['1']), mean, 2), ['2'])\n",
      "#9, -6.5790, neg_select(summarise(group_by(@param0, ['1', '3']), sum, 3), ['1', '2'])\n",
      "#10, -6.7783, neg_select(summarise(group_by(@param0, ['1']), sum, 1), ['1'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "==== Press to enter next problem ==== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Problem ====\n",
      "summarise(gather(mutate(@param0, /, 2, 4), ['3', '5']), min, 1)\n",
      "==== beam search ====\n",
      "#1, -5.4296, select(summarise(group_by(@param0, ['1']), sum, 1), ['2'])\n",
      "#2, -5.4459, select(summarise(group_by(@param0, ['1', '3']), sum, 3), ['3'])\n",
      "#3, -5.5176, neg_select(summarise(group_by(@param0, ['1', '3']), min, 3), ['1', '2'])\n",
      "#4, -5.9697, neg_select(summarise(group_by(@param0, ['1']), sum, 1), ['1'])\n",
      "#5, -6.0898, select(summarise(group_by(@param0, ['3']), sum, 1), ['2'])\n",
      "#6, -6.0925, select(summarise(group_by(@param0, ['1']), mean, 1), ['2'])\n",
      "#7, -6.1640, select(summarise(group_by(@param0, ['1']), sum, 3), ['2'])\n",
      "#8, -6.1681, select(summarise(group_by(@param0, ['1']), mean, 2), ['2'])\n",
      "#9, -6.1855, neg_select(summarise(group_by(@param0, ['1', '3']), sum, 3), ['1', '2'])\n",
      "#10, -6.3301, neg_select(summarise(group_by(@param0, ['1', '3']), min, 3), ['1', '3'])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "==== Press to enter next problem ==== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Problem ====\n",
      "gather(unite(gather(@param0, ['4', '5']), 3, 5), ['3', '4'])\n",
      "==== beam search ====\n",
      "#1, -4.5679, neg_select(gather(separate(@param0, 3), ['1', '3']), ['1', '2'])\n",
      "#2, -5.5894, neg_select(gather(separate(@param0, 3), ['3', '4']), ['3', '6'])\n",
      "#3, -6.0112, neg_select(gather(separate(@param0, 3), ['3', '4']), ['1', '2'])\n",
      "#4, -6.7527, neg_select(gather(separate(@param0, 3), ['1', '5']), ['1', '2'])\n",
      "#5, -6.7625, summarise(group_by(separate(@param0, 5), ['1', '5']), max, 2)\n",
      "#6, -6.8747, unite(gather(separate(@param0, 3), ['3', '5']), 5, 1)\n",
      "#7, -7.3128, summarise(group_by(separate(@param0, 3), ['1', '4']), sum, 2)\n",
      "#8, -7.5906, neg_select(gather(separate(@param0, 3), ['3', '4']), ['3', '4'])\n",
      "#9, -7.6182, neg_select(gather(separate(@param0, 3), ['4', '6']), ['1', '2'])\n",
      "#10, -7.6551, neg_select(neg_gather(gather(@param0, ['1', '5']), ['1', '2']), ['2'])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-06107108ccf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSeqBeam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_neo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-2f74652a8e90>\u001b[0m in \u001b[0;36mSeqBeam\u001b[0;34m(p_config, p_sourceps, p_model, p_dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m             ))\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==== Press to enter next problem ====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# <END_FOR_EPISODE>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SeqBeam(m_config, m_ps, seq_neo, m_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
