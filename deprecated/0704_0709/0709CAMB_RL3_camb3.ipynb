{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransNeo\n",
    "- AlphaNeo using pre-trained TransE embeddings\n",
    "- Stage: Cambrian\n",
    "- Version: Charniodiscus\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.interpreter import Interpreter, PostOrderInterpreter, GeneralError, InterpreterError\n",
    "from tyrell.enumerator import Enumerator, SmtEnumerator, RandomEnumerator, DesignatedEnumerator, RandomEnumeratorS, ExhaustiveEnumerator\n",
    "from tyrell.decider import Example, ExampleConstraintPruningDecider, ExampleDecider, TestDecider\n",
    "from tyrell.synthesizer import Synthesizer\n",
    "from tyrell.logger import get_logger\n",
    "from sexpdata import Symbol\n",
    "from tyrell import dsl as D\n",
    "from typing import Callable, NamedTuple, List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morpheus Version\n",
    "from utils_morpheus import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG_PS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueEncoder(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(ValueEncoder, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.vocab_size = self.config[\"val\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"val\"][\"embd_dim\"]\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embd_dim,\n",
    "            self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels = self.config[\"val\"][\"embd_dim\"],\n",
    "            out_channels = self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            kernel_size = self.config[\"val\"][\"conv_kernel_size\"],\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = self.config[\"val\"][\"pool_kernel_size\"],\n",
    "            padding = self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            self.config[\"embd_dim\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, bp_map):\n",
    "        # batched maps, (B, map_r, map_c)\n",
    "        # in this version, every value only contains 1 map\n",
    "        B = bp_map.shape[0]\n",
    "        \n",
    "        # (B, map_r, map_c, val_embd_dim) -> (B, val_embd_dim, map_r, map_c)\n",
    "        d_embd = self.embedding(bp_map).permute(0,3,1,2)\n",
    "        \n",
    "        # (B, n_kernel, map_r, 1)\n",
    "        d_conv = F.relu(self.conv(d_embd))\n",
    "        \n",
    "        # (B, n_kernel)\n",
    "        d_pool = self.pool(d_conv).view(B,self.config[\"val\"][\"conv_n_kernels\"])\n",
    "        \n",
    "        # (B, embd_dim)\n",
    "        d_out = torch.sigmoid(\n",
    "            self.fc(d_pool)\n",
    "        )\n",
    "        \n",
    "        return d_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorphTransE(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(MorphTransE, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.value_encoder = ValueEncoder(p_config=p_config)\n",
    "        \n",
    "        self.fn_vocab_size = self.config[\"fn\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"embd_dim\"]\n",
    "        \n",
    "        self.fn_embedding = nn.Embedding(\n",
    "            self.fn_vocab_size,\n",
    "            self.embd_dim,\n",
    "        )\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fn_embedding.weight.data)\n",
    "        self.fn_embedding.weight.data = F.normalize(\n",
    "            self.fn_embedding.weight.data, p=2, dim=1,\n",
    "        )\n",
    "# ----> skip the forward part since we don't need it <---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(TransNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        # predict a fixed number of shells\n",
    "        self.policy = nn.Linear(\n",
    "            self.config[\"embd_dim\"],\n",
    "            self.config[\"fn\"][\"vocab_size\"],\n",
    "        )\n",
    "        \n",
    "        # deeper\n",
    "#         self.policy0 = nn.Linear(\n",
    "#             self.config[\"embd_dim\"],\n",
    "#             2048,\n",
    "#         )\n",
    "#         self.policy1 = nn.Linear(\n",
    "#             2048,\n",
    "#             self.config[\"fn\"][\"vocab_size\"],\n",
    "#         )\n",
    "        \n",
    "        self.mte = MorphTransE(p_config=p_config)\n",
    "        # then load the parameters\n",
    "        self.mte.load_state_dict(torch.load(self.config[\"mte_path\"]))\n",
    "        \n",
    "    def forward(self, p_mapin, p_mapout):\n",
    "        # p_mapin/p_mapout: (B, map_r, map_c)\n",
    "        v_in = self.mte.value_encoder(p_mapin).detach() # (B, embd_dim)\n",
    "        v_out= self.mte.value_encoder(p_mapout).detach() # (B, embd_dim)\n",
    "        v_delta = v_out - v_in\n",
    "        tmp_out = torch.log_softmax(\n",
    "            self.policy(v_delta),dim=1\n",
    "        )\n",
    "#         tmp_out = torch.log_softmax(\n",
    "#             self.policy1(\n",
    "#                 F.relu(\n",
    "#                     self.policy0(\n",
    "#                         v_delta\n",
    "#                     )\n",
    "#                 )\n",
    "#             ),dim=1\n",
    "#         )\n",
    "        \n",
    "        return tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_program(p_config, p_interpreter, p_generator):\n",
    "    # initialize a program first\n",
    "    while True:\n",
    "        p_input = p_interpreter.random_table()\n",
    "        p_prog, p_example = p_generator.generate(\n",
    "            fixed_depth=p_config[\"fixed_depth\"],\n",
    "            example=Example(input=[p_input], output=None),\n",
    "        )\n",
    "        # make sure at least one function call\n",
    "        if p_prog is not None and p_prog.is_apply():\n",
    "            break\n",
    "    return p_prog, p_example\n",
    "\n",
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))\n",
    "\n",
    "def TransNeoTrainer(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer):\n",
    "    global DBG_PS\n",
    "    nth_attempt = 0 # tell whether to back-prop or not\n",
    "    batch_loss = 0.\n",
    "    \n",
    "    n_solved = 0 # track the number of solved problem\n",
    "    n_attempt_list = [] # track the number of attempts in every episode\n",
    "    \n",
    "    # print(\"BEFORE\")\n",
    "    # print(p_model.policy1.weight)\n",
    "    \n",
    "    for d_episode in range(p_config[\"n_episode\"]):\n",
    "        p_model.train()\n",
    "        \n",
    "        # in every episode, generate a new program(maze/ps) to learn\n",
    "        p_prog, p_example = get_new_program(\n",
    "            p_config, p_interpreter, p_generator,\n",
    "        )\n",
    "        ps_solution = ProgramSpace(\n",
    "            p_spec, p_interpreter, p_example.input, p_example.output,\n",
    "        )\n",
    "        ps_solution.init_by_prog(p_prog) # this constructs a solution for this problem\n",
    "        DBG_PS = ps_solution\n",
    "        \n",
    "        is_solved = False\n",
    "        \n",
    "        for d_attempt in range(p_config[\"max_attempts\"]):\n",
    "            if is_solved:\n",
    "                # already solved in the last attempt, stop\n",
    "                break\n",
    "            nth_attempt += 1\n",
    "            \n",
    "            selected_neurons = []\n",
    "            attempt_reward = None\n",
    "            \n",
    "            # in every new attempt, initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, p_example.input, p_example.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "                \n",
    "            for d_step in range(p_config[\"max_steps\"]):\n",
    "                \n",
    "                # print the training progress\n",
    "                print(\"\\r# AC/EP:{}/{}, AT:{}, SP:{}, avg.attempt:{:.2f}, er:{:.2f}\".format(\n",
    "                    n_solved, d_episode, d_attempt, d_step, \n",
    "                    sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else -1,\n",
    "                    p_config[\"exploration_rate\"](d_episode,d_attempt),\n",
    "                ),end=\"\")\n",
    "                \n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                # print(\"frontiers:{}\".format(ps_current.get_frontiers()))\n",
    "                # input(\"PAUSE\")\n",
    "                id_current = ps_current.get_frontiers()[0]\n",
    "                var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "                var_output = p_example.output\n",
    "                \n",
    "                map_current = camb_get_abs(var_current)\n",
    "                map_output = camb_get_abs(var_output)\n",
    "                \n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                \n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.long)).cuda()\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.long)).cuda()\n",
    "                else:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.long))\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.long))\n",
    "                    \n",
    "                # (B=1, fn_vocab_size)\n",
    "                # fn_vocab_size\n",
    "                td_pred = p_model(td_current, td_output)\n",
    "                \n",
    "                if random.random()<=p_config[\"hint_rate\"](d_episode):\n",
    "                    # print(\"hint!\")\n",
    "                    # give some hints\n",
    "                    tmp_id = current_shell_list.index(ps_solution.shells[d_step])\n",
    "                else:\n",
    "                    # no hints\n",
    "                    if random.random()<=p_config[\"exploration_rate\"](d_episode,d_attempt):\n",
    "                        # exploration\n",
    "                        tmp_id = random.choice(range(len(current_shell_list)))\n",
    "                    else:\n",
    "                        # exploitation\n",
    "                        tmp_id = torch.multinomial(td_pred.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "                \n",
    "                # print(\"shell to add:{}\".format(current_shell_list[tmp_id]))\n",
    "                # input(\"PAUSE-2\")\n",
    "                \n",
    "                # record selected neuron\n",
    "                selected_neurons.append(td_pred[0,tmp_id])\n",
    "                # update ps_current\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if update_status:\n",
    "                    # succeed\n",
    "                    if ps_current.check_eq() is not None:\n",
    "                        # and solved!\n",
    "                        is_solved = True\n",
    "                        n_solved += 1\n",
    "                        attempt_reward = 1.0\n",
    "                        break\n",
    "                    # else: not yet solved, just move to next step\n",
    "                else:\n",
    "                    # fail, do not continue\n",
    "                    break\n",
    "            \n",
    "            # <END_FOR_STEP>\n",
    "                \n",
    "            # check the attempt_reward\n",
    "            if attempt_reward is None:\n",
    "                # means either failure in execution or exceeding max_step\n",
    "                attempt_reward = -0.1\n",
    "            \n",
    "            # compute the loss\n",
    "            attempt_loss = 0.\n",
    "            for i in range(len(selected_neurons)):\n",
    "                d_decay = p_config[\"decay_rate\"]**(len(selected_neurons)-1-i)\n",
    "                attempt_loss += d_decay*attempt_reward*(-selected_neurons[i])\n",
    "                \n",
    "            batch_loss += attempt_loss\n",
    "            if is_solved or nth_attempt>=p_config[\"batch_size\"]:\n",
    "                # print(\"\\nBP!\")\n",
    "                # directly do the back-prop\n",
    "                p_optim.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                p_optim.step()\n",
    "                nth_attempt = 0\n",
    "                batch_loss = 0.\n",
    "                # print(\"AFTER\")\n",
    "                # print(p_model.policy1.weight)\n",
    "                \n",
    "        # <END_FOR_ATTEMPT>     \n",
    "        \n",
    "        # after all the attempts\n",
    "        n_attempt_list.append(d_attempt)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\n",
    "                'avg.attempt',\n",
    "                sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else 0,\n",
    "                len(n_attempt_list),\n",
    "            )\n",
    "            \n",
    "    # <END_FOR_EPISODE>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    "    sfn=m_interpreter.sanity_check,\n",
    ")\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")\n",
    "\n",
    "m_config = {\n",
    "    \"val\":{\n",
    "        \"vocab_size\": len(CAMB_LIST),\n",
    "        \"embd_dim\": 16, # embedding dim of CAMB abstract token\n",
    "        \"conv_n_kernels\": 512,\n",
    "        \"conv_kernel_size\": (1,CAMB_NCOL), \n",
    "        \"pool_kernel_size\": (CAMB_NROW,1), \n",
    "        \"IDX_PAD\": 0,\n",
    "    },\n",
    "    \"fn\":{\n",
    "        \"vocab_size\": len(m_ps.get_neighboring_shells())\n",
    "    },\n",
    "    \"embd_dim\": 128,\n",
    "    \"mte_path\": \"./saved_models/0709CAMB_TransE_camb3_std_ep{}.pt\".format(180),\n",
    "    \"batch_size\": 8, # number of steps between every back-prop by n_attempt\n",
    "    \"fixed_depth\": 4, # means size of 3\n",
    "    \"n_episode\": 100000000,\n",
    "    \"max_attempts\": 100, # max number of attepmts in every episode\n",
    "    \"max_steps\": 3, # max number of function calls\n",
    "    # \"exploration_rate\": 0.1, # fixed exp rate\n",
    "    # \"exploration_rate\": lambda x:0.9-0.8*(min(1,x/2500)), # from 0.9 to 0.1\n",
    "    \"exploration_rate\": lambda xep,xat:(0.9-0.8*(min(1,xep/1000)))*(1-xat/100), # from 0.9 to 0.1\n",
    "    \"decay_rate\": 0.9,\n",
    "    # \"hint_rate\": lambda x:1 if x<1000 and x%2==0 else 0, # first 100 episodes have hints\n",
    "    # \"hint_rate\": lambda x:1 if x<10000 else 0, # first 100 episodes have hints\n",
    "    \"hint_rate\": lambda x:0,\n",
    "}\n",
    "\n",
    "trans_neo = TransNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    trans_neo = trans_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(trans_neo.parameters()))\n",
    "writer = SummaryWriter(\"runs/0709CAMB_RL1_camb3\")\n",
    "# writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 5.7268e-02,  6.1678e-04,  5.2439e-04,  ...,  7.5539e-04,\n",
       "          5.4709e-04,  5.7681e-04],\n",
       "        [ 6.0244e-02, -1.6486e-03, -1.4140e-02,  ...,  2.2669e-03,\n",
       "         -1.6315e-02,  2.6088e-03],\n",
       "        [ 8.8966e-02,  1.3801e-03,  1.4845e-03,  ...,  1.5980e-03,\n",
       "          1.2511e-03,  1.5288e-03],\n",
       "        ...,\n",
       "        [ 3.7081e-04, -2.2392e-04,  2.2704e-07,  ...,  1.2175e-07,\n",
       "          9.4631e-06,  6.3774e-04],\n",
       "        [-2.9767e-04,  1.9597e-07, -1.1352e-03,  ...,  6.4633e-03,\n",
       "         -6.2261e-03,  6.5144e-04],\n",
       "        [-3.9150e-02,  1.5500e-02,  1.3192e-02,  ..., -4.6315e-02,\n",
       "          5.9218e-10,  5.0396e-02]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_neo.mte.fn_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val': {'vocab_size': 150,\n",
       "  'embd_dim': 16,\n",
       "  'conv_n_kernels': 512,\n",
       "  'conv_kernel_size': (1, 15),\n",
       "  'pool_kernel_size': (15, 1),\n",
       "  'IDX_PAD': 0},\n",
       " 'fn': {'vocab_size': 120},\n",
       " 'embd_dim': 128,\n",
       " 'mte_path': './saved_models/0709CAMB_TransE_camb3_std_ep180.pt',\n",
       " 'batch_size': 8,\n",
       " 'fixed_depth': 4,\n",
       " 'n_episode': 100000000,\n",
       " 'max_attempts': 100,\n",
       " 'max_steps': 3,\n",
       " 'exploration_rate': <function __main__.<lambda>(xep, xat)>,\n",
       " 'decay_rate': 0.9,\n",
       " 'hint_rate': <function __main__.<lambda>(x)>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AC/EP:34/748, AT:30, SP:2, avg.attempt:96.53, er:0.21"
     ]
    }
   ],
   "source": [
    "TransNeoTrainer(m_config, m_spec, m_interpreter, m_generator, trans_neo, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=trans_neo.mte.fn_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cosine_similarity(u,u[[0 for i in range(120)],:],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cosine_similarity(u,u[[1 for i in range(120)],:],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cosine_similarity(u,u[[2 for i in range(120)],:],dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
