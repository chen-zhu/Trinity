{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransNeo\n",
    "- AlphaNeo using pre-trained TransE embeddings\n",
    "- Stage: Cambrian\n",
    "- Version: Charniodiscus\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.interpreter import Interpreter, PostOrderInterpreter, GeneralError, InterpreterError\n",
    "from tyrell.enumerator import Enumerator, SmtEnumerator, RandomEnumerator, DesignatedEnumerator, RandomEnumeratorS, ExhaustiveEnumerator\n",
    "from tyrell.decider import Example, ExampleConstraintPruningDecider, ExampleDecider, TestDecider\n",
    "from tyrell.synthesizer import Synthesizer\n",
    "from tyrell.logger import get_logger\n",
    "from sexpdata import Symbol\n",
    "from tyrell import dsl as D\n",
    "from typing import Callable, NamedTuple, List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morpheus Version\n",
    "from utils_morpheus import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG_PS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueEncoder(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(ValueEncoder, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.vocab_size = self.config[\"val\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"val\"][\"embd_dim\"]\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embd_dim,\n",
    "            self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels = self.config[\"val\"][\"embd_dim\"],\n",
    "            out_channels = self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            kernel_size = self.config[\"val\"][\"conv_kernel_size\"],\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = self.config[\"val\"][\"pool_kernel_size\"],\n",
    "            padding = self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            self.config[\"embd_dim\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, bp_map):\n",
    "        # batched maps, (B, map_r, map_c)\n",
    "        # in this version, every value only contains 1 map\n",
    "        B = bp_map.shape[0]\n",
    "        \n",
    "        # (B, map_r, map_c, val_embd_dim) -> (B, val_embd_dim, map_r, map_c)\n",
    "        d_embd = self.embedding(bp_map).permute(0,3,1,2)\n",
    "        \n",
    "        # (B, n_kernel, map_r, 1)\n",
    "        d_conv = F.relu(self.conv(d_embd))\n",
    "        \n",
    "        # (B, n_kernel)\n",
    "        d_pool = self.pool(d_conv).view(B,self.config[\"val\"][\"conv_n_kernels\"])\n",
    "        \n",
    "        # (B, embd_dim)\n",
    "        d_out = torch.sigmoid(\n",
    "            self.fc(d_pool)\n",
    "        )\n",
    "        \n",
    "        return d_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorphTransE(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(MorphTransE, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.value_encoder = ValueEncoder(p_config=p_config)\n",
    "        \n",
    "        self.fn_vocab_size = self.config[\"fn\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"embd_dim\"]\n",
    "        \n",
    "        self.fn_embedding = nn.Embedding(\n",
    "            self.fn_vocab_size,\n",
    "            self.embd_dim,\n",
    "        )\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fn_embedding.weight.data)\n",
    "        self.fn_embedding.weight.data = F.normalize(\n",
    "            self.fn_embedding.weight.data, p=2, dim=1,\n",
    "        )\n",
    "# ----> skip the forward part since we don't need it <---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(TransNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        # predict a fixed number of shells\n",
    "        self.policy = nn.Linear(\n",
    "            self.config[\"embd_dim\"],\n",
    "            self.config[\"fn\"][\"vocab_size\"],\n",
    "        )\n",
    "        \n",
    "        # deeper\n",
    "#         self.policy0 = nn.Linear(\n",
    "#             self.config[\"embd_dim\"],\n",
    "#             2048,\n",
    "#         )\n",
    "#         self.policy1 = nn.Linear(\n",
    "#             2048,\n",
    "#             self.config[\"fn\"][\"vocab_size\"],\n",
    "#         )\n",
    "        \n",
    "        self.mte = MorphTransE(p_config=p_config)\n",
    "        # then load the parameters\n",
    "        self.mte.load_state_dict(torch.load(self.config[\"mte_path\"]))\n",
    "        \n",
    "    def forward(self, p_mapin, p_mapout):\n",
    "        # p_mapin/p_mapout: (B, map_r, map_c)\n",
    "        v_in = self.mte.value_encoder(p_mapin).detach() # (B, embd_dim)\n",
    "        v_out= self.mte.value_encoder(p_mapout).detach() # (B, embd_dim)\n",
    "        v_delta = v_out - v_in\n",
    "        tmp_out = torch.log_softmax(\n",
    "            self.policy(v_delta),dim=1\n",
    "        )\n",
    "#         tmp_out = torch.log_softmax(\n",
    "#             self.policy1(\n",
    "#                 F.relu(\n",
    "#                     self.policy0(\n",
    "#                         v_delta\n",
    "#                     )\n",
    "#                 )\n",
    "#             ),dim=1\n",
    "#         )\n",
    "        \n",
    "        return tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_program(p_config, p_interpreter, p_generator):\n",
    "    # initialize a program first\n",
    "    while True:\n",
    "        p_input = p_interpreter.random_table()\n",
    "        p_prog, p_example = p_generator.generate(\n",
    "            fixed_depth=p_config[\"fixed_depth\"],\n",
    "            example=Example(input=[p_input], output=None),\n",
    "        )\n",
    "        # make sure at least one function call\n",
    "        if p_prog is not None and p_prog.is_apply():\n",
    "            break\n",
    "    return p_prog, p_example\n",
    "\n",
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransNeoBeam(p_config, p_spec, p_interpreter, p_model, p_exp, verbose=False):\n",
    "    p_model.eval()\n",
    "    p_example = p_exp\n",
    "    is_solved = False\n",
    "    \n",
    "    # in every new attempt, initialize a new Program Space\n",
    "    ps_current = ProgramSpace(\n",
    "        p_spec, p_interpreter, p_example.input, p_example.output,\n",
    "    )\n",
    "    \n",
    "    seed_list = [\n",
    "        (0.0, ps_current, True) # (score, ps, is_alive)\n",
    "    ]\n",
    "    beam_list = []\n",
    "    dead_list = []\n",
    "    \n",
    "    # start the beam search\n",
    "    for d_step in range(p_config[\"max_steps\"]):\n",
    "        if verbose:\n",
    "            print(\"# Analyzing step#{}\".format(d_step))\n",
    "        \n",
    "        for sd_score, sd_ps, sd_sts in seed_list:\n",
    "            \n",
    "            if not sd_sts:\n",
    "                # already dead, append it then move on to the next\n",
    "                dead_list.append(\n",
    "                    (sd_score, sd_ps, sd_sts)\n",
    "                )\n",
    "                continue\n",
    "            \n",
    "            # initialized customized shell template\n",
    "            sd_shell_list = sd_ps.get_neighboring_shells()\n",
    "            sd_node_to_replace = sd_ps.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            sd_template_list = [\n",
    "                modify_shell(sd_shell_list[i],sd_node_to_replace,-1)\n",
    "                for i in range(len(sd_shell_list))\n",
    "            ]\n",
    "            \n",
    "            # ### assume chain execution, so only 1 possible returns\n",
    "            # ### at d_step=0, this should be input[0]\n",
    "            id_current = sd_ps.get_frontiers()[0]\n",
    "            var_current = sd_ps.node_list[id_current].ps_data # need the real var name in r env\n",
    "            var_output = sd_ps.output\n",
    "\n",
    "            map_current = camb_get_abs(var_current)\n",
    "            map_output = camb_get_abs(var_output)\n",
    "\n",
    "            # make current shell list\n",
    "            current_shell_list = [\n",
    "                modify_shell(sd_template_list[i],-1,id_current)\n",
    "                for i in range(len(sd_template_list))\n",
    "            ]\n",
    "\n",
    "            # wrap in B=1\n",
    "            if use_cuda:\n",
    "                td_current = Variable(torch.tensor([map_current],dtype=torch.long)).cuda()\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.long)).cuda()\n",
    "            else:\n",
    "                td_current = Variable(torch.tensor([map_current],dtype=torch.long))\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.long))\n",
    "\n",
    "            # (B=1, fn_vocab_size)\n",
    "            # fn_vocab_size\n",
    "            td_pred = p_model(td_current, td_output)\n",
    "            d_pred = td_pred.data.flatten().cpu().numpy()\n",
    "            asorted_pred = np.argsort(d_pred)[::-1]\n",
    "            \n",
    "            # pick and add the top beam_size actions\n",
    "            for i in range(p_config[\"test\"][\"beam_size\"]):\n",
    "                d_ind = asorted_pred[i]\n",
    "                tmp_ps = copy.deepcopy(sd_ps)\n",
    "                tmp_status = tmp_ps.add_neighboring_shell(\n",
    "                    sd_shell_list[d_ind]\n",
    "                )\n",
    "                # check if successful\n",
    "                if tmp_status:\n",
    "                    # succeed\n",
    "                    beam_list.append(\n",
    "                        (sd_score+d_pred[d_ind], tmp_ps, True)\n",
    "                    )\n",
    "                else:\n",
    "                    # fail\n",
    "                    beam_list.append(\n",
    "                        (sd_score+d_pred[d_ind], tmp_ps, False)\n",
    "                    )\n",
    "        \n",
    "        # <END_SEED_LIST>\n",
    "        # sort the beam list and keep the top seeded ones\n",
    "        sorted_beam_list = sorted(beam_list, key=lambda p:p[0], reverse=True)\n",
    "        seed_list = sorted_beam_list[:p_config[\"test\"][\"seed_size\"]] if len(seed_list)>=p_config[\"test\"][\"seed_size\"] else sorted_beam_list\n",
    "        beam_list = []\n",
    "\n",
    "    # <END_STEP>\n",
    "    # filter out the beam list once again\n",
    "    for sd_score, sd_ps, sd_sts in seed_list:\n",
    "        if not sd_sts:\n",
    "            # already dead, append it then move on to the next\n",
    "            dead_list.append(\n",
    "                (sd_score, sd_ps, sd_sts)\n",
    "            )\n",
    "            continue\n",
    "        else:\n",
    "            beam_list.append(\n",
    "                (sd_score, sd_ps, sd_sts)\n",
    "            )\n",
    "    seed_list = beam_list\n",
    "    \n",
    "    return seed_list, dead_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    "    sfn=m_interpreter.sanity_check,\n",
    ")\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")\n",
    "\n",
    "m_config = {\n",
    "    \"val\":{\n",
    "        \"vocab_size\": len(CAMB_LIST),\n",
    "        \"embd_dim\": 16, # embedding dim of CAMB abstract token\n",
    "        \"conv_n_kernels\": 512,\n",
    "        \"conv_kernel_size\": (1,CAMB_NCOL), \n",
    "        \"pool_kernel_size\": (CAMB_NROW,1), \n",
    "        \"IDX_PAD\": 0,\n",
    "    },\n",
    "    \"fn\":{\n",
    "        \"vocab_size\": len(m_ps.get_neighboring_shells())\n",
    "    },\n",
    "    \"embd_dim\": 128,\n",
    "    \"mte_path\": \"./saved_models/0712CAMB_TransE_camb3_ep{}.pt\".format(150),\n",
    "    \"agent_path\": \"./saved_models/0712CAMB_RL2_camb3_ep{}.pt\".format(4300),\n",
    "    \"batch_size\": 8, # number of steps between every back-prop by n_attempt\n",
    "    \"fixed_depth\": 3, # means size of 3\n",
    "    \"n_episode\": 100000000,\n",
    "    \"max_attempts\": 100, # max number of attepmts in every episode\n",
    "    \"max_steps\": 2, # max number of function calls\n",
    "    # \"exploration_rate\": 0.1, # fixed exp rate\n",
    "    # \"exploration_rate\": lambda x:0.9-0.8*(min(1,x/2500)), # from 0.9 to 0.1\n",
    "    \"exploration_rate\": lambda xep,xat:(0.9-0.8*(min(1,xep/1000)))*(1-xat/100), # from 0.9 to 0.1\n",
    "    \"decay_rate\": 0.9,\n",
    "    # \"hint_rate\": lambda x:1 if x<1000 and x%2==0 else 0, # first 100 episodes have hints\n",
    "    # \"hint_rate\": lambda x:1 if x<10000 else 0, # first 100 episodes have hints\n",
    "    \"hint_rate\": lambda x:0,\n",
    "    \"test\":{\n",
    "        \"beam_size\":50, # how many candidates to expand in every step\n",
    "        \"seed_size\":20, # how many candidates are there in every final list\n",
    "    }\n",
    "}\n",
    "\n",
    "trans_neo = TransNeo(p_config=m_config)\n",
    "trans_neo.load_state_dict(torch.load(m_config[\"agent_path\"]))\n",
    "if use_cuda:\n",
    "    trans_neo = trans_neo.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val': {'vocab_size': 150,\n",
       "  'embd_dim': 16,\n",
       "  'conv_n_kernels': 512,\n",
       "  'conv_kernel_size': (1, 15),\n",
       "  'pool_kernel_size': (15, 1),\n",
       "  'IDX_PAD': 0},\n",
       " 'fn': {'vocab_size': 120},\n",
       " 'embd_dim': 128,\n",
       " 'mte_path': './saved_models/0712CAMB_TransE_camb3_ep150.pt',\n",
       " 'agent_path': './saved_models/0712CAMB_RL2_camb3_ep4300.pt',\n",
       " 'batch_size': 8,\n",
       " 'fixed_depth': 3,\n",
       " 'n_episode': 100000000,\n",
       " 'max_attempts': 100,\n",
       " 'max_steps': 2,\n",
       " 'exploration_rate': <function __main__.<lambda>(xep, xat)>,\n",
       " 'decay_rate': 0.9,\n",
       " 'hint_rate': <function __main__.<lambda>(x)>,\n",
       " 'test': {'beam_size': 50, 'seed_size': 20}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransNeoTrainer(m_config, m_spec, m_interpreter, m_generator, trans_neo, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Analyzing step#0\n",
      "# Analyzing step#1\n",
      "====INPUT====\n",
      "  OCOL1 OCOL2  OCOL3 OCOL4  OCOL5\n",
      "1    29    36  61.59    50  65.15\n",
      "2    29    96  72.77    94  21.47\n",
      "3    75    85 -42.04    56 -26.65\n",
      "4    29   -66 -66.84    56 -20.60\n",
      "5    29     5  27.93    56  49.19\n",
      "\n",
      "====OUTPUT====\n",
      "  OCOL1  OCOL3  OCOL5 -66  5 COL179001 COL179002 85 96\n",
      "1    29 -66.84 -20.60  56 NA      <NA>      <NA> NA NA\n",
      "2    29  27.93  49.19  NA 56      <NA>      <NA> NA NA\n",
      "3    29  61.59  65.15  NA NA        50      <NA> NA NA\n",
      "4    29  72.77  21.47  NA NA      <NA>      <NA> NA 94\n",
      "5    75 -42.04 -26.65  NA NA      <NA>      <NA> 56 NA\n",
      "\n",
      "====Original Program====\n",
      "separate(spread(@param0, 2, 4), 6)\n",
      "=====Beam Solutions=====\n",
      "#1(False,-9.442216873168945): spread(@param0, 1, 2)\n",
      "#2(False,-10.522241115570068): gather(@param0, ['1'])\n",
      "#3(False,-11.354947090148926): select(@param0, ['4', '5'])\n",
      "#4(False,-11.543549060821533): gather(@param0, ['1', '2'])\n",
      "#5(False,-11.753877639770508): gather(@param0, ['1', '2'])\n",
      "#6(False,-12.008302688598633): unite(@param0, 2, 3)\n",
      "#7(False,-12.17349624633789): gather(@param0, ['1', '2'])\n",
      "#8(True,-12.253339767456055): spread(@param0, 2, 3)\n",
      "#9(False,-12.255239009857178): gather(@param0, ['1', '2'])\n",
      "#10(False,-12.270286083221436): gather(@param0, ['4'])\n",
      "#11(False,-12.310265302658081): gather(gather(@param0, ['1', '2']), ['4'])\n",
      "#12(False,-12.417108535766602): gather(@param0, ['1', '2'])\n",
      "=====Dead Solutions=====\n",
      "#1(,-13.294079780578613): @param0\n",
      "#2(,-13.388744354248047): @param0\n",
      "#3(,-13.446401596069336): @param0\n",
      "#4(,-13.6854248046875): @param0\n",
      "#5(,-0.0005846023559570312): select(@param0, ['4', '5'])\n",
      "#6(,-10.88929271697998): select(@param0, ['2', '3'])\n",
      "#7(,-10.893803596496582): select(@param0, ['3'])\n",
      "#8(,-11.418354988098145): select(@param0, ['1'])\n",
      "#9(,-11.42599868774414): select(@param0, ['4', '5'])\n",
      "#10(,-11.500147819519043): select(@param0, ['2'])\n",
      "#11(,-12.066676139831543): select(@param0, ['1', '2'])\n",
      "#12(,-12.365567207336426): select(@param0, ['3', '4'])\n"
     ]
    }
   ],
   "source": [
    "m_prog, m_example = get_new_program(\n",
    "    m_config, m_interpreter, m_generator,\n",
    ")\n",
    "alist, dlist = TransNeoBeam(m_config, m_spec, m_interpreter, trans_neo, m_example, verbose=True)\n",
    "# visualize\n",
    "print(\"====INPUT====\")\n",
    "print(robjects.r(m_example.input[0]))\n",
    "print(\"====OUTPUT====\")\n",
    "print(robjects.r(m_example.output))\n",
    "print(\"====Original Program====\")\n",
    "print(m_prog)\n",
    "print(\"=====Beam Solutions=====\")\n",
    "for i in range(len(alist)):\n",
    "    is_solved = None\n",
    "    if alist[i][1].check_eq() is not None:\n",
    "        # solved\n",
    "        is_solved = True\n",
    "    else:\n",
    "        is_solved = False\n",
    "    tmp_node_id = alist[i][1].get_frontiers()[0]\n",
    "    print(\"#{}({},{}): {}\".format(\n",
    "        i+1, is_solved, alist[i][0], alist[i][1].node_list[tmp_node_id]\n",
    "        # get_frontiers only works for chain execution\n",
    "    ))\n",
    "print(\"=====Dead Solutions=====\")\n",
    "for i in range(len(dlist)):\n",
    "    tmp_node_id = dlist[i][1].get_frontiers()[0]\n",
    "    print(\"#{}(,{}): {}\".format(\n",
    "        i+1, dlist[i][0], dlist[i][1].node_list[tmp_node_id]\n",
    "        # get_frontiers only works for chain execution\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, (69, 1, 2)), (1, (69, 37))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alist[7][1].shells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alist[7][1].check_eq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ApplyNode(spread, [ParamNode(0), AtomNode(2), AtomNode(3)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alist[7][1].node_list[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RET_DF11614'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alist[7][1].node_list[70].ps_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCOL1 OCOL4  OCOL5    -66     5    36     85    96\n",
      "1    29    50  65.15     NA    NA 61.59     NA    NA\n",
      "2    29    56 -20.60 -66.84    NA    NA     NA    NA\n",
      "3    29    56  49.19     NA 27.93    NA     NA    NA\n",
      "4    29    94  21.47     NA    NA    NA     NA 72.77\n",
      "5    75    56 -26.65     NA    NA    NA -42.04    NA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(robjects.r(\"RET_DF11614\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCOL1  OCOL3  OCOL5 -66  5 COL179001 COL179002 85 96\n",
      "1    29 -66.84 -20.60  56 NA      <NA>      <NA> NA NA\n",
      "2    29  27.93  49.19  NA 56      <NA>      <NA> NA NA\n",
      "3    29  61.59  65.15  NA NA        50      <NA> NA NA\n",
      "4    29  72.77  21.47  NA NA      <NA>      <NA> NA 94\n",
      "5    75 -42.04 -26.65  NA NA      <NA>      <NA> 56 NA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(robjects.r(\"RET_DF11599\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "  sorted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(robjects.r(\"\"\"\n",
    "tmp1 <- sapply(RET_DF11614, as.character)\n",
    "tmp2 <- sapply(RET_DF11599, as.character)\n",
    "compare(tmp1,tmp2, ignoreOrder=TRUE)\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     OCOL1 OCOL4 OCOL5    -66      5       36      85       96     \n",
      "[1,] \"29\"  \"50\"  \"65.15\"  NA       NA      \"61.59\" NA       NA     \n",
      "[2,] \"29\"  \"56\"  \"-20.6\"  \"-66.84\" NA      NA      NA       NA     \n",
      "[3,] \"29\"  \"56\"  \"49.19\"  NA       \"27.93\" NA      NA       NA     \n",
      "[4,] \"29\"  \"94\"  \"21.47\"  NA       NA      NA      NA       \"72.77\"\n",
      "[5,] \"75\"  \"56\"  \"-26.65\" NA       NA      NA      \"-42.04\" NA     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(robjects.r(\"tmp1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     OCOL1 OCOL3    OCOL5    -66  5    COL179001 COL179002 85   96  \n",
      "[1,] \"29\"  \"-66.84\" \"-20.6\"  \"56\" NA   NA        NA        NA   NA  \n",
      "[2,] \"29\"  \"27.93\"  \"49.19\"  NA   \"56\" NA        NA        NA   NA  \n",
      "[3,] \"29\"  \"61.59\"  \"65.15\"  NA   NA   \"50\"      NA        NA   NA  \n",
      "[4,] \"29\"  \"72.77\"  \"21.47\"  NA   NA   NA        NA        NA   \"94\"\n",
      "[5,] \"75\"  \"-42.04\" \"-26.65\" NA   NA   NA        NA        \"56\" NA  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(robjects.r(\"tmp2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_interpreter.equal(\"RET_DF11614\",\"RET_DF11599\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RET_DF11599'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alist[7][1].output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
