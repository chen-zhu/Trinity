{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaNeo Cambrian Version\n",
    "\n",
    "```\n",
    "tensorboard --logdir runs\n",
    "```\n",
    "\n",
    "```\n",
    "cd ./Trinity/\n",
    "python ./AlphaNeo_Cambrian_pworker.py 1\n",
    "```\n",
    "\n",
    "```\n",
    "nohup jupyter lab > jupyter.log &\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG_VAR = None\n",
    "DBG_SEXP = None\n",
    "DBG_POST = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import fcntl\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.interpreter import Interpreter, PostOrderInterpreter, GeneralError, InterpreterError\n",
    "from tyrell.enumerator import Enumerator, SmtEnumerator, RandomEnumerator, DesignatedEnumerator, RandomEnumeratorS, ExhaustiveEnumerator\n",
    "from tyrell.decider import Example, ExampleConstraintPruningDecider, ExampleDecider, TestDecider\n",
    "from tyrell.synthesizer import Synthesizer\n",
    "from tyrell.logger import get_logger\n",
    "from sexpdata import Symbol\n",
    "from tyrell import dsl as D\n",
    "from typing import Callable, NamedTuple, List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: False\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "import dill as pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morpheus Version\n",
    "from utils_morpheus import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListModule(object):\n",
    "    def __init__(self, module, prefix, *args):\n",
    "        self.module = module\n",
    "        self.prefix = prefix\n",
    "        self.num_module = 0\n",
    "        for new_module in args:\n",
    "            self.append(new_module)\n",
    "    \n",
    "    def append(self, new_module):\n",
    "        if not isinstance(new_module, nn.Module):\n",
    "            raise ValueError('Not a Module')\n",
    "        else:\n",
    "            self.module.add_module(self.prefix + str(self.num_module), new_module)\n",
    "            self.num_module += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.num_module\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i<0 or i>=self.num_module:\n",
    "            raise IndexError('Out of bound')\n",
    "        return getattr(self.module, self.prefix+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(AlphaNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        # abstraction token embedding\n",
    "        self.vocab_size = self.config[\"embd_vocab_size\"]\n",
    "        self.embd_dim = self.config[\"embd_dim\"]\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embd_dim,\n",
    "            self.config['IDX_PAD'],\n",
    "        )\n",
    "        \n",
    "        # special 1d kernels, kernel sizes will always be 1\n",
    "        self.n_kernel = self.config[\"conv_n_kernel\"]\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels = self.config[\"embd_dim\"],\n",
    "            out_channels = self.n_kernel,\n",
    "            kernel_size = self.config[\"conv_kernel_size\"],\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = self.config[\"pool_kernel_size\"],\n",
    "            padding = self.config[\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTMCell(\n",
    "            input_size = self.config[\"lstm_input_size\"],\n",
    "            hidden_size = self.config[\"lstm_hidden_size\"],\n",
    "            bias=True,\n",
    "        )\n",
    "        \n",
    "        self.fcs = ListModule(self, \"fc_\")\n",
    "        self.fcs.append(\n",
    "            nn.Linear(self.config[\"lstm_hidden_size\"], self.config[\"fcs\"][0])\n",
    "        )\n",
    "        for i in range(1,len(self.config[\"fcs\"])):\n",
    "            self.fcs.append(\n",
    "                nn.Linear(self.config[\"fcs\"][i-1], self.config[\"fcs\"][i])\n",
    "            )\n",
    "    \n",
    "    '''\n",
    "    single batch behavior, no batch dim expected\n",
    "    '''\n",
    "    def forward(self, p1, hc=None):\n",
    "        # p1: (1, col, row) %=% (1, dim, maxlen)\n",
    "        # hc: previous hidden state, if None, start a new sequence\n",
    "        \n",
    "        d_embd = self.embedding(p1) # (1, nrow, ncol) -> (1, nrow, ncol, dim)\n",
    "        d_embd = d_embd.permute(0,3,1,2) # (1, dim, nrow, ncol), fit the conv\n",
    "        \n",
    "        d_conv = F.relu(self.conv(d_embd)) # (1, dim, nrow, ncol) -> (1, n_kernel, nrow, 1)\n",
    "        d_pool = self.pool(d_conv) # (1, n_kernel, nrow, 1) -> (1, n_kernel, 1, 1)\n",
    "        d_known = d_pool.view(1,-1) # (1, n_kernel)\n",
    "        \n",
    "#         print(\"====SHAPE INFOR====\")\n",
    "#         print(\"embd:{}\".format(d_embd.shape))\n",
    "#         print(\"conv:{}\".format(d_conv.shape))\n",
    "#         print(\"pool:{}\".format(d_pool.shape))\n",
    "#         print(\"known:{}\".format(d_known.shape))\n",
    "        \n",
    "        if hc is None:\n",
    "            hc = self.init_hidden()\n",
    "        \n",
    "        h_t, c_t = self.lstm(d_known, hc)\n",
    "        \n",
    "        tmp1 = h_t\n",
    "        for i in range(len(self.fcs)-1):\n",
    "            tmp1 = F.relu(self.fcs[i](tmp1))\n",
    "        \n",
    "        # (1, #production_rules)\n",
    "        tmp1 = F.log_softmax(self.fcs[len(self.fcs)-1](tmp1), dim=1)\n",
    "        \n",
    "        # hidden states can be reused\n",
    "        return tmp1, (h_t,c_t)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        if use_cuda:\n",
    "            return (torch.zeros(1,self.config[\"lstm_hidden_size\"]).cuda(),\n",
    "                    torch.zeros(1,self.config[\"lstm_hidden_size\"]).cuda())\n",
    "        else:\n",
    "            return (torch.zeros(1,self.config[\"lstm_hidden_size\"]),\n",
    "                    torch.zeros(1,self.config[\"lstm_hidden_size\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlphaNeoTrainer(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer):\n",
    "    global DBG_VAR, DBG_SEXP, DBG_POST\n",
    "    reward_list = []\n",
    "    n_batch = 1\n",
    "    batch_loss = 0.\n",
    "    c_nth = 0\n",
    "    \n",
    "    # #### mp #### #\n",
    "    for ii in [1,2,3]:\n",
    "        data_path = \"./pworker_storage/data_{}.pkl\".format(ii)\n",
    "        Path(data_path).touch()\n",
    "    external_data = []\n",
    "    # iterator\n",
    "    iter_external_data = iter(external_data)\n",
    "    need_reload = True\n",
    "    # #### mp #### #\n",
    "    \n",
    "    total_ac = {1:0,2:0,3:0}\n",
    "    total_sp = {1:0,2:0,3:0}\n",
    "    # one program each step\n",
    "    for d_step in range(p_config[\"n_steps\"]):\n",
    "        p_model.train()\n",
    "        \n",
    "        # #### mp #### #\n",
    "        if need_reload:\n",
    "            for ii in [1,2,3]:\n",
    "                data_path = \"./pworker_storage/data_{}.pkl\".format(ii)\n",
    "                # compete once and get some results\n",
    "                f = open(data_path,\"rb+\")\n",
    "                try:\n",
    "                    fcntl.flock(f.fileno(), fcntl.LOCK_EX)\n",
    "                    if os.path.getsize(data_path)>0:\n",
    "                        external_data = pickle.load(f)\n",
    "                        if len(external_data)>0:\n",
    "                            # actually it has data\n",
    "                            f.seek(0)\n",
    "                            pickle.dump([],f)\n",
    "                            iter_external_data = iter(external_data)\n",
    "                            need_reload = False\n",
    "                except IOError as e:\n",
    "                    if e.errno != errno.EAGAIN:\n",
    "                        # unrelated errors\n",
    "                        raise\n",
    "                    else:\n",
    "                        # fail once, move on generate by itself\n",
    "                        pass\n",
    "                f.close()\n",
    "                if not need_reload:\n",
    "                    break\n",
    "        # #### mp #### #\n",
    "        \n",
    "        try:\n",
    "            p_prog, str_example = next(iter_external_data)\n",
    "            # Morpheus ONLY: convert str_example to p_example\n",
    "            # assign new names\n",
    "            p_example = Example(\n",
    "                input=[get_fresh_name() for p in str_example.input],\n",
    "                output=get_fresh_name(),\n",
    "            )\n",
    "            # load the value into new names in R environment\n",
    "            for i in range(len(p_example.input)):\n",
    "                p_interpreter.load_data_into_var(\n",
    "                    str_example.input[i], # data\n",
    "                    p_example.input[i], # var name\n",
    "                )\n",
    "            p_interpreter.load_data_into_var(\n",
    "                str_example.output,\n",
    "                p_example.output,\n",
    "            )\n",
    "        except StopIteration:\n",
    "            need_reload = True\n",
    "            # run out of sample, generate one \n",
    "            while True:\n",
    "                p_input = p_interpreter.random_table()\n",
    "                p_prog, p_example = p_generator.generate(\n",
    "                    fixed_depth=p_config[\"max_depth\"],\n",
    "                    example=Example(input=[p_input], output=None),\n",
    "                )\n",
    "                # make sure at least one function call\n",
    "                if p_prog is not None and p_prog.is_apply():\n",
    "                    break\n",
    "                \n",
    "        # construct the full program\n",
    "        ps_full = ProgramSpaceChainOneNB(\n",
    "            p_spec, p_interpreter, eq_r, p_example.input, p_example.output,\n",
    "        )\n",
    "        p_prog_list = ps_full.get_prog_list(p_prog)\n",
    "        for p in p_prog_list:\n",
    "            ps_full.add_sexp(p.to_sexp())\n",
    "        total_sp[len(ps_full.prog_list)] += 1\n",
    "        # start from the first state\n",
    "        ps_current = ProgramSpaceChainOneNB(\n",
    "            p_spec, p_interpreter, eq_r, p_example.input, p_example.output,\n",
    "        )\n",
    "        d_reward = None\n",
    "        selected_edges = []\n",
    "        \n",
    "        # if true, the problem turns into supervised problem\n",
    "        if random.random()<=p_config[\"hint_rate\"](d_step,len(ps_full.prog_list)):\n",
    "            need_hints = True\n",
    "        else:\n",
    "            need_hints = False\n",
    "            \n",
    "\n",
    "        # roll till the ending condition\n",
    "        hc_t = None\n",
    "        while True:\n",
    "            outv_current = ps_current.get_frontier()\n",
    "            # generate dense rep for known nodes\n",
    "            # d_vertex = morpheus_abstraction(outv_current[0])\n",
    "            # generate dense rep for target\n",
    "            # d_target = morpheus_abstraction(ps_current.output)\n",
    "            \n",
    "            d_feat = camb_get_features(outv_current[0], ps_current.output)\n",
    "            # d_feat = morpheus_select_cmm(outv_current[0], ps_current.output)\n",
    "            \n",
    "\n",
    "            if use_cuda:\n",
    "                # td_vertex = Variable(torch.FloatTensor( [d_vertex] )).cuda()\n",
    "                # td_target = Variable(torch.FloatTensor( [d_target] )).cuda()\n",
    "                td_feat = Variable(torch.LongTensor( [d_feat] )).cuda()\n",
    "            else:\n",
    "                # td_vertex = Variable(torch.FloatTensor( [d_vertex] ))\n",
    "                # td_target = Variable(torch.FloatTensor( [d_target] ))\n",
    "                td_feat = Variable(torch.LongTensor( [d_feat] ))\n",
    "                                     \n",
    "            # (1, LIST_PAD_LENGTH+#production_rules)\n",
    "            td_output, hc_t = p_model(td_feat, hc_t)\n",
    "            # td_output = p_model(td_feat)\n",
    "            cnd_list = ps_full.shell_list\n",
    "\n",
    "            DBG_VAR = [ps_full, ps_current]\n",
    "            if need_hints:\n",
    "                # just assign the correct solution\n",
    "                selected_id = ps_full.str_shell_dict[\n",
    "                    str(ps_full.prog_list[len(ps_current.prog_list)])\n",
    "                ]\n",
    "            else:\n",
    "                if random.random()<=p_config[\"exploration_rate\"](d_step):\n",
    "                    # exploration\n",
    "                    selected_id = random.choice(range(len(cnd_list)))\n",
    "                else:\n",
    "                    # exploitation\n",
    "                    selected_id = torch.multinomial(td_output.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "            # keep track of selected edges\n",
    "            selected_edges.append(td_output[0, selected_id])\n",
    "            # add selected edges and fill\n",
    "            ret = ps_current.add_sexp(ps_current.shell_list[selected_id].to_sexp())\n",
    "            # debug info\n",
    "            DBG_SEXP = ps_current.shell_list[selected_id].to_sexp()\n",
    "            DBG_POST = ps_current\n",
    "            \n",
    "            if ret==False:\n",
    "                # failed\n",
    "                d_reward = -0.1\n",
    "                hc_t = None # cut off sequence\n",
    "                break\n",
    "            else:\n",
    "                # #### disabled temporarily #### #\n",
    "                # #### should be used together with sanity_check, but now the outv from generator may not pass outv_check #### #\n",
    "                # outv check!! can terminate early\n",
    "                # outv_post = ps_current.get_frontier()\n",
    "                # if not p_interpreter.outv_check(outv_post[0]):\n",
    "                    # fail the check\n",
    "                    # d_reward = 0.\n",
    "                    # hc_t = None\n",
    "                    # break\n",
    "                # succeeded\n",
    "                if ps_current.out_eq():\n",
    "                    # solved in depth less than or equal to max_depth\n",
    "                    d_reward = 1.\n",
    "                    total_ac[len(ps_current.prog_list)] += 1\n",
    "                    hc_t = None # cut off sequence\n",
    "                    break\n",
    "                # NOTICE: Trinity depth is # of layers of nodes, AlphaNeo depth is # of edges (height)\n",
    "                elif len(ps_current.prog_list)>=p_config[\"max_depth\"]-1:\n",
    "                    d_reward = -0.1\n",
    "                    hc_t = None # cut off sequence\n",
    "                    break\n",
    "                    \n",
    "        \n",
    "        # finally compute the loss\n",
    "        d_loss = 0.\n",
    "        ns = len(selected_edges)\n",
    "        for i in range(ns):\n",
    "            d_decay = p_config[\"gamma\"]**(ns-1-i)\n",
    "            # should negate the log probabilities\n",
    "            d_loss += d_decay*d_reward*(-selected_edges[i])\n",
    "\n",
    "        reward_list.append(d_reward)\n",
    "        batch_loss += d_loss\n",
    "\n",
    "        print(\"\\r# STEP{}, from:{}, size:c{}/f{}, reward:{:.4f}, avg.reward:{:.4f}, ac/sp: 1->{}/{}, 2->{}/{}, 3->{}/{}\".format(\n",
    "            d_step, \"gen\" if need_reload else \"load\",\n",
    "            len(ps_current.prog_list), len(ps_full.prog_list), d_reward, sum(reward_list)/len(reward_list),\n",
    "            total_ac[1], total_sp[1], total_ac[2], total_sp[2], total_ac[3], total_sp[3],\n",
    "        ), end=\"\")\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\n",
    "                'avg.reward/step',\n",
    "                sum(reward_list)/len(reward_list),\n",
    "                d_step,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        c_nth += 1\n",
    "        if c_nth%n_batch==0:\n",
    "            c_nth = 0\n",
    "            # perform gradient in every batch\n",
    "            batch_loss.backward()\n",
    "            p_optim.step()\n",
    "            p_optim.zero_grad()\n",
    "            batch_loss = 0.\n",
    "            \n",
    "#         if d_step%10000==0:\n",
    "#             torch.save(p_model.state_dict(), \"./saved_models/0610_RL1_AlphaNeo_mChainOneNB_ep{}.pt\".format(d_step))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb1.tyrell')\n",
    "m_eq = eq_r\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    "    sfn=m_interpreter.sanity_check,\n",
    ")\n",
    "m_ps = ProgramSpaceChainOneNB(\n",
    "    m_spec, m_interpreter, m_eq, None, None,\n",
    ")\n",
    "# m_config = {\n",
    "#     'embd_vocab_size': len(CAMB_LIST),\n",
    "#     'embd_dim': 10,\n",
    "#     'conv_n_kernel': 100,\n",
    "#     'conv_kernel_size': (1,CAMB_NCOL),\n",
    "#     'pool_kernel_size': (CAMB_NROW+1,1), # +1 for column names\n",
    "#     'IDX_PAD': 0, \n",
    "#     'n_steps': 10000000,\n",
    "#     'gamma': 0.618,\n",
    "#     'exploration_rate': lambda x:0.9-0.8*(min(1, x/2500)),\n",
    "#     'hint_rate': lambda x,n:{1:0.8}[n]*(1-(min(0.8, x/2500))),\n",
    "#     'max_depth': 2,\n",
    "# }\n",
    "m_config = {\n",
    "    'embd_vocab_size': len(CAMB_LIST),\n",
    "    'embd_dim': 10,\n",
    "    'conv_n_kernel': 100,\n",
    "    'conv_kernel_size': (1,CAMB_NCOL),\n",
    "    'pool_kernel_size': (2*(CAMB_NROW+1),1), # a:1, b:nrow, c:1, d:nrow\n",
    "#     'pool_kernel_size': (CAMB_NROW+1,1), # a:1, b:nrow, c:1, d:nrow\n",
    "    'IDX_PAD': 0, \n",
    "    'n_steps': 10000000,\n",
    "    'gamma': 0.618,\n",
    "    'exploration_rate': lambda x:0.9-0.8*(min(1, x/2500)),\n",
    "    'hint_rate': lambda x,n:{1:0.8,2:0.8}[n]*(1-(min(0.8, x/2500))),\n",
    "    'max_depth': 3,\n",
    "}\n",
    "m_config[\"lstm_input_size\"] = m_config[\"conv_n_kernel\"]\n",
    "m_config[\"lstm_hidden_size\"] = m_config[\"conv_n_kernel\"]\n",
    "m_config[\"fcs\"] = [\n",
    "    len(m_ps.shell_list),\n",
    "]\n",
    "\n",
    "alpha_neo = AlphaNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    alpha_neo = alpha_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(alpha_neo.parameters()))\n",
    "writer = SummaryWriter(\"runs/0623CAMB_RL2LSTM_camb1\")\n",
    "# writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_ps.shell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# STEP24090, from:load, size:c2/f1, reward:1.0000, avg.reward:0.7254, ac/sp: 1->225/1, 2->17853/24090, 3->0/0Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-17afb9992d47>\", line 1, in <module>\n",
      "    AlphaNeoTrainer(m_config, m_spec, m_interpreter, m_generator, alpha_neo, optimizer, writer)\n",
      "  File \"<ipython-input-10-c4c5dea3c0c8>\", line 64, in AlphaNeoTrainer\n",
      "    p_example.input[i], # var name\n",
      "  File \"/home/ju-ucsb/Trinity/utils_morpheus.py\", line 182, in load_data_into_var\n",
      "    robjects.r(\"{} <- {}\".format(pvar,pdata))\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 388, in __call__\n",
      "    p = _rparse(text=StrSexpVector((string,)))\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/conversion.py\", line 30, in _\n",
      "    return _cdata_to_rinterface(cdata)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/conversion.py\", line 17, in _cdata_to_rinterface\n",
      "    scaps = _rinterface.SexpCapsule(cdata)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\", line 96, in __init__\n",
      "    assert is_cdata_sexp(cdata)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\", line 43, in is_cdata_sexp\n",
      "    ffi.typeof(obj).cname == 'struct SEXPREC *'):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 735, in getmodule\n",
      "    if f == _filesbymodname.get(modname, None):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "AlphaNeoTrainer(m_config, m_spec, m_interpreter, m_generator, alpha_neo, optimizer, writer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
