{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PolyNeo\n",
    "- Introducing a poly policy for fast adaptation\n",
    "- Stage: Cambrian\n",
    "- Version: Inaria\n",
    "- Update Logs\n",
    "    - 0713: with DeepPath style rollback at training\n",
    "    - 0716: new learning paradigm, see memo for details\n",
    "    - 0724: poly structure to fit fast online adaptation\n",
    "\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListModule(object):\n",
    "    def __init__(self, module, prefix, *args):\n",
    "        self.module = module\n",
    "        self.prefix = prefix\n",
    "        self.num_module = 0\n",
    "        for new_module in args:\n",
    "            self.append(new_module)\n",
    "    \n",
    "    def append(self, new_module):\n",
    "        if not isinstance(new_module, nn.Module):\n",
    "            raise ValueError('Not a Module')\n",
    "        else:\n",
    "            self.module.add_module(self.prefix + str(self.num_module), new_module)\n",
    "            self.num_module += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.num_module\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i<0 or i>=self.num_module:\n",
    "            raise IndexError('Out of bound')\n",
    "        return getattr(self.module, self.prefix+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueEncoder(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(ValueEncoder, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.vocab_size = self.config[\"val\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"val\"][\"embd_dim\"]\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embd_dim,\n",
    "            self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels = self.config[\"val\"][\"embd_dim\"],\n",
    "            out_channels = self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            kernel_size = self.config[\"val\"][\"conv_kernel_size\"],\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = self.config[\"val\"][\"pool_kernel_size\"],\n",
    "            padding = self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            self.config[\"embd_dim\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, bp_map):\n",
    "        # batched maps, (B, map_r, map_c)\n",
    "        # in this version, every value only contains 1 map\n",
    "        B = bp_map.shape[0]\n",
    "        \n",
    "        # (B, map_r, map_c, val_embd_dim) -> (B, val_embd_dim, map_r, map_c)\n",
    "        d_embd = self.embedding(bp_map).permute(0,3,1,2)\n",
    "        \n",
    "        # (B, n_kernel, map_r, 1)\n",
    "        d_conv = F.relu(self.conv(d_embd))\n",
    "        \n",
    "        # (B, n_kernel)\n",
    "        d_pool = self.pool(d_conv).view(B,self.config[\"val\"][\"conv_n_kernels\"])\n",
    "        \n",
    "        # (B, embd_dim)\n",
    "        d_out = F.relu(\n",
    "            self.fc(d_pool)\n",
    "        )\n",
    "        \n",
    "        return d_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(PolyNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.value_encoder = ValueEncoder(self.config)\n",
    "        self.fn_embedding = nn.Embedding(\n",
    "            self.config[\"fn\"][\"vocab_size\"]+1, # +1 for pad\n",
    "            self.config[\"embd_dim\"],\n",
    "            padding_idx=self.config[\"fn\"][\"vocab_size\"], # NOTICE: use +1 as padding\n",
    "        )\n",
    "        self.core_policy = nn.Linear(\n",
    "            self.config[\"embd_dim\"],\n",
    "            self.config[\"fn\"][\"vocab_size\"],\n",
    "        )\n",
    "        self.poly_policy = nn.Linear(\n",
    "            self.config[\"fn\"][\"vocab_size\"] + \\\n",
    "            (self.config[\"adaptation\"][\"maxn_step\"]-1) * self.config[\"embd_dim\"],\n",
    "            self.config[\"fn\"][\"vocab_size\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, p_mapin, p_mapout, p_fns):\n",
    "        # p_mapin/p_mapout: (B=1, map_r, map_c)\n",
    "        # p_fns: (B=1, #f_called)\n",
    "        # p_poly: int, step/#f_called\n",
    "        B = p_mapin.shape[0]\n",
    "        \n",
    "        v_in = self.value_encoder(p_mapin)\n",
    "        v_out= self.value_encoder(p_mapout)\n",
    "        v_delta = v_out-v_in # (B=1, embd_dim)\n",
    "        v_core = F.relu(\n",
    "            self.core_policy(\n",
    "                v_delta,\n",
    "            )\n",
    "        ) # (B=1, fn_vocab_size)\n",
    "        \n",
    "        v_fns = self.fn_embedding(p_fns) # (B=1, maxn_step, embd_dim)\n",
    "        vi_fns = v_fns.view(B, -1) # (B=1, maxn_step*embd_dim)\n",
    "        \n",
    "        v_po = torch.cat([v_core,vi_fns],dim=1)\n",
    "        # (B=1, fn_vocab_size+maxn_step*embd_dim)\n",
    "        \n",
    "        v_pred = self.poly_policy(\n",
    "            v_po,\n",
    "        )\n",
    "        # (B=1, fn_vocab_size)\n",
    "        \n",
    "        # didn't apply any activation\n",
    "        return F.log_softmax(\n",
    "            v_pred, dim=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "meta-train the agent in a supervised way\n",
    "epoch -> episode, one attempt with hint\n",
    "NOTICE: only valid for size 1 training\n",
    "'''\n",
    "def Pretrain(p_config, p_spec, p_interpreter, p_model, p_data, p_optim, p_writer):\n",
    "    print(\"# Start Pretraining...\")\n",
    "    for d_epoch in range(p_config[\"pretrain\"][\"n_epoch\"]):\n",
    "        p_model.train()\n",
    "        \n",
    "        epoch_loss_list = []\n",
    "        batch_loss_list = []\n",
    "        random.shuffle(p_data)\n",
    "        train_data = p_data[:p_config[\"pretrain\"][\"n_truncated\"]]\n",
    "        \n",
    "        for d_ind in range(len(train_data)):\n",
    "            print(\"\\r# epoch:{}, index:{}/{}, avg.loss:{:.2f}\".format(\n",
    "                d_epoch, d_ind, len(train_data),\n",
    "                sum(epoch_loss_list)/len(epoch_loss_list)\n",
    "                if len(epoch_loss_list)>0 else 0,\n",
    "            ),end=\"\")\n",
    "            d_prog, dstr_example = train_data[d_ind]\n",
    "            d_example = Example(\n",
    "                input=[\n",
    "                    p_interpreter.load_data_into_var(p)\n",
    "                    for p in dstr_example.input\n",
    "                ],\n",
    "                output=p_interpreter.load_data_into_var(\n",
    "                    dstr_example.output\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # initialize a solution\n",
    "            ps_solution = ProgramSpace(\n",
    "                p_spec, p_interpreter, d_example.input, d_example.output,\n",
    "            )\n",
    "            ps_solution.init_by_prog(d_prog) # this constructs a solution for this problem\n",
    "            \n",
    "            # initialize a new ProgramSpace\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, d_example.input, d_example.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "            \n",
    "            id_current = ps_current.get_strict_frontiers()[0]\n",
    "            # make current shell list\n",
    "            current_shell_list = [\n",
    "                modify_shell(template_list[i],-1,id_current)\n",
    "                for i in range(len(template_list))\n",
    "            ]\n",
    "            \n",
    "            var_input = ps_current.inputs[0]\n",
    "            var_output = ps_current.output\n",
    "            map_input = p_interpreter.camb_get_abs(var_input)\n",
    "            map_output = p_interpreter.camb_get_abs(var_output)\n",
    "            # wrap in B=1\n",
    "            if use_cuda:\n",
    "                td_input = Variable(torch.tensor([map_input],dtype=torch.long)).cuda()\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.long)).cuda()\n",
    "                td_fns = Variable(torch.tensor([\n",
    "                    [p_config[\"fn\"][\"vocab_size\"]\n",
    "                     for _ in range(p_config[\"adaptation\"][\"maxn_step\"]-1)]\n",
    "                ],dtype=torch.long)).cuda()\n",
    "            else:\n",
    "                td_input = Variable(torch.tensor([map_input],dtype=torch.long))\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.long))\n",
    "                td_fns = Variable(torch.tensor([\n",
    "                    [p_config[\"fn\"][\"vocab_size\"]\n",
    "                     for _ in range(p_config[\"adaptation\"][\"maxn_step\"]-1)]\n",
    "                ],dtype=torch.long))\n",
    "\n",
    "            # (B=1, fn_vocab_size)\n",
    "            td_pred = p_model(td_input, td_output, td_fns)\n",
    "            # directly give the hint / supervised, ps.solution.shell[0] works for 1\n",
    "            tmp_id = current_shell_list.index(ps_solution.shells[0])\n",
    "            d_loss = (+1)*(-td_pred[0,tmp_id])\n",
    "            batch_loss_list.append(\n",
    "                d_loss, # supervised / always correct with +1 reward\n",
    "            )\n",
    "            epoch_loss_list.append(\n",
    "                d_loss.cpu().data.numpy(),\n",
    "            )\n",
    "            \n",
    "            if len(batch_loss_list)%p_config[\"pretrain\"][\"batch_size\"]==0 or len(batch_loss_list)==len(train_data):\n",
    "                # do back-prop.\n",
    "                if len(batch_loss_list)>0:\n",
    "                    batch_loss = sum(batch_loss_list)/len(batch_loss_list)\n",
    "                    p_optim.zero_grad()\n",
    "                    batch_loss.backward()\n",
    "                    p_optim.step()\n",
    "                # after back-prop., clean up\n",
    "                batch_loss = None\n",
    "                batch_loss_list = []\n",
    "                \n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "meta-test an agent, directly run into testing / online adaptation\n",
    "'''\n",
    "def Adaptation(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer):\n",
    "    print(\"# Start Adaptation...\")\n",
    "    \n",
    "    n_solved = 0 # track the number of solved problem\n",
    "    n_attempt_list = [] # track the number of attempts in every episode\n",
    "    \n",
    "    for d_episode in range(p_config[\"adaptation\"][\"n_episode\"]):\n",
    "        \n",
    "        # retrieve the given meta-trained model for testing\n",
    "        test_model = copy.deepcopy(p_model)\n",
    "        test_model.train()\n",
    "        \n",
    "        # if doing random meta-testing\n",
    "        # then randomly generate a program for testing\n",
    "        ps_solution = p_generator.get_new_chain_program(\n",
    "            p_config[\"adaptation\"][\"fixed_depth\"],\n",
    "        )\n",
    "        # print(\"# Problem: {}\".format(str(ps_solution.node_list[-1])))\n",
    "        \n",
    "        is_solved = False\n",
    "        for d_attempt in range(p_config[\"adaptation\"][\"maxn_attempt\"]):\n",
    "            \n",
    "            attempt_reward = None\n",
    "            \n",
    "            # in every new attempt, initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, ps_solution.inputs, ps_solution.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "            \n",
    "            n_dead = 0\n",
    "            n_sanity = 0\n",
    "            d_step = 0\n",
    "            selected_neurons = []\n",
    "            selected_functions = [\n",
    "                p_config[\"fn\"][\"vocab_size\"]\n",
    "                for _ in range(p_config[\"adaptation\"][\"maxn_step\"]-1)\n",
    "            ]\n",
    "            \n",
    "            var_input = ps_current.inputs[0]\n",
    "            var_output = ps_current.output\n",
    "            map_input = p_interpreter.camb_get_abs(var_input)\n",
    "            map_output = p_interpreter.camb_get_abs(var_output)\n",
    "            # wrap in B=1\n",
    "            if use_cuda:\n",
    "                td_input = Variable(torch.tensor([map_input],dtype=torch.long)).cuda()\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.long)).cuda()\n",
    "            else:\n",
    "                td_input = Variable(torch.tensor([map_input],dtype=torch.long))\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.long))\n",
    "            \n",
    "            while d_step<p_config[\"adaptation\"][\"maxn_step\"]:\n",
    "                \n",
    "                # print the training progress\n",
    "                print(\"\\r# AC/EP:{}/{}, AT:{}, SP:{}, ND:{}, NS:{}, avg.attempt:{:.2f}\".format(\n",
    "                    n_solved, d_episode, d_attempt, d_step,\n",
    "                    n_dead, n_sanity,\n",
    "                    sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else -1,\n",
    "                ),end=\"\")\n",
    "                \n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                id_current = ps_current.get_strict_frontiers()[0]\n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                \n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_fns = Variable(torch.tensor([selected_functions],dtype=torch.long)).cuda()\n",
    "                else:\n",
    "                    td_fns = Variable(torch.tensor([selected_functions],dtype=torch.long))\n",
    "                    \n",
    "                # (B=1, fn_vocab_size)\n",
    "                td_pred = test_model(td_input, td_output, td_fns)\n",
    "                \n",
    "                # no hints\n",
    "                if random.random()<=p_config[\"adaptation\"][\"exploration_rate\"]:\n",
    "                    # exploration\n",
    "                    tmp_id = random.choice(range(len(current_shell_list)))\n",
    "                else:\n",
    "                    # exploitation\n",
    "                    tmp_id = torch.multinomial(td_pred.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "                \n",
    "                # update ps_current\n",
    "                ps_backup = ps_current.make_copy() # supports undo for failed sanity_check\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if update_status:\n",
    "                    \n",
    "                    # succeed\n",
    "                    if ps_current.check_eq() is not None:\n",
    "                        # and solved!\n",
    "                        d_step += 1\n",
    "                        is_solved = True\n",
    "                        n_solved += 1\n",
    "                        attempt_reward = 1. # useless, but still attach it\n",
    "                        break\n",
    "                    else:\n",
    "                        # do sanity check\n",
    "                        check_current = p_interpreter.sanity_check(ps_current)\n",
    "                        if check_current[0]:\n",
    "                            d_step += 1\n",
    "                            selected_neurons.append(td_pred[0,tmp_id])\n",
    "                            selected_functions.append(tmp_id)\n",
    "                            selected_functions = selected_functions[1:]\n",
    "                            attempt_reward = -1. # this is temporal, may change later\n",
    "                            continue\n",
    "                        else:\n",
    "                            # Inaria: fail the sanity check, bp immediately and restart the same step\n",
    "                            dead_loss = (-1.)*td_pred[0,tmp_id]\n",
    "                            p_optim.zero_grad()\n",
    "                            dead_loss.backward()\n",
    "                            p_optim.step()\n",
    "                            dead_loss = None\n",
    "                            \n",
    "                            # between this, undo the ProgramSpace\n",
    "                            ps_current = ps_backup\n",
    "                            \n",
    "                            n_sanity += 1\n",
    "                            if n_sanity>=p_config[\"adaptation\"][\"maxn_sanity\"]:\n",
    "                                # reach the limit, perhaps all are dead, restart the attempt\n",
    "                                attempt_reward = -0.5\n",
    "                                break\n",
    "                            else:\n",
    "                                continue\n",
    "                            \n",
    "                else:\n",
    "                    # Inaria: fail, back prop **immediately** and restart the **same step**\n",
    "                    dead_loss = (-1.)*td_pred[0,tmp_id]\n",
    "                    p_optim.zero_grad()\n",
    "                    dead_loss.backward()\n",
    "                    p_optim.step()\n",
    "                    dead_loss = None\n",
    "                    \n",
    "                    n_dead += 1\n",
    "                    if n_dead>=p_config[\"adaptation\"][\"maxn_dead\"]:\n",
    "                        # reach the limit, perhaps all are dead, restart the attempt\n",
    "                        attempt_reward = -0.5\n",
    "                        break\n",
    "                        # and then still need to deal with bp of previous choices\n",
    "                    else:\n",
    "                        continue\n",
    "            \n",
    "            # <END_FOR_STEP>\n",
    "            \n",
    "            \n",
    "            if is_solved:\n",
    "                # already solved in the last attempt, stop\n",
    "                n_attempt_list.append(d_attempt)\n",
    "                # print(\"Solution: {}\".format(ps_current.node_list[-1]))\n",
    "                break\n",
    "            \n",
    "            if len(selected_neurons)>0:\n",
    "                attempt_loss = 0.\n",
    "                # compute the loss (sequential selected)\n",
    "                for i in range(len(selected_neurons)):\n",
    "                    d_decay = p_config[\"adaptation\"][\"decay_rate\"]**(len(selected_neurons)-1-i)\n",
    "                    attempt_loss += d_decay*attempt_reward*(-selected_neurons[i]) \n",
    "                p_optim.zero_grad()\n",
    "                attempt_loss.backward()\n",
    "                p_optim.step()\n",
    "                attepmt_loss = None\n",
    "            # else: do nothing\n",
    "                \n",
    "        # <END_FOR_ATTEMPT>     \n",
    "            \n",
    "    # <END_FOR_EPISODE>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Total Meta-Train Data: 77038\n"
     ]
    }
   ],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    ")\n",
    "\n",
    "# dumb variable to help infer the shells\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")\n",
    "\n",
    "m_config = {\n",
    "    # ==== TransE Setting ==== #\n",
    "    \"val\":{\n",
    "        \"vocab_size\": len(m_interpreter.CAMB_LIST),\n",
    "        \"embd_dim\": 16, # embedding dim of CAMB abstract token\n",
    "        \"conv_n_kernels\": 512,\n",
    "        \"conv_kernel_size\": (1,m_interpreter.CAMB_NCOL), \n",
    "        \"pool_kernel_size\": (m_interpreter.CAMB_NROW,1), \n",
    "        \"IDX_PAD\": 0,\n",
    "    },\n",
    "    \"fn\":{\n",
    "        \"vocab_size\": len(m_ps.get_neighboring_shells())\n",
    "    },\n",
    "    \"embd_dim\": 128,\n",
    "    \"pretrain\":{\n",
    "        \"n_epoch\": 10,\n",
    "        \"batch_size\": 4, # how many indices\n",
    "        \"data_path\": \"./0716MDsize1.pkl\",\n",
    "        \"n_truncated\": 1000,\n",
    "    },\n",
    "    \"adaptation\":{\n",
    "        \"n_episode\": 100000,\n",
    "        \"fixed_depth\": 3,\n",
    "        \"maxn_attempt\": 100,\n",
    "        \"maxn_step\": 2, # program size\n",
    "        \"maxn_dead\": 50,\n",
    "        \"maxn_sanity\": 50,\n",
    "        \"exploration_rate\": 0,\n",
    "        \"decay_rate\": 0.9,\n",
    "    },\n",
    "}\n",
    "\n",
    "# load the size 1 supervised data\n",
    "with open(m_config[\"pretrain\"][\"data_path\"],\"rb\") as f:\n",
    "    dt_data = pickle.load(f)\n",
    "m_data = [\n",
    "    dt_data[dkey][i]\n",
    "    for dkey in dt_data.keys()\n",
    "    for i in range(len(dt_data[dkey]))\n",
    "]\n",
    "print(\"# Total Meta-Train Data: {}\".format(len(m_data)))\n",
    "\n",
    "poly_neo = PolyNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    poly_neo = poly_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(poly_neo.parameters()))\n",
    "\n",
    "# writer = SummaryWriter(\"runs/0713CAMB_RL2_camb3\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val': {'vocab_size': 150,\n",
       "  'embd_dim': 16,\n",
       "  'conv_n_kernels': 512,\n",
       "  'conv_kernel_size': (1, 15),\n",
       "  'pool_kernel_size': (15, 1),\n",
       "  'IDX_PAD': 0},\n",
       " 'fn': {'vocab_size': 120},\n",
       " 'embd_dim': 128,\n",
       " 'pretrain': {'n_epoch': 10,\n",
       "  'batch_size': 4,\n",
       "  'data_path': './0716MDsize1.pkl',\n",
       "  'n_truncated': 1000},\n",
       " 'adaptation': {'n_episode': 100000,\n",
       "  'fixed_depth': 3,\n",
       "  'maxn_attempt': 100,\n",
       "  'maxn_step': 2,\n",
       "  'maxn_dead': 50,\n",
       "  'maxn_sanity': 50,\n",
       "  'exploration_rate': 0,\n",
       "  'decay_rate': 0.9}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start Pretraining...\n",
      "# epoch:0, index:999/1000, avg.loss:4.21\n",
      "# epoch:1, index:999/1000, avg.loss:3.53\n",
      "# epoch:2, index:999/1000, avg.loss:3.05\n",
      "# epoch:3, index:999/1000, avg.loss:2.84\n",
      "# epoch:4, index:999/1000, avg.loss:2.66\n",
      "# epoch:5, index:999/1000, avg.loss:2.68\n",
      "# epoch:6, index:999/1000, avg.loss:2.65\n",
      "# epoch:7, index:999/1000, avg.loss:2.56\n",
      "# epoch:8, index:999/1000, avg.loss:2.51\n",
      "# epoch:9, index:999/1000, avg.loss:2.36\n"
     ]
    }
   ],
   "source": [
    "Pretrain(m_config, m_spec, m_interpreter, poly_neo, m_data, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start Adaptation...\n",
      "# AC/EP:3/13, AT:15, SP:1, ND:7, NS:2, avg.attempt:75.67Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-26b0e17700ab>\", line 1, in <module>\n",
      "    Adaptation(m_config, m_spec, m_interpreter, m_generator, poly_neo, optimizer, writer)\n",
      "  File \"<ipython-input-10-7affcb5bc64f>\", line 100, in Adaptation\n",
      "    current_shell_list[tmp_id]\n",
      "  File \"/home/ju-ucsb/Trinity/ProgramSpace.py\", line 246, in add_neighboring_shell\n",
      "    tmp_outv = self.interpreter.eval(self.node_list[d_nid],self.inputs)\n",
      "  File \"/home/ju-ucsb/Trinity/tyrell/interpreter/post_order.py\", line 62, in eval\n",
      "    return node_visitor.visit_with_context(prog)\n",
      "  File \"/home/ju-ucsb/Trinity/tyrell/interpreter/post_order.py\", line 25, in visit_with_context\n",
      "    res = self.visit(node)\n",
      "  File \"/home/ju-ucsb/Trinity/tyrell/visitor.py\", line 22, in visit\n",
      "    return visitor(node)\n",
      "  File \"/home/ju-ucsb/Trinity/tyrell/interpreter/post_order.py\", line 49, in visit_apply_node\n",
      "    return method(apply_node, in_values)\n",
      "  File \"/home/ju-ucsb/Trinity/MorpheusInterpreter.py\", line 414, in eval_unite\n",
      "    ret_df=ret_df_name, table=args[0], TMP=self.get_fresh_col(args[0],0), col1=str(args[1]), col2=str(args[2]))\n",
      "  File \"/home/ju-ucsb/Trinity/MorpheusInterpreter.py\", line 109, in get_fresh_col\n",
      "    dstr = self.renv(p_obj).r_repr()\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 389, in __call__\n",
      "    res = self.eval(p)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 364, in __getattribute__\n",
      "    return self.__getitem__(attr)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 370, in __getitem__\n",
      "    res = conversion.rpy2py(res)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/functools.py\", line 824, in wrapper\n",
      "    return dispatch(args[0].__class__)(*args, **kw)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 207, in _rpy2py_sexpclosure\n",
      "    return SignatureTranslatedFunction(obj)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\", line 151, in __init__\n",
      "    super(SignatureTranslatedFunction, self).__init__(sexp)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\", line 96, in __init__\n",
      "    hash=rinterface.BoolSexpVector((True, ))\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/conversion.py\", line 28, in _\n",
      "    cdata = function(*args, **kwargs)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface.py\", line 766, in __call__\n",
      "    kwargs.items()))\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\", line 223, in build_rcall\n",
      "    cdata = rmemory.protect(conversion._get_cdata(val))\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/memorymanagement.py\", line 27, in protect\n",
      "    cdata = openrlib.rlib.Rf_protect(cdata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "Adaptation(m_config, m_spec, m_interpreter, m_generator, poly_neo, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
