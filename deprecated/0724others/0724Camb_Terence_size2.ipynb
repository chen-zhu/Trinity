{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PolyNeo\n",
    "- Introducing a poly policy for fast adaptation\n",
    "- Stage: Cambrian\n",
    "- Version: Inaria\n",
    "- Update Logs\n",
    "    - 0713: with DeepPath style rollback at training\n",
    "    - 0716: new learning paradigm, see memo for details\n",
    "    - 0724: poly structure to fit fast online adaptation\n",
    "\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListModule(object):\n",
    "    def __init__(self, module, prefix, *args):\n",
    "        self.module = module\n",
    "        self.prefix = prefix\n",
    "        self.num_module = 0\n",
    "        for new_module in args:\n",
    "            self.append(new_module)\n",
    "    \n",
    "    def append(self, new_module):\n",
    "        if not isinstance(new_module, nn.Module):\n",
    "            raise ValueError('Not a Module')\n",
    "        else:\n",
    "            self.module.add_module(self.prefix + str(self.num_module), new_module)\n",
    "            self.num_module += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.num_module\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i<0 or i>=self.num_module:\n",
    "            raise IndexError('Out of bound')\n",
    "        return getattr(self.module, self.prefix+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueEncoder(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(ValueEncoder, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.vocab_size = self.config[\"val\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"val\"][\"embd_dim\"]\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embd_dim,\n",
    "            self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels = self.config[\"val\"][\"embd_dim\"],\n",
    "            out_channels = self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            kernel_size = self.config[\"val\"][\"conv_kernel_size\"],\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = self.config[\"val\"][\"pool_kernel_size\"],\n",
    "            padding = self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            self.config[\"embd_dim\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, bp_map):\n",
    "        # batched maps, (B, map_r, map_c)\n",
    "        # in this version, every value only contains 1 map\n",
    "        B = bp_map.shape[0]\n",
    "        \n",
    "        # (B, map_r, map_c, val_embd_dim) -> (B, val_embd_dim, map_r, map_c)\n",
    "        d_embd = self.embedding(bp_map).permute(0,3,1,2)\n",
    "        \n",
    "        # (B, n_kernel, map_r, 1)\n",
    "        d_conv = F.relu(self.conv(d_embd))\n",
    "        \n",
    "        # (B, n_kernel)\n",
    "        d_pool = self.pool(d_conv).view(B,self.config[\"val\"][\"conv_n_kernels\"])\n",
    "        \n",
    "        # (B, embd_dim)\n",
    "        d_out = F.relu(\n",
    "            self.fc(d_pool)\n",
    "        )\n",
    "        \n",
    "        return d_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(PolyNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.value_encoders = ListModule(self, \"value_encoders_\")\n",
    "        self.fn_embeddings = ListModule(self, \"fn_embeddings_\")\n",
    "        self.poly_policies = ListModule(self, \"poly_policies_\")\n",
    "        \n",
    "        # construct policies\n",
    "        for i in range(self.config[\"adaptation\"][\"maxn_step\"]):\n",
    "            self.value_encoders.append(\n",
    "                ValueEncoder(self.config)\n",
    "            )\n",
    "            \n",
    "            self.fn_embeddings.append(\n",
    "                nn.Embedding(\n",
    "                    self.config[\"fn\"][\"vocab_size\"],\n",
    "                    self.config[\"embd_dim\"],\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            self.poly_policies.append(\n",
    "                nn.Linear(\n",
    "                    self.config[\"embd_dim\"] + i * self.config[\"embd_dim\"],\n",
    "                    # value distance embedding with embedding(s) of function(s) called\n",
    "                    self.config[\"fn\"][\"vocab_size\"],\n",
    "                )\n",
    "            )\n",
    "        \n",
    "    def forward(self, p_mapin, p_mapout, p_fns, p_poly):\n",
    "        # p_mapin/p_mapout: (B=1, map_r, map_c)\n",
    "        # p_fns: (B=1, #f_called)\n",
    "        # p_poly: int, step/#f_called\n",
    "        B = p_mapin.shape[0]\n",
    "        \n",
    "        v_in = self.value_encoders[p_poly](p_mapin)\n",
    "        v_out= self.value_encoders[p_poly](p_mapout)\n",
    "        v_delta = v_out-v_in # (B=1, embd_dim)\n",
    "        \n",
    "        v_fns = self.fn_embeddings[p_poly](p_fns) # (B=1, #f_called, embd_dim)\n",
    "        vi_fns = v_fns.view(B, -1) # (B=1, #f_called*embd_dim)\n",
    "        \n",
    "        v_pred = self.poly_policies[p_poly](\n",
    "            torch.cat([v_delta,vi_fns],dim=1), # (B=1, embd_dim+#f_called*embd_dim)\n",
    "        ) # (B=1, fn_vocab_size)\n",
    "        \n",
    "        # didn't apply any activation\n",
    "        return F.log_softmax(v_pred ,dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "meta-test an agent, directly run into testing / online adaptation\n",
    "'''\n",
    "def Adaptation(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer):\n",
    "    print(\"# Start Adaptation...\")\n",
    "    \n",
    "    n_solved = 0 # track the number of solved problem\n",
    "    n_attempt_list = [] # track the number of attempts in every episode\n",
    "    \n",
    "    for d_episode in range(p_config[\"adaptation\"][\"n_episode\"]):\n",
    "        \n",
    "        # retrieve the given meta-trained model for testing\n",
    "        test_model = copy.deepcopy(p_model)\n",
    "        test_model.train()\n",
    "        \n",
    "        # if doing random meta-testing\n",
    "        # then randomly generate a program for testing\n",
    "        ps_solution = p_generator.get_new_chain_program(\n",
    "            p_config[\"adaptation\"][\"fixed_depth\"],\n",
    "        )\n",
    "        print(\"# Problem: {}\".format(str(ps_solution.node_list[-1])))\n",
    "        \n",
    "        is_solved = False\n",
    "        for d_attempt in range(p_config[\"adaptation\"][\"maxn_attempt\"]):\n",
    "            \n",
    "            attempt_reward = None\n",
    "            \n",
    "            # in every new attempt, initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, ps_solution.inputs, ps_solution.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "            \n",
    "            n_dead = 0\n",
    "            n_sanity = 0\n",
    "            d_step = 0\n",
    "            selected_neurons = []\n",
    "            selected_functions = []\n",
    "            \n",
    "            var_input = ps_current.inputs[0]\n",
    "            var_output = ps_current.output\n",
    "            map_input = p_interpreter.camb_get_abs(var_input)\n",
    "            map_output = p_interpreter.camb_get_abs(var_output)\n",
    "            # wrap in B=1\n",
    "            if use_cuda:\n",
    "                td_input = Variable(torch.tensor([map_input],dtype=torch.long)).cuda()\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.long)).cuda()\n",
    "            else:\n",
    "                td_input = Variable(torch.tensor([map_input],dtype=torch.long))\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.long))\n",
    "            \n",
    "            while d_step<p_config[\"adaptation\"][\"maxn_step\"]:\n",
    "                \n",
    "                # print the training progress\n",
    "                print(\"\\r# AC/EP:{}/{}, AT:{}, SP:{}, ND:{}, NS:{}, avg.attempt:{:.2f}\".format(\n",
    "                    n_solved, d_episode, d_attempt, d_step,\n",
    "                    n_dead, n_sanity,\n",
    "                    sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else -1,\n",
    "                ),end=\"\")\n",
    "                \n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                id_current = ps_current.get_strict_frontiers()[0]\n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                \n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_fns = Variable(torch.tensor([selected_functions],dtype=torch.long)).cuda()\n",
    "                else:\n",
    "                    td_fns = Variable(torch.tensor([selected_functions],dtype=torch.long))\n",
    "                    \n",
    "                # (B=1, fn_vocab_size)\n",
    "                td_pred = test_model(td_input, td_output, td_fns, d_step)\n",
    "                \n",
    "                # no hints\n",
    "                if random.random()<=p_config[\"adaptation\"][\"exploration_rate\"]:\n",
    "                    # exploration\n",
    "                    tmp_id = random.choice(range(len(current_shell_list)))\n",
    "                else:\n",
    "                    # exploitation\n",
    "                    tmp_id = torch.multinomial(td_pred.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "                \n",
    "                # update ps_current\n",
    "                ps_backup = ps_current.make_copy() # supports undo for failed sanity_check\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if update_status:\n",
    "                    \n",
    "                    # succeed\n",
    "                    if ps_current.check_eq() is not None:\n",
    "                        # and solved!\n",
    "                        d_step += 1\n",
    "                        is_solved = True\n",
    "                        n_solved += 1\n",
    "                        attempt_reward = 1. # useless, but still attach it\n",
    "                        break\n",
    "                    else:\n",
    "                        # do sanity check\n",
    "                        check_current = p_interpreter.sanity_check(ps_current)\n",
    "                        if check_current[0]:\n",
    "                            d_step += 1\n",
    "                            selected_neurons.append(td_pred[0,tmp_id])\n",
    "                            selected_functions.append(tmp_id)\n",
    "                            attempt_reward = -1. # this is temporal, may change later\n",
    "                            continue\n",
    "                        else:\n",
    "                            # Inaria: fail the sanity check, bp immediately and restart the same step\n",
    "                            dead_loss = (-1.)*td_pred[0,tmp_id]\n",
    "                            p_optim.zero_grad()\n",
    "                            dead_loss.backward()\n",
    "                            p_optim.step()\n",
    "                            dead_loss = None\n",
    "                            \n",
    "                            # between this, undo the ProgramSpace\n",
    "                            ps_current = ps_backup\n",
    "                            \n",
    "                            n_sanity += 1\n",
    "                            if n_sanity>=p_config[\"adaptation\"][\"maxn_sanity\"]:\n",
    "                                # reach the limit, perhaps all are dead, restart the attempt\n",
    "                                attempt_reward = -0.5\n",
    "                                break\n",
    "                            else:\n",
    "                                continue\n",
    "                            \n",
    "                else:\n",
    "                    # Inaria: fail, back prop **immediately** and restart the **same step**\n",
    "                    dead_loss = (-1.)*td_pred[0,tmp_id]\n",
    "                    p_optim.zero_grad()\n",
    "                    dead_loss.backward()\n",
    "                    p_optim.step()\n",
    "                    dead_loss = None\n",
    "                    \n",
    "                    n_dead += 1\n",
    "                    if n_dead>=p_config[\"adaptation\"][\"maxn_dead\"]:\n",
    "                        # reach the limit, perhaps all are dead, restart the attempt\n",
    "                        attempt_reward = -0.5\n",
    "                        break\n",
    "                        # and then still need to deal with bp of previous choices\n",
    "                    else:\n",
    "                        continue\n",
    "            \n",
    "            # <END_FOR_STEP>\n",
    "            \n",
    "            if is_solved:\n",
    "                # already solved in the last attempt, stop\n",
    "                n_attempt_list.append(d_attempt)\n",
    "                print()\n",
    "                print(\"Solution: {}\".format(ps_current.node_list[-1]))\n",
    "                print()\n",
    "                break\n",
    "            \n",
    "            if len(selected_neurons)>0:\n",
    "                attempt_loss = 0.\n",
    "                # compute the loss (sequential selected)\n",
    "                for i in range(len(selected_neurons)):\n",
    "                    d_decay = p_config[\"adaptation\"][\"decay_rate\"]**(len(selected_neurons)-1-i)\n",
    "                    attempt_loss += d_decay*attempt_reward*(-selected_neurons[i]) \n",
    "                p_optim.zero_grad()\n",
    "                attempt_loss.backward()\n",
    "                p_optim.step()\n",
    "                attepmt_loss = None\n",
    "            # else: do nothing\n",
    "                \n",
    "        # <END_FOR_ATTEMPT>     \n",
    "            \n",
    "    # <END_FOR_EPISODE>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    ")\n",
    "\n",
    "# dumb variable to help infer the shells\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")\n",
    "\n",
    "m_config = {\n",
    "    # ==== TransE Setting ==== #\n",
    "    \"val\":{\n",
    "        \"vocab_size\": len(m_interpreter.CAMB_LIST),\n",
    "        \"embd_dim\": 16, # embedding dim of CAMB abstract token\n",
    "        \"conv_n_kernels\": 512,\n",
    "        \"conv_kernel_size\": (1,m_interpreter.CAMB_NCOL), \n",
    "        \"pool_kernel_size\": (m_interpreter.CAMB_NROW,1), \n",
    "        \"IDX_PAD\": 0,\n",
    "    },\n",
    "    \"fn\":{\n",
    "        \"vocab_size\": len(m_ps.get_neighboring_shells())\n",
    "    },\n",
    "    \"embd_dim\": 128,\n",
    "    \"adaptation\":{\n",
    "        \"n_episode\": 100000,\n",
    "        \"fixed_depth\": 3,\n",
    "        \"maxn_attempt\": 2000,\n",
    "        \"maxn_step\": 2, # program size\n",
    "        \"maxn_dead\": 50,\n",
    "        \"maxn_sanity\": 50,\n",
    "        \"exploration_rate\": 0,\n",
    "        \"decay_rate\": 0.8,\n",
    "    },\n",
    "}\n",
    "\n",
    "poly_neo = PolyNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    poly_neo = poly_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(poly_neo.parameters()))\n",
    "\n",
    "# writer = SummaryWriter(\"runs/0713CAMB_RL2_camb3\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val': {'vocab_size': 150,\n",
       "  'embd_dim': 16,\n",
       "  'conv_n_kernels': 512,\n",
       "  'conv_kernel_size': (1, 15),\n",
       "  'pool_kernel_size': (15, 1),\n",
       "  'IDX_PAD': 0},\n",
       " 'fn': {'vocab_size': 120},\n",
       " 'embd_dim': 128,\n",
       " 'adaptation': {'n_episode': 100000,\n",
       "  'fixed_depth': 3,\n",
       "  'maxn_attempt': 2000,\n",
       "  'maxn_step': 2,\n",
       "  'maxn_dead': 50,\n",
       "  'maxn_sanity': 50,\n",
       "  'exploration_rate': 0,\n",
       "  'decay_rate': 0.8}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start Adaptation...\n",
      "# Problem: separate(unite(@param0, 3, 1), 1)\n",
      "# AC/EP:0/0, AT:376, SP:1, ND:0, NS:3, avg.attempt:-1.00\n",
      "Solution: separate(unite(@param0, 3, 1), 1)\n",
      "\n",
      "# Problem: unite(gather(@param0, ['1', '5']), 6, 4)\n",
      "# AC/EP:1/1, AT:685, SP:1, ND:5, NS:5, avg.attempt:376.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-26b0e17700ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAdaptation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_interpreter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly_neo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-4db06dce4a5c>\u001b[0m in \u001b[0;36mAdaptation\u001b[0;34m(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mps_backup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps_current\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# supports undo for failed sanity_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 update_status = ps_current.add_neighboring_shell(\n\u001b[0;32m---> 97\u001b[0;31m                     \u001b[0mcurrent_shell_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 )\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/ProgramSpace.py\u001b[0m in \u001b[0;36madd_neighboring_shell\u001b[0;34m(self, d_shell, update_node_data)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupdate_node_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mtmp_outv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_nid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_nid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mps_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_outv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterpreterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/tyrell/interpreter/post_order.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, prog, inputs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mnode_visitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNodeVisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnode_visitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_with_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterpreterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_visitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/tyrell/interpreter/post_order.py\u001b[0m in \u001b[0;36mvisit_with_context\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mvisit_with_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/tyrell/visitor.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmethod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_visit_method_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgeneric_visit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/tyrell/interpreter/post_order.py\u001b[0m in \u001b[0;36mvisit_apply_node\u001b[0;34m(self, apply_node)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mvisit_apply_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mApplyNode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 in_values = [self.visit_with_context(\n\u001b[0;32m---> 44\u001b[0;31m                     x) for x in apply_node.args]\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mmethod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_method_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/tyrell/interpreter/post_order.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mvisit_apply_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mApplyNode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 in_values = [self.visit_with_context(\n\u001b[0;32m---> 44\u001b[0;31m                     x) for x in apply_node.args]\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mmethod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_method_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/tyrell/interpreter/post_order.py\u001b[0m in \u001b[0;36mvisit_with_context\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mvisit_with_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/tyrell/visitor.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmethod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_visit_method_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgeneric_visit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/tyrell/interpreter/post_order.py\u001b[0m in \u001b[0;36mvisit_apply_node\u001b[0;34m(self, apply_node)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 method = getattr(self._interp, method_name,\n\u001b[1;32m     48\u001b[0m                                  self._method_not_found)\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m_method_not_found\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mApplyNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/MorpheusInterpreter.py\u001b[0m in \u001b[0;36meval_unite\u001b[0;34m(self, node, args)\u001b[0m\n\u001b[1;32m    418\u001b[0m                                     \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shadow_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                                     \u001b[0mcol1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m                                     col2=str(args[2])))[0]\n\u001b[0m\u001b[1;32m    421\u001b[0m         shadow_script_0 = '{ret_shadow} <- select({table},{cols})'.format(\n\u001b[1;32m    422\u001b[0m             \u001b[0mret_shadow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shadow_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_df_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStrSexpVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/conversion.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cdata_res_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# TODO: test cdata is of the expected CType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cdata_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m                 openrlib.rlib.R_tryEval(\n\u001b[1;32m    769\u001b[0m                     \u001b[0mcall_r\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m                     \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobalenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sexp__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m                     error_occured))\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_occured\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Adaptation(m_config, m_spec, m_interpreter, m_generator, poly_neo, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
