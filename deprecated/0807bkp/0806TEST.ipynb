{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and parse fake SO benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./0805MDSOsize3.pkl\",\"rb\") as f:\n",
    "    dt_mdso = pickle.load(f)\n",
    "mdso_parsed = []\n",
    "for i in range(len(dt_mdso)):\n",
    "    tmp_str = str(dt_mdso[i][0])\n",
    "    tmp_s = tmp_str.index(\"@\")\n",
    "    tmp_sl = tmp_str[:tmp_s].split(\"(\")[::-1]\n",
    "    tmp_sls = [p for p in tmp_sl if p]\n",
    "    mdso_parsed.append(tmp_sls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['separate', 'gather', 'select']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdso_parsed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and parse ngrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./size3-ngram-camb3.txt\",\"r\") as f:\n",
    "    ngram_raw = f.readlines()\n",
    "ngram_parsed = []\n",
    "for dline in ngram_raw:\n",
    "    ngram_parsed.append(tuple(dline.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gather', 'unite', 'spread')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_parsed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute so-ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "songram_dict = {}\n",
    "for i in range(len(mdso_parsed)):\n",
    "    d_ent = tuple(mdso_parsed[i])\n",
    "    if d_ent not in songram_dict:\n",
    "        songram_dict[d_ent] = 0\n",
    "    songram_dict[d_ent] += 1\n",
    "# sort\n",
    "songram_pair = sorted(songram_dict, key=songram_dict.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('gather', 'unite', 'select'), ('gather', 'spread', 'select'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songram_pair[0], songram_pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songram_dict[('gather', 'unite', 'select')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songram_dict[('gather', 'spread', 'select')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute averaged ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_ngram = []\n",
    "rank_songram = []\n",
    "for p in mdso_parsed:\n",
    "    tp = tuple(p)\n",
    "    rank_ngram.append(ngram_parsed.index(tp))\n",
    "    rank_songram.append(songram_pair.index(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.358695652173912"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rank_ngram)/len(rank_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.108695652173913"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rank_songram)/len(rank_songram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened? Show the distribution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('gather', 'separate', 'gather'): 13,\n",
       " ('gather', 'separate', 'select'): 12,\n",
       " ('gather', 'separate', 'spread'): 1,\n",
       " ('gather', 'separate', 'unite'): 11,\n",
       " ('gather', 'spread', 'select'): 135,\n",
       " ('gather', 'unite', 'select'): 179,\n",
       " ('gather', 'unite', 'spread'): 2,\n",
       " ('separate', 'gather', 'select'): 107}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gather', 'unite', 'spread'),\n",
       " ('gather', 'separate', 'spread'),\n",
       " ('gather', 'separate', 'select'),\n",
       " ('gather', 'spread', 'select'),\n",
       " ('gather', 'select', 'spread'),\n",
       " ('separate', 'spread', 'select'),\n",
       " ('select', 'spread', 'select'),\n",
       " ('unite', 'spread', 'select'),\n",
       " ('select', 'gather', 'select'),\n",
       " ('gather', 'unite', 'select'),\n",
       " ('separate', 'unite', 'spread'),\n",
       " ('unite', 'unite', 'spread'),\n",
       " ('select', 'gather', 'spread'),\n",
       " ('separate', 'gather', 'select'),\n",
       " ('gather', 'separate', 'gather'),\n",
       " ('select', 'unite', 'spread'),\n",
       " ('gather', 'unite', 'unite'),\n",
       " ('separate', 'gather', 'spread'),\n",
       " ('spread', 'select', 'spread'),\n",
       " ('select', 'gather', 'separate'),\n",
       " ('select', 'separate', 'spread'),\n",
       " ('gather', 'separate', 'unite'),\n",
       " ('separate', 'gather', 'separate'),\n",
       " ('separate', 'select', 'spread'),\n",
       " ('select', 'gather', 'unite'),\n",
       " ('gather', 'select', 'gather'),\n",
       " ('gather', 'unite', 'separate'),\n",
       " ('spread', 'gather', 'select'),\n",
       " ('spread', 'unite', 'spread'),\n",
       " ('unite', 'separate', 'spread'),\n",
       " ('separate', 'gather', 'unite'),\n",
       " ('spread', 'gather', 'spread'),\n",
       " ('gather', 'spread', 'gather'),\n",
       " ('spread', 'separate', 'spread'),\n",
       " ('spread', 'gather', 'separate'),\n",
       " ('separate', 'spread', 'gather'),\n",
       " ('select', 'separate', 'select'),\n",
       " ('select', 'spread', 'gather'),\n",
       " ('separate', 'unite', 'select'),\n",
       " ('unite', 'unite', 'select'),\n",
       " ('gather', 'select', 'separate'),\n",
       " ('unite', 'select', 'spread'),\n",
       " ('gather', 'unite', 'gather'),\n",
       " ('spread', 'select', 'gather'),\n",
       " ('unite', 'spread', 'gather'),\n",
       " ('gather', 'select', 'unite'),\n",
       " ('spread', 'gather', 'unite'),\n",
       " ('select', 'unite', 'select'),\n",
       " ('gather', 'spread', 'separate'),\n",
       " ('unite', 'separate', 'select'),\n",
       " ('gather', 'spread', 'unite'),\n",
       " ('separate', 'unite', 'unite'),\n",
       " ('unite', 'gather', 'select'),\n",
       " ('separate', 'select', 'gather'),\n",
       " ('separate', 'spread', 'separate'),\n",
       " ('separate', 'spread', 'unite'),\n",
       " ('select', 'spread', 'separate'),\n",
       " ('unite', 'gather', 'spread'),\n",
       " ('select', 'unite', 'unite'),\n",
       " ('select', 'spread', 'unite'),\n",
       " ('spread', 'separate', 'select'),\n",
       " ('unite', 'spread', 'separate'),\n",
       " ('select', 'separate', 'gather'),\n",
       " ('unite', 'spread', 'unite'),\n",
       " ('unite', 'gather', 'separate'),\n",
       " ('separate', 'unite', 'separate'),\n",
       " ('unite', 'unite', 'separate'),\n",
       " ('spread', 'unite', 'select'),\n",
       " ('spread', 'select', 'separate'),\n",
       " ('spread', 'select', 'unite'),\n",
       " ('select', 'unite', 'separate'),\n",
       " ('unite', 'separate', 'gather'),\n",
       " ('select', 'separate', 'unite'),\n",
       " ('unite', 'gather', 'unite'),\n",
       " ('separate', 'select', 'separate'),\n",
       " ('spread', 'unite', 'unite'),\n",
       " ('unite', 'select', 'gather'),\n",
       " ('separate', 'select', 'unite'),\n",
       " ('spread', 'separate', 'gather'),\n",
       " ('unite', 'separate', 'unite'),\n",
       " ('separate', 'unite', 'gather'),\n",
       " ('unite', 'unite', 'gather'),\n",
       " ('spread', 'unite', 'separate'),\n",
       " ('select', 'unite', 'gather'),\n",
       " ('spread', 'separate', 'unite'),\n",
       " ('unite', 'select', 'separate'),\n",
       " ('unite', 'select', 'unite'),\n",
       " ('spread', 'unite', 'gather')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So a fair comparison is, get rid of frequencies and try again, because we care about long-tail entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = [\n",
    "    ('gather', 'separate', 'gather'),\n",
    "    ('gather', 'separate', 'select'),\n",
    "    ('gather', 'separate', 'spread'),\n",
    "    ('gather', 'separate', 'unite'),\n",
    "    ('gather', 'spread', 'select'),\n",
    "    ('gather', 'unite', 'select'),\n",
    "    ('gather', 'unite', 'spread'),\n",
    "    ('separate', 'gather', 'select'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrank_ngram = []\n",
    "vrank_songram = []\n",
    "for p in query_list:\n",
    "    vrank_ngram.append(ngram_parsed.index(p))\n",
    "    vrank_songram.append(songram_pair.index(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.875"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vrank_ngram)/len(vrank_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 2, 1, 21, 3, 9, 0, 13]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrank_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vrank_songram)/len(vrank_songram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 7, 5, 1, 0, 6, 2]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrank_songram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about performance on MD data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./0804MDsize3_part2.pkl\",\"rb\") as f:\n",
    "    dt_md = pickle.load(f)\n",
    "md_parsed = []\n",
    "for i in range(len(dt_md)):\n",
    "    tmp_str = str(dt_md[i][0])\n",
    "    tmp_s = tmp_str.index(\"@\")\n",
    "    tmp_sl = tmp_str[:tmp_s].split(\"(\")[::-1]\n",
    "    tmp_sls = [p for p in tmp_sl if p]\n",
    "    md_parsed.append(tmp_sls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['separate', 'gather', 'unite']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_parsed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "songram2_dict = {}\n",
    "for i in range(len(md_parsed)):\n",
    "    d_ent = tuple(md_parsed[i])\n",
    "    if d_ent not in songram2_dict:\n",
    "        songram2_dict[d_ent] = 0\n",
    "    songram2_dict[d_ent] += 1\n",
    "# sort\n",
    "songram2_pair = sorted(songram2_dict, key=songram2_dict.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_mdgram = []\n",
    "rank_songram2 = []\n",
    "for p in md_parsed:\n",
    "    tp = tuple(p)\n",
    "    rank_mdgram.append(ngram_parsed.index(tp))\n",
    "    rank_songram2.append(songram2_pair.index(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.418235877106046"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rank_mdgram)/len(rank_mdgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.352824578790882"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rank_songram2)/len(rank_songram2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### study the generated data's distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_freq = {}\n",
    "for p in md_parsed:\n",
    "    tp = tuple(p)\n",
    "    if tp not in md_freq:\n",
    "        md_freq[tp] = 0\n",
    "    md_freq[tp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('gather', 'separate', 'gather'): 15,\n",
       " ('gather', 'separate', 'select'): 32,\n",
       " ('gather', 'separate', 'spread'): 4,\n",
       " ('gather', 'separate', 'unite'): 16,\n",
       " ('gather', 'spread', 'gather'): 146,\n",
       " ('gather', 'spread', 'select'): 258,\n",
       " ('gather', 'spread', 'separate'): 16,\n",
       " ('gather', 'spread', 'unite'): 43,\n",
       " ('gather', 'unite', 'gather'): 181,\n",
       " ('gather', 'unite', 'select'): 354,\n",
       " ('gather', 'unite', 'separate'): 81,\n",
       " ('gather', 'unite', 'spread'): 12,\n",
       " ('separate', 'gather', 'select'): 189,\n",
       " ('separate', 'gather', 'spread'): 21,\n",
       " ('separate', 'gather', 'unite'): 131,\n",
       " ('separate', 'unite', 'gather'): 65,\n",
       " ('separate', 'unite', 'select'): 98,\n",
       " ('separate', 'unite', 'separate'): 16,\n",
       " ('spread', 'gather', 'select'): 1,\n",
       " ('unite', 'gather', 'select'): 71,\n",
       " ('unite', 'gather', 'separate'): 3,\n",
       " ('unite', 'gather', 'spread'): 23,\n",
       " ('unite', 'gather', 'unite'): 56,\n",
       " ('unite', 'separate', 'gather'): 56,\n",
       " ('unite', 'separate', 'select'): 11,\n",
       " ('unite', 'separate', 'unite'): 108,\n",
       " ('unite', 'spread', 'gather'): 4,\n",
       " ('unite', 'spread', 'select'): 3,\n",
       " ('unite', 'spread', 'separate'): 1,\n",
       " ('unite', 'spread', 'unite'): 3}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdso_freq = {}\n",
    "for p in mdso_parsed:\n",
    "    tp = tuple(p)\n",
    "    if tp not in mdso_freq:\n",
    "        mdso_freq[tp] = 0\n",
    "    mdso_freq[tp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('gather', 'separate', 'gather'): 13,\n",
       " ('gather', 'separate', 'select'): 12,\n",
       " ('gather', 'separate', 'spread'): 1,\n",
       " ('gather', 'separate', 'unite'): 11,\n",
       " ('gather', 'spread', 'select'): 135,\n",
       " ('gather', 'unite', 'select'): 179,\n",
       " ('gather', 'unite', 'spread'): 2,\n",
       " ('separate', 'gather', 'select'): 107}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdso_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1) gather separate gather\n",
    "(1) gather separate select\n",
    "(40)gather separate spread\n",
    "(2) gather separate unite\n",
    "(7) gather spread select\n",
    "(1) gather unite select\n",
    "(44)gather unite spread\n",
    "(2) separate gather select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now test on the old dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./0804MDsize3_part1.pkl\",\"rb\") as f:\n",
    "    dt_part1 = pickle.load(f)\n",
    "part1_parsed = []\n",
    "for i in range(len(dt_part1)):\n",
    "    tmp_str = str(dt_part1[i][0])\n",
    "    tmp_s = tmp_str.index(\"@\")\n",
    "    tmp_sl = tmp_str[:tmp_s].split(\"(\")[::-1]\n",
    "    tmp_sls = [p for p in tmp_sl if p]\n",
    "    part1_parsed.append(tmp_sls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['separate', 'gather', 'select']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1_parsed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./size3-ngram-camb3.txt\",\"r\") as f:\n",
    "    ngram_raw = f.readlines()\n",
    "ngram_parsed = []\n",
    "for dline in ngram_raw:\n",
    "    ngram_parsed.append(tuple(dline.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gather', 'unite', 'spread'),\n",
       " ('gather', 'separate', 'spread'),\n",
       " ('gather', 'separate', 'select'),\n",
       " ('gather', 'spread', 'select'),\n",
       " ('gather', 'select', 'spread'),\n",
       " ('separate', 'spread', 'select'),\n",
       " ('select', 'spread', 'select'),\n",
       " ('unite', 'spread', 'select'),\n",
       " ('select', 'gather', 'select'),\n",
       " ('gather', 'unite', 'select'),\n",
       " ('separate', 'unite', 'spread'),\n",
       " ('unite', 'unite', 'spread'),\n",
       " ('select', 'gather', 'spread'),\n",
       " ('separate', 'gather', 'select'),\n",
       " ('gather', 'separate', 'gather'),\n",
       " ('select', 'unite', 'spread'),\n",
       " ('gather', 'unite', 'unite'),\n",
       " ('separate', 'gather', 'spread'),\n",
       " ('spread', 'select', 'spread'),\n",
       " ('select', 'gather', 'separate'),\n",
       " ('select', 'separate', 'spread'),\n",
       " ('gather', 'separate', 'unite'),\n",
       " ('separate', 'gather', 'separate'),\n",
       " ('separate', 'select', 'spread'),\n",
       " ('select', 'gather', 'unite'),\n",
       " ('gather', 'select', 'gather'),\n",
       " ('gather', 'unite', 'separate'),\n",
       " ('spread', 'gather', 'select'),\n",
       " ('spread', 'unite', 'spread'),\n",
       " ('unite', 'separate', 'spread'),\n",
       " ('separate', 'gather', 'unite'),\n",
       " ('spread', 'gather', 'spread'),\n",
       " ('gather', 'spread', 'gather'),\n",
       " ('spread', 'separate', 'spread'),\n",
       " ('spread', 'gather', 'separate'),\n",
       " ('separate', 'spread', 'gather'),\n",
       " ('select', 'separate', 'select'),\n",
       " ('select', 'spread', 'gather'),\n",
       " ('separate', 'unite', 'select'),\n",
       " ('unite', 'unite', 'select'),\n",
       " ('gather', 'select', 'separate'),\n",
       " ('unite', 'select', 'spread'),\n",
       " ('gather', 'unite', 'gather'),\n",
       " ('spread', 'select', 'gather'),\n",
       " ('unite', 'spread', 'gather'),\n",
       " ('gather', 'select', 'unite'),\n",
       " ('spread', 'gather', 'unite'),\n",
       " ('select', 'unite', 'select'),\n",
       " ('gather', 'spread', 'separate'),\n",
       " ('unite', 'separate', 'select'),\n",
       " ('gather', 'spread', 'unite'),\n",
       " ('separate', 'unite', 'unite'),\n",
       " ('unite', 'gather', 'select'),\n",
       " ('separate', 'select', 'gather'),\n",
       " ('separate', 'spread', 'separate'),\n",
       " ('separate', 'spread', 'unite'),\n",
       " ('select', 'spread', 'separate'),\n",
       " ('unite', 'gather', 'spread'),\n",
       " ('select', 'unite', 'unite'),\n",
       " ('select', 'spread', 'unite'),\n",
       " ('spread', 'separate', 'select'),\n",
       " ('unite', 'spread', 'separate'),\n",
       " ('select', 'separate', 'gather'),\n",
       " ('unite', 'spread', 'unite'),\n",
       " ('unite', 'gather', 'separate'),\n",
       " ('separate', 'unite', 'separate'),\n",
       " ('unite', 'unite', 'separate'),\n",
       " ('spread', 'unite', 'select'),\n",
       " ('spread', 'select', 'separate'),\n",
       " ('spread', 'select', 'unite'),\n",
       " ('select', 'unite', 'separate'),\n",
       " ('unite', 'separate', 'gather'),\n",
       " ('select', 'separate', 'unite'),\n",
       " ('unite', 'gather', 'unite'),\n",
       " ('separate', 'select', 'separate'),\n",
       " ('spread', 'unite', 'unite'),\n",
       " ('unite', 'select', 'gather'),\n",
       " ('separate', 'select', 'unite'),\n",
       " ('spread', 'separate', 'gather'),\n",
       " ('unite', 'separate', 'unite'),\n",
       " ('separate', 'unite', 'gather'),\n",
       " ('unite', 'unite', 'gather'),\n",
       " ('spread', 'unite', 'separate'),\n",
       " ('select', 'unite', 'gather'),\n",
       " ('spread', 'separate', 'unite'),\n",
       " ('unite', 'select', 'separate'),\n",
       " ('unite', 'select', 'unite'),\n",
       " ('spread', 'unite', 'gather')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_mdgram = []\n",
    "for p in part1_parsed:\n",
    "    tp = tuple(p)\n",
    "    rank_mdgram.append(ngram_parsed.index(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.502"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rank_mdgram)/len(rank_mdgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
