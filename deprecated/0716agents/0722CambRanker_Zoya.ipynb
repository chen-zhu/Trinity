{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransNeo/AlphaNeo Ranker\n",
    "- tell which pair of tables are functionally/logically closer on execution chain\n",
    "- Stage: Cambrian\n",
    "- Version: Spriggina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataset for test: load the examples from given dataset\n",
    "'''\n",
    "class RankerTestDataset(Dataset):\n",
    "    def __init__(self, p_config=None, p_dataset=None, p_interpreter=None, p_spec=None, is_fake=False):\n",
    "        self.interpreter = p_interpreter\n",
    "        self.spec = p_spec\n",
    "        self.dataset = p_dataset\n",
    "        self.config = p_config\n",
    "        \n",
    "        # flatten the dataset in the form [str_example]\n",
    "        # we don't care about what the prog is\n",
    "        self.str_examples = [\n",
    "            self.dataset[dkey][i][1]\n",
    "            for dkey in self.dataset.keys()\n",
    "            for i in range(len(self.dataset[dkey])-990)\n",
    "        ]\n",
    "        self.n_exp = len(self.str_examples)\n",
    "        self.n_row = self.config[\"ranker\"][\"n_row\"]\n",
    "        self.n_col = self.config[\"ranker\"][\"n_col\"]\n",
    "        \n",
    "        print(\"# Test Dataset Examples: {}\".format(self.n_exp))\n",
    "        \n",
    "        # == only works for chain: 1 input, 1 output ==\n",
    "        # then compute the abstraction map of the variables\n",
    "        print(\"# Parsing Dataset...\")\n",
    "        self.LMTX = np.full(\n",
    "            (self.n_exp, self.n_row, self.n_col),\n",
    "            self.interpreter.CAMB_DICT[\"<PAD>\"],\n",
    "            dtype=int,\n",
    "        )\n",
    "        self.RMTX = np.full(\n",
    "            (self.n_exp, self.n_row, self.n_col),\n",
    "            self.interpreter.CAMB_DICT[\"<PAD>\"],\n",
    "            dtype=int,\n",
    "        )\n",
    "        for i in range(self.n_exp):\n",
    "            print(\"\\r## in:{}/{}\".format(i,self.n_exp),end=\"\")\n",
    "            if is_fake:\n",
    "                # fake the data for negative samples\n",
    "                var_input = self.interpreter.random_table()\n",
    "                var_output= self.interpreter.random_table()\n",
    "            else:\n",
    "                d_example = self.str_examples[i]\n",
    "                var_input = self.interpreter.load_data_into_var(d_example.input[0]) ## == chain == ##\n",
    "                var_output= self.interpreter.load_data_into_var(d_example.output)\n",
    "            map_input = self.interpreter.camb_get_abs(var_input)\n",
    "            map_output= self.interpreter.camb_get_abs(var_output)\n",
    "            # store into matrices\n",
    "            self.LMTX[i,:,:] = map_input\n",
    "            self.RMTX[i,:,:] = map_output\n",
    "        print()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_exp\n",
    "    \n",
    "    '''\n",
    "    should always use batch_size=1 so as to ensure the ratio of negative examples\n",
    "    '''\n",
    "    def __getitem__(self, p_ind):\n",
    "        # (left, right)\n",
    "        return (\n",
    "            self.LMTX[p_ind,:,:], # (map_r, map_c)\n",
    "            self.RMTX[p_ind,:,:], # (map_r, map_c)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataset for training: load random positive/negative examples every time\n",
    "'''\n",
    "class RankerTrainDataset(Dataset):\n",
    "    def __init__(self, p_config=None, p_dataset=None, p_interpreter=None, p_spec=None):\n",
    "        self.interpreter = p_interpreter\n",
    "        self.spec = p_spec\n",
    "        self.dataset = p_dataset\n",
    "        self.config = p_config\n",
    "        \n",
    "        # we need the prog to sample IOs\n",
    "        self.progs = [\n",
    "            self.dataset[dkey][0][0]\n",
    "            for dkey in self.dataset.keys()\n",
    "            if len(self.dataset[dkey])>20\n",
    "        ]\n",
    "        self.n_exp = len(self.progs)\n",
    "        self.n_neg = self.config[\"ranker\"][\"n_neg\"]\n",
    "        self.n_pos = self.config[\"ranker\"][\"n_pos\"]\n",
    "        self.n_row = self.config[\"ranker\"][\"n_row\"]\n",
    "        self.n_col = self.config[\"ranker\"][\"n_col\"]\n",
    "        \n",
    "        print(\"# Train Dataset Programs: {}\".format(self.n_exp))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_exp\n",
    "    \n",
    "    '''\n",
    "    should always use batch_size=1 so as to ensure the ratio of negative examples\n",
    "    '''\n",
    "    def __getitem__(self, p_ind):\n",
    "        # generate both positive and negative data on the fly\n",
    "        tmpLMTX = np.full(\n",
    "            (self.n_pos, self.n_row, self.n_col),\n",
    "            self.interpreter.CAMB_DICT[\"<PAD>\"],\n",
    "            dtype=int,\n",
    "        )\n",
    "        tmpRMTX = np.full(\n",
    "            (self.n_pos, self.n_row, self.n_col),\n",
    "            self.interpreter.CAMB_DICT[\"<PAD>\"],\n",
    "            dtype=int,\n",
    "        )\n",
    "        \n",
    "        # generate positive data\n",
    "        for k in range(self.n_pos):\n",
    "            d_prog = random.choice(self.progs)\n",
    "            while True:\n",
    "                tmp_input = self.interpreter.random_table()\n",
    "                try:\n",
    "                    tmp_eval = self.interpreter.eval(\n",
    "                        d_prog,\n",
    "                        [tmp_input],\n",
    "                    )\n",
    "                except Exception:\n",
    "                    continue\n",
    "                tmp_example = Example(\n",
    "                    input=[tmp_input],\n",
    "                    output=tmp_eval,\n",
    "                )\n",
    "                tmp_ps = ProgramSpace(\n",
    "                    self.spec, self.interpreter,\n",
    "                    tmp_example.input, tmp_example.output\n",
    "                )\n",
    "                tmp_ps.init_by_prog(d_prog)\n",
    "                tmp_check = self.interpreter.sanity_check(tmp_ps)\n",
    "                if tmp_check[0]:\n",
    "                    # succeed\n",
    "                    map_input = self.interpreter.camb_get_abs(tmp_input)\n",
    "                    map_output= self.interpreter.camb_get_abs(tmp_eval)\n",
    "                    tmpLMTX[k,:,:] = map_input\n",
    "                    tmpRMTX[k,:,:] = map_output\n",
    "                    break\n",
    "                else:\n",
    "                    # fail, try again\n",
    "                    continue\n",
    "                    \n",
    "        # generate negative data\n",
    "        tmpWMTX = np.full(\n",
    "            (self.n_neg, self.n_row, self.n_col),\n",
    "            self.interpreter.CAMB_DICT[\"<PAD>\"],\n",
    "            dtype=int,\n",
    "        )\n",
    "        for i in range(self.n_neg):\n",
    "            var_table = self.interpreter.random_table()\n",
    "            map_table = self.interpreter.camb_get_abs(var_table)\n",
    "            tmpWMTX[i,:,:] = map_table\n",
    "        # generate negative data\n",
    "        tmpVMTX = np.full(\n",
    "            (self.n_neg, self.n_row, self.n_col),\n",
    "            self.interpreter.CAMB_DICT[\"<PAD>\"],\n",
    "            dtype=int,\n",
    "        )\n",
    "        for i in range(self.n_neg):\n",
    "            var_table = self.interpreter.random_table()\n",
    "            map_table = self.interpreter.camb_get_abs(var_table)\n",
    "            tmpVMTX[i,:,:] = map_table\n",
    "        \n",
    "        # (left, right, negatives)\n",
    "        return (\n",
    "            tmpLMTX, # (n_pos, map_r, map_c)\n",
    "            tmpRMTX, # (n_pos, map_r, map_c)\n",
    "            tmpWMTX, # (n_neg, map_r, map_c)\n",
    "            tmpVMTX, # (n_neg, map_r, map_c)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueEncoder(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(ValueEncoder, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.vocab_size = self.config[\"val\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"val\"][\"embd_dim\"]\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embd_dim,\n",
    "            self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels = self.config[\"val\"][\"embd_dim\"],\n",
    "            out_channels = self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            kernel_size = self.config[\"val\"][\"conv_kernel_size\"],\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = self.config[\"val\"][\"pool_kernel_size\"],\n",
    "            padding = self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            self.config[\"embd_dim\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, bp_map):\n",
    "        # batched maps, (B, map_r, map_c)\n",
    "        # in this version, every value only contains 1 map\n",
    "        B = bp_map.shape[0]\n",
    "        \n",
    "        # (B, map_r, map_c, val_embd_dim) -> (B, val_embd_dim, map_r, map_c)\n",
    "        d_embd = self.embedding(bp_map).permute(0,3,1,2)\n",
    "        \n",
    "        # (B, n_kernel, map_r, 1)\n",
    "        d_conv = F.relu(self.conv(d_embd))\n",
    "        \n",
    "        # (B, n_kernel)\n",
    "        d_pool = self.pool(d_conv).view(B,self.config[\"val\"][\"conv_n_kernels\"])\n",
    "        \n",
    "        # (B, embd_dim)\n",
    "        # d_out = torch.sigmoid(\n",
    "        d_out = F.relu(\n",
    "            self.fc(d_pool)\n",
    "        )\n",
    "        \n",
    "        return d_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranker(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(Ranker, self).__init__()\n",
    "        self.config = p_config\n",
    "        self.value_encoder = ValueEncoder(p_config=p_config)\n",
    "        self.fc0 = nn.Linear(\n",
    "            self.config[\"embd_dim\"]*2,\n",
    "            2048,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            2048,\n",
    "            2,\n",
    "        )\n",
    "        \n",
    "    def forward(self, pL, pR, pW, pV):\n",
    "        # pL/pR: (B=1, n_pos, map_r, map_c)\n",
    "        # pW/pV: (B=1, n_neg, map_r, map_c)\n",
    "        vL = self.value_encoder(\n",
    "            pL.view(\n",
    "                self.config[\"ranker\"][\"n_pos\"],\n",
    "                self.config[\"ranker\"][\"n_row\"],\n",
    "                self.config[\"ranker\"][\"n_col\"],\n",
    "            )\n",
    "        ) # (B=n_pos, embd_dim)\n",
    "        vR = self.value_encoder(\n",
    "            pR.view(\n",
    "                self.config[\"ranker\"][\"n_pos\"],\n",
    "                self.config[\"ranker\"][\"n_row\"],\n",
    "                self.config[\"ranker\"][\"n_col\"],\n",
    "            )\n",
    "        ) # (B=n_pos, embd_dim)\n",
    "        vW = self.value_encoder(\n",
    "            pW.view(\n",
    "                self.config[\"ranker\"][\"n_neg\"],\n",
    "                self.config[\"ranker\"][\"n_row\"],\n",
    "                self.config[\"ranker\"][\"n_col\"],\n",
    "            ),\n",
    "        ) # (B=n_neg, embd_dim)\n",
    "        vV = self.value_encoder(\n",
    "            pV.view(\n",
    "                self.config[\"ranker\"][\"n_neg\"],\n",
    "                self.config[\"ranker\"][\"n_row\"],\n",
    "                self.config[\"ranker\"][\"n_col\"],\n",
    "            )\n",
    "        ) # (B=n_neg, embd_dim)\n",
    "        \n",
    "        vLR = torch.cat([vL,vR],dim=1) # (n_pos, embd_dim * 2)\n",
    "        vWV = torch.cat([vW,vV],dim=1) # (n_neg, embd_dim * 2)\n",
    "        \n",
    "        vII = torch.cat([vLR,vWV],dim=0) # (n_pos+n_neg, embd_dim * 2)\n",
    "        \n",
    "        # == Notice: don't do any activation at the last layer ==\n",
    "        vOO = self.fc1(\n",
    "            F.relu(\n",
    "                self.fc0(\n",
    "                    vII\n",
    "                )\n",
    "            )\n",
    "        )# (n_neg+1, 2)\n",
    "        \n",
    "        return vOO\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    used for actual testing\n",
    "    '''\n",
    "    def inference(self, pL, pR):\n",
    "        # pL/pR: (B, map_r, map_c)\n",
    "        vL = self.value_encoder(pL) # (B, embd_dim)\n",
    "        vR = self.value_encoder(pR) # (B, embd_dim)\n",
    "        \n",
    "        vLR = torch.cat([vL,vR],dim=1) # (B, embd_dim * 2)\n",
    "        \n",
    "        # == Notice: don't do any activation at the last layer ==\n",
    "        vOO = self.fc1(\n",
    "            F.relu(\n",
    "                self.fc0(\n",
    "                    vLR\n",
    "                )\n",
    "            )\n",
    "        )# (B, 2)\n",
    "        \n",
    "        return vOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RankerTester(p_config, p_model, p_ld_test_data, p_lossfn, p_target):\n",
    "    test_loss_list = []\n",
    "    test_prob_list = [] \n",
    "    test_accu_list = [] # number of correct predictions\n",
    "    for batch_idx, (d_left, d_right) in enumerate(p_ld_test_data):\n",
    "        p_model.eval()\n",
    "        B = d_left.shape[0]\n",
    "        if use_cuda:\n",
    "            td_left = Variable(d_left).cuda()\n",
    "            td_right= Variable(d_right).cuda()\n",
    "            td_label = Variable(torch.tensor(\n",
    "                [p_target for _ in range(B)]\n",
    "            )).cuda()\n",
    "        else:\n",
    "            td_left = Variable(d_left)\n",
    "            td_right= Variable(d_right)\n",
    "            td_label = Variable(torch.tensor(\n",
    "                [p_target for _ in range(B)]\n",
    "            ))\n",
    "        d_output = p_model.inference(td_left, td_right) # (B, 2)\n",
    "        d_loss = p_lossfn(\n",
    "            F.log_softmax(d_output, dim=1),\n",
    "            td_label,\n",
    "        )\n",
    "        test_loss_list.append(d_loss.cpu().data.numpy())\n",
    "        test_prob_list += F.softmax(d_output,dim=1)[:,p_target].cpu().data.tolist()\n",
    "        test_accu_list += (torch.argmax(d_output,dim=1)==td_label).cpu().data.tolist()\n",
    "    print(\"# Test target:{}, avg.loss:{:.2f}, avg.prob.:{:.2f}, avg.acc.:{:.2f}\".format(\n",
    "        p_target,\n",
    "        sum(test_loss_list)/len(test_loss_list),\n",
    "        sum(test_prob_list)/len(test_prob_list),\n",
    "        sum(test_accu_list)/len(test_accu_list),\n",
    "    ))\n",
    "    # print(test_prob_list)\n",
    "    # print(test_accu_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RankerTrainer(p_config, p_model, p_ld_train_data, p_ld_testpos_data, p_ld_testneg_data, p_optim, p_lossfn):\n",
    "    RankerTester(p_config, p_model, p_ld_testneg_data, p_lossfn, 0)\n",
    "    RankerTester(p_config, p_model, p_ld_testpos_data, p_lossfn, 1)\n",
    "    for d_ep in range(p_config[\"ranker\"][\"n_ep\"]):\n",
    "        epoch_loss_list = []\n",
    "        \n",
    "        for batch_idx, (d_left, d_right, d_window, d_violin) in enumerate(p_ld_train_data):\n",
    "            p_model.train()\n",
    "            \n",
    "            if use_cuda:\n",
    "                td_left = Variable(d_left).cuda() # (B=1, n_pos, map_r, map_c)\n",
    "                td_right = Variable(d_right).cuda() # (B=1, n_pos, map_r, map_c)\n",
    "                td_window = Variable(d_window).cuda() # (B=1, n_neg, map_r, map_c)\n",
    "                td_violin = Variable(d_violin).cuda() # (B=1, n_neg, map_r, map_c)\n",
    "                td_label = Variable(torch.tensor(\n",
    "                    [1 for _ in range(p_config[\"ranker\"][\"n_pos\"])]+\\\n",
    "                    [0 for _ in range(p_config[\"ranker\"][\"n_neg\"])]\n",
    "                )).cuda()\n",
    "            else:\n",
    "                td_left = Variable(d_left) # (B=1, n_pos, map_r, map_c)\n",
    "                td_right = Variable(d_right) # (B=1, n_pos, map_r, map_c)\n",
    "                td_window = Variable(d_window) # (B=1, n_neg, map_r, map_c)\n",
    "                td_violin = Variable(d_violin) # (B=1, n_neg, map_r, map_c)\n",
    "                td_label = Variable(torch.tensor(\n",
    "                    [1 for _ in range(p_config[\"ranker\"][\"n_pos\"])]+\\\n",
    "                    [0 for _ in range(p_config[\"ranker\"][\"n_neg\"])]\n",
    "                ))\n",
    "                \n",
    "            # (n_neg+1, 2)\n",
    "            d_output = p_model(td_left, td_right, td_window, td_violin)\n",
    "            p_optim.zero_grad()\n",
    "            d_loss = p_lossfn(\n",
    "                F.log_softmax(d_output, dim=1),\n",
    "                td_label,\n",
    "            )\n",
    "            epoch_loss_list.append(d_loss.cpu().data.numpy())\n",
    "            d_loss.backward()\n",
    "            p_optim.step()\n",
    "            \n",
    "            print(\"\\r# Training EP:{}, B:{}, ep.loss:{:.2f}\".format(\n",
    "                d_ep, batch_idx, sum(epoch_loss_list),\n",
    "            ),end=\"\")\n",
    "        \n",
    "        # end of epoch print a new line\n",
    "        print()\n",
    "        RankerTester(p_config, p_model, p_ld_testneg_data, p_lossfn, 0)\n",
    "        RankerTester(p_config, p_model, p_ld_testpos_data, p_lossfn, 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train Dataset Programs: 78\n",
      "# Test Dataset Examples: 770\n",
      "# Parsing Dataset...\n",
      "## in:769/770\n",
      "# Test Dataset Examples: 770\n",
      "# Parsing Dataset...\n",
      "## in:769/770\n"
     ]
    }
   ],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "\n",
    "m_config = {\n",
    "    \"val\":{\n",
    "        \"vocab_size\": len(m_interpreter.CAMB_LIST),\n",
    "        \"embd_dim\": 16, # embedding dim of CAMB abstract token\n",
    "        \"conv_n_kernels\": 512,\n",
    "        \"conv_kernel_size\": (1,m_interpreter.CAMB_NCOL), \n",
    "        \"pool_kernel_size\": (m_interpreter.CAMB_NROW,1), \n",
    "        \"IDX_PAD\": 0,\n",
    "    },\n",
    "    \"embd_dim\": 128,\n",
    "    \"ranker\":{\n",
    "        \"data_path\": \"./0716MDsize1.pkl\",\n",
    "        \"n_row\": m_interpreter.CAMB_NROW,\n",
    "        \"n_col\": m_interpreter.CAMB_NCOL,\n",
    "        \"n_neg\": 9,\n",
    "        \"n_pos\": 1,\n",
    "        \"n_ep\": 1000000,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# load the data and dataset\n",
    "with open(m_config[\"ranker\"][\"data_path\"],\"rb\") as f:\n",
    "    m_data = pickle.load(f)\n",
    "    \n",
    "dt_train = RankerTrainDataset(\n",
    "    p_config=m_config, \n",
    "    p_dataset=m_data, \n",
    "    p_interpreter=m_interpreter,\n",
    "    p_spec=m_spec,\n",
    ")\n",
    "ld_train = DataLoader(dataset=dt_train, batch_size=1, shuffle=True)\n",
    "\n",
    "dt_testpos = RankerTestDataset(\n",
    "    p_config=m_config, \n",
    "    p_dataset=m_data, \n",
    "    p_interpreter=m_interpreter,\n",
    "    p_spec=m_spec,\n",
    "    is_fake=False,\n",
    ")\n",
    "ld_testpos = DataLoader(dataset=dt_testpos, batch_size=128, shuffle=True)\n",
    "\n",
    "dt_testneg = RankerTestDataset(\n",
    "    p_config=m_config, \n",
    "    p_dataset=m_data, \n",
    "    p_interpreter=m_interpreter,\n",
    "    p_spec=m_spec,\n",
    "    is_fake=True,\n",
    ")\n",
    "ld_testneg = DataLoader(dataset=dt_testneg, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "m_ranker = Ranker(p_config=m_config)\n",
    "if use_cuda:\n",
    "    m_ranker = m_ranker.cuda()\n",
    "optimizer = torch.optim.Adam(list(m_ranker.parameters()))\n",
    "lossfn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test target:0, avg.loss:0.69, avg.prob.:0.50, avg.acc.:0.50\n",
      "# Test target:1, avg.loss:0.69, avg.prob.:0.50, avg.acc.:0.55\n",
      "# Training EP:0, B:77, ep.loss:25.30\n",
      "# Test target:0, avg.loss:0.11, avg.prob.:0.90, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:2.06, avg.prob.:0.18, avg.acc.:0.00\n",
      "# Training EP:1, B:77, ep.loss:24.68\n",
      "# Test target:0, avg.loss:0.07, avg.prob.:0.93, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:2.53, avg.prob.:0.11, avg.acc.:0.00\n",
      "# Training EP:2, B:77, ep.loss:23.04\n",
      "# Test target:0, avg.loss:0.03, avg.prob.:0.97, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:2.83, avg.prob.:0.11, avg.acc.:0.00\n",
      "# Training EP:3, B:77, ep.loss:22.29\n",
      "# Test target:0, avg.loss:0.14, avg.prob.:0.93, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:2.16, avg.prob.:0.19, avg.acc.:0.04\n",
      "# Training EP:4, B:77, ep.loss:19.95\n",
      "# Test target:0, avg.loss:0.11, avg.prob.:0.90, avg.acc.:0.97\n",
      "# Test target:1, avg.loss:1.55, avg.prob.:0.36, avg.acc.:0.37\n",
      "# Training EP:5, B:77, ep.loss:21.35\n",
      "# Test target:0, avg.loss:0.11, avg.prob.:0.90, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.50, avg.prob.:0.29, avg.acc.:0.20\n",
      "# Training EP:6, B:77, ep.loss:18.99\n",
      "# Test target:0, avg.loss:0.08, avg.prob.:0.92, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.54, avg.prob.:0.32, avg.acc.:0.32\n",
      "# Training EP:7, B:77, ep.loss:18.16\n",
      "# Test target:0, avg.loss:0.08, avg.prob.:0.92, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.72, avg.prob.:0.35, avg.acc.:0.32\n",
      "# Training EP:8, B:77, ep.loss:17.61\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:0.99\n",
      "# Test target:1, avg.loss:1.46, avg.prob.:0.43, avg.acc.:0.43\n",
      "# Training EP:9, B:77, ep.loss:16.94\n",
      "# Test target:0, avg.loss:0.14, avg.prob.:0.89, avg.acc.:0.98\n",
      "# Test target:1, avg.loss:1.31, avg.prob.:0.52, avg.acc.:0.52\n",
      "# Training EP:10, B:77, ep.loss:14.87\n",
      "# Test target:0, avg.loss:0.06, avg.prob.:0.94, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.80, avg.prob.:0.45, avg.acc.:0.42\n",
      "# Training EP:11, B:77, ep.loss:15.81\n",
      "# Test target:0, avg.loss:0.03, avg.prob.:0.97, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.77, avg.prob.:0.42, avg.acc.:0.42\n",
      "# Training EP:12, B:77, ep.loss:14.30\n",
      "# Test target:0, avg.loss:0.12, avg.prob.:0.91, avg.acc.:0.98\n",
      "# Test target:1, avg.loss:1.35, avg.prob.:0.57, avg.acc.:0.56\n",
      "# Training EP:13, B:77, ep.loss:12.67\n",
      "# Test target:0, avg.loss:0.02, avg.prob.:0.98, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:2.21, avg.prob.:0.49, avg.acc.:0.49\n",
      "# Training EP:14, B:77, ep.loss:18.28\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.48, avg.prob.:0.50, avg.acc.:0.47\n",
      "# Training EP:15, B:77, ep.loss:14.67\n",
      "# Test target:0, avg.loss:0.03, avg.prob.:0.97, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.66, avg.prob.:0.52, avg.acc.:0.52\n",
      "# Training EP:16, B:77, ep.loss:13.52\n",
      "# Test target:0, avg.loss:0.04, avg.prob.:0.96, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.49, avg.prob.:0.56, avg.acc.:0.54\n",
      "# Training EP:17, B:77, ep.loss:13.23\n",
      "# Test target:0, avg.loss:0.03, avg.prob.:0.97, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.26, avg.prob.:0.54, avg.acc.:0.53\n",
      "# Training EP:18, B:77, ep.loss:14.53\n",
      "# Test target:0, avg.loss:0.10, avg.prob.:0.92, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:0.93, avg.prob.:0.55, avg.acc.:0.54\n",
      "# Training EP:19, B:77, ep.loss:16.02\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.17, avg.prob.:0.52, avg.acc.:0.53\n",
      "# Training EP:20, B:77, ep.loss:14.02\n",
      "# Test target:0, avg.loss:0.03, avg.prob.:0.97, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.30, avg.prob.:0.51, avg.acc.:0.52\n",
      "# Training EP:21, B:77, ep.loss:13.57\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:0.99\n",
      "# Test target:1, avg.loss:1.06, avg.prob.:0.59, avg.acc.:0.59\n",
      "# Training EP:22, B:77, ep.loss:12.38\n",
      "# Test target:0, avg.loss:0.06, avg.prob.:0.94, avg.acc.:0.99\n",
      "# Test target:1, avg.loss:0.87, avg.prob.:0.61, avg.acc.:0.58\n",
      "# Training EP:23, B:77, ep.loss:12.27\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.17, avg.prob.:0.60, avg.acc.:0.58\n",
      "# Training EP:24, B:77, ep.loss:12.09\n",
      "# Test target:0, avg.loss:0.09, avg.prob.:0.92, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:0.92, avg.prob.:0.59, avg.acc.:0.54\n",
      "# Training EP:25, B:77, ep.loss:12.07\n",
      "# Test target:0, avg.loss:0.02, avg.prob.:0.98, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.88, avg.prob.:0.51, avg.acc.:0.51\n",
      "# Training EP:26, B:77, ep.loss:15.08\n",
      "# Test target:0, avg.loss:0.07, avg.prob.:0.93, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:0.82, avg.prob.:0.62, avg.acc.:0.59\n",
      "# Training EP:27, B:77, ep.loss:12.49\n",
      "# Test target:0, avg.loss:0.04, avg.prob.:0.96, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:0.96, avg.prob.:0.62, avg.acc.:0.58\n",
      "# Training EP:28, B:77, ep.loss:9.24\n",
      "# Test target:0, avg.loss:0.01, avg.prob.:0.99, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.70, avg.prob.:0.56, avg.acc.:0.56\n",
      "# Training EP:29, B:77, ep.loss:13.28\n",
      "# Test target:0, avg.loss:0.04, avg.prob.:0.96, avg.acc.:0.99\n",
      "# Test target:1, avg.loss:1.24, avg.prob.:0.54, avg.acc.:0.54\n",
      "# Training EP:30, B:77, ep.loss:12.81\n",
      "# Test target:0, avg.loss:0.02, avg.prob.:0.98, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.36, avg.prob.:0.57, avg.acc.:0.57\n",
      "# Training EP:31, B:77, ep.loss:11.19\n",
      "# Test target:0, avg.loss:0.04, avg.prob.:0.96, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.03, avg.prob.:0.60, avg.acc.:0.59\n",
      "# Training EP:32, B:77, ep.loss:12.50\n",
      "# Test target:0, avg.loss:0.09, avg.prob.:0.91, avg.acc.:0.99\n",
      "# Test target:1, avg.loss:0.69, avg.prob.:0.67, avg.acc.:0.62\n",
      "# Training EP:33, B:77, ep.loss:11.67\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:0.86, avg.prob.:0.64, avg.acc.:0.62\n",
      "# Training EP:34, B:77, ep.loss:11.74\n",
      "# Test target:0, avg.loss:0.04, avg.prob.:0.97, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.31, avg.prob.:0.56, avg.acc.:0.53\n",
      "# Training EP:35, B:77, ep.loss:13.70\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.07, avg.prob.:0.65, avg.acc.:0.62\n",
      "# Training EP:36, B:77, ep.loss:9.45\n",
      "# Test target:0, avg.loss:0.04, avg.prob.:0.96, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.48, avg.prob.:0.60, avg.acc.:0.58\n",
      "# Training EP:37, B:77, ep.loss:12.54\n",
      "# Test target:0, avg.loss:0.03, avg.prob.:0.97, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.19, avg.prob.:0.62, avg.acc.:0.60\n",
      "# Training EP:38, B:77, ep.loss:10.54\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.30, avg.prob.:0.62, avg.acc.:0.59\n",
      "# Training EP:39, B:77, ep.loss:8.35\n",
      "# Test target:0, avg.loss:0.02, avg.prob.:0.98, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.47, avg.prob.:0.62, avg.acc.:0.61\n",
      "# Training EP:40, B:77, ep.loss:10.20\n",
      "# Test target:0, avg.loss:0.04, avg.prob.:0.96, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.15, avg.prob.:0.63, avg.acc.:0.61\n",
      "# Training EP:41, B:77, ep.loss:10.50\n",
      "# Test target:0, avg.loss:0.03, avg.prob.:0.97, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.10, avg.prob.:0.64, avg.acc.:0.62\n",
      "# Training EP:42, B:77, ep.loss:12.26\n",
      "# Test target:0, avg.loss:0.07, avg.prob.:0.94, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:0.76, avg.prob.:0.66, avg.acc.:0.62\n",
      "# Training EP:43, B:77, ep.loss:13.98\n",
      "# Test target:0, avg.loss:0.04, avg.prob.:0.96, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:0.90, avg.prob.:0.63, avg.acc.:0.61\n",
      "# Training EP:44, B:77, ep.loss:10.78\n",
      "# Test target:0, avg.loss:0.04, avg.prob.:0.96, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:0.86, avg.prob.:0.66, avg.acc.:0.63\n",
      "# Training EP:45, B:77, ep.loss:12.35\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.34, avg.prob.:0.59, avg.acc.:0.58\n",
      "# Training EP:46, B:77, ep.loss:9.82\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:0.97, avg.prob.:0.67, avg.acc.:0.63\n",
      "# Training EP:47, B:77, ep.loss:10.93\n",
      "# Test target:0, avg.loss:0.07, avg.prob.:0.94, avg.acc.:0.99\n",
      "# Test target:1, avg.loss:0.89, avg.prob.:0.68, avg.acc.:0.63\n",
      "# Training EP:48, B:77, ep.loss:10.15\n",
      "# Test target:0, avg.loss:0.05, avg.prob.:0.95, avg.acc.:0.99\n",
      "# Test target:1, avg.loss:0.77, avg.prob.:0.68, avg.acc.:0.64\n",
      "# Training EP:49, B:77, ep.loss:11.65\n",
      "# Test target:0, avg.loss:0.06, avg.prob.:0.95, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.09, avg.prob.:0.68, avg.acc.:0.64\n",
      "# Training EP:50, B:77, ep.loss:9.27\n",
      "# Test target:0, avg.loss:0.02, avg.prob.:0.98, avg.acc.:1.00\n",
      "# Test target:1, avg.loss:1.06, avg.prob.:0.64, avg.acc.:0.63\n",
      "# Training EP:51, B:1, ep.loss:0.07"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-46293f08981b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRankerTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_ranker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mld_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mld_testpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mld_testneg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-fbb503d2fb64>\u001b[0m in \u001b[0;36mRankerTrainer\u001b[0;34m(p_config, p_model, p_ld_train_data, p_ld_testpos_data, p_ld_testneg_data, p_optim, p_lossfn)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepoch_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_violin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_ld_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f84e3503abb0>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, p_ind)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 )\n\u001b[1;32m     64\u001b[0m                 \u001b[0mtmp_ps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_by_prog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_prog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mtmp_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_ps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtmp_check\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0;31m# succeed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/MorpheusInterpreter.py\u001b[0m in \u001b[0;36msanity_check\u001b[0;34m(self, p_ps)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mtmp_psze\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_prog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ApplyNode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 tmp_shadow_max = self.renv(\"max({})\".format(\n\u001b[0;32m--> 241\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shadow_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_prog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mps_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m                     ))[0]\n\u001b[1;32m    243\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtmp_shadow_max\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtmp_psze\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStrSexpVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_ae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_globalenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__rname__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__rname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    822\u001b[0m                             '1 positional argument')\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m_rpy2py_sexpclosure\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdefault_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSexpClosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_rpy2py_sexpclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignatureTranslatedFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sexp, init_prm_translate, on_conflict, symbol_r2python, symbol_check_after)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mprm_translate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_prm_translate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mformals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sexp__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNULL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sexp__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             (symbol_mapping,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36mformals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mR\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;34m'formals()'\u001b[0m \u001b[0mwould\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_formals_fixed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m_formals_fixed\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_formals_fixed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__is_null\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNULL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/conversion.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cdata_res_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# TODO: test cdata is of the expected CType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cdata_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m                 openrlib.rlib.R_tryEval(\n\u001b[1;32m    769\u001b[0m                     \u001b[0mcall_r\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m                     \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobalenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sexp__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m                     error_occured))\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_occured\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/sexp.py\u001b[0m in \u001b[0;36m__sexp__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mR\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mcapsule\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mequal\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         type of the old capsule. A ValueError is raised otherwise.\"\"\"\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sexpobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m__sexp__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RankerTrainer(m_config, m_ranker, ld_train, ld_testpos, ld_testneg, optimizer, lossfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
