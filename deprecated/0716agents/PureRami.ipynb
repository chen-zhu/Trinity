{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaNeo\n",
    "- AlphaNeo with Pre-Trained Ranker\n",
    "- Stage: Cambrian\n",
    "- Version: Spriggina\n",
    "- **Notice: small changes to ValueEncoder (sigmoid to relu)**\n",
    "\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueEncoder(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(ValueEncoder, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.vocab_size = self.config[\"val\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"val\"][\"embd_dim\"]\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embd_dim,\n",
    "            self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels = self.config[\"val\"][\"embd_dim\"],\n",
    "            out_channels = self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            kernel_size = self.config[\"val\"][\"conv_kernel_size\"],\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = self.config[\"val\"][\"pool_kernel_size\"],\n",
    "            padding = self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            self.config[\"embd_dim\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, bp_map):\n",
    "        # batched maps, (B, map_r, map_c)\n",
    "        # in this version, every value only contains 1 map\n",
    "        B = bp_map.shape[0]\n",
    "        \n",
    "        # (B, map_r, map_c, val_embd_dim) -> (B, val_embd_dim, map_r, map_c)\n",
    "        d_embd = self.embedding(bp_map).permute(0,3,1,2)\n",
    "        \n",
    "        # (B, n_kernel, map_r, 1)\n",
    "        d_conv = F.relu(self.conv(d_embd))\n",
    "        \n",
    "        # (B, n_kernel)\n",
    "        d_pool = self.pool(d_conv).view(B,self.config[\"val\"][\"conv_n_kernels\"])\n",
    "        \n",
    "        # (B, embd_dim)\n",
    "        # d_out = torch.sigmoid(\n",
    "        d_out = F.relu(\n",
    "            self.fc(d_pool)\n",
    "        )\n",
    "        \n",
    "        return d_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorphTransE(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(MorphTransE, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.value_encoder = ValueEncoder(p_config=p_config)\n",
    "        \n",
    "        self.fn_vocab_size = self.config[\"fn\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"embd_dim\"]\n",
    "        \n",
    "        self.fn_embedding = nn.Embedding(\n",
    "            self.fn_vocab_size,\n",
    "            self.embd_dim,\n",
    "        )\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fn_embedding.weight.data)\n",
    "        self.fn_embedding.weight.data = F.normalize(\n",
    "            self.fn_embedding.weight.data, p=2, dim=1,\n",
    "        )\n",
    "# ----> skip the forward part since we don't need it <---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(TransNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        # predict a fixed number of shells\n",
    "#         self.policy = nn.Linear(\n",
    "#             self.config[\"embd_dim\"],\n",
    "#             self.config[\"fn\"][\"vocab_size\"],\n",
    "#         )\n",
    "        \n",
    "        # deeper\n",
    "        self.policy0 = nn.Linear(\n",
    "            self.config[\"embd_dim\"],\n",
    "            2048,\n",
    "        )\n",
    "        self.policy1 = nn.Linear(\n",
    "            2048,\n",
    "            self.config[\"fn\"][\"vocab_size\"],\n",
    "        )\n",
    "        \n",
    "        self.value_encoder = ValueEncoder(p_config=p_config)\n",
    "        \n",
    "    def forward(self, p_mapin, p_mapout):\n",
    "        # p_mapin/p_mapout: (B, map_r, map_c)\n",
    "        v_in = self.value_encoder(p_mapin) # (B, embd_dim)\n",
    "        v_out= self.value_encoder(p_mapout) # (B, embd_dim)\n",
    "        v_delta = v_out - v_in\n",
    "#         tmp_out = torch.log_softmax(\n",
    "#             self.policy(v_delta),dim=1\n",
    "#         )\n",
    "        tmp_out = torch.log_softmax(\n",
    "            self.policy1(\n",
    "                F.relu(\n",
    "                    self.policy0(\n",
    "                        v_delta\n",
    "                    )\n",
    "                )\n",
    "            ),dim=1\n",
    "        )\n",
    "        \n",
    "        return tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranker(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(Ranker, self).__init__()\n",
    "        self.config = p_config\n",
    "        self.value_encoder = ValueEncoder(p_config=p_config)\n",
    "        self.fc0 = nn.Linear(\n",
    "            self.config[\"embd_dim\"]*2,\n",
    "            2048,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            2048,\n",
    "            2,\n",
    "        )\n",
    "        \n",
    "    '''\n",
    "    do not use forward function in actual testing, it's only for training\n",
    "    '''\n",
    "    def forward(self, pA, pB, pC, pD):\n",
    "        # pA/pB/pC/pD: (B=1, map_r, map_c)\n",
    "        \n",
    "        # (B, embd_dim)\n",
    "        vA = self.value_encoder(pA)\n",
    "        vB = self.value_encoder(pB)\n",
    "        vC = self.value_encoder(pC)\n",
    "        vD = self.value_encoder(pD)\n",
    "        \n",
    "        # (B=2, embd_dim * 2)\n",
    "        vPOS = torch.cat(\n",
    "            [\n",
    "                torch.cat([vA,vB],dim=1),\n",
    "                torch.cat([vA,vC],dim=1),\n",
    "            ],dim=0\n",
    "        )\n",
    "        \n",
    "        # (B=10, embd_dim * 2)\n",
    "        vNEG = torch.cat(\n",
    "            [\n",
    "                torch.cat([vB,vA],dim=1),\n",
    "                torch.cat([vB,vC],dim=1),\n",
    "                torch.cat([vC,vA],dim=1),\n",
    "                torch.cat([vC,vB],dim=1),\n",
    "            ],dim=0\n",
    "        )\n",
    "        \n",
    "        # (B=4*3=12, embd_dim * 2)\n",
    "        vII = torch.cat([vPOS,vNEG],dim=0)\n",
    "        \n",
    "        # == Notice: don't do any activation at the last layer ==\n",
    "        vOO = self.fc1(\n",
    "            F.relu(\n",
    "                self.fc0(\n",
    "                    vII\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        # (B=4*3=12, 2)\n",
    "        \n",
    "        return vOO\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    strictly in this form A->B\n",
    "    '''\n",
    "    def inference(self, pA, pB):\n",
    "        vA = self.value_encoder(pA) # (B, embd_dim)\n",
    "        vB = self.value_encoder(pB) # (B, embd_dim)\n",
    "        vUNK = torch.cat([vA,vB],dim=1) # (B, embd_dim * 2)\n",
    "        vOUT = self.fc1(\n",
    "            F.relu(\n",
    "                self.fc0(\n",
    "                    vUNK\n",
    "                )\n",
    "            )\n",
    "        ) # (B, 2)\n",
    "        vOUT = F.softmax(vOUT, dim=1)\n",
    "        return vOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "meta-test an agent, directly run into testing / online adaptation\n",
    "'''\n",
    "def MetaTest(p_config, p_spec, p_interpreter, p_generator, p_model, p_ranker, p_optim, p_writer):\n",
    "    print(\"# Start Meta-Test...\")\n",
    "    p_ranker.eval()\n",
    "    \n",
    "    nth_attempt = 0 # tell whether to back-prop or not\n",
    "    batch_lossA_list = []\n",
    "    batch_lossD_list = []\n",
    "    \n",
    "    n_solved = 0 # track the number of solved problem\n",
    "    n_attempt_list = [] # track the number of attempts in every episode\n",
    "    \n",
    "    selected_neurons = []\n",
    "    ranker_scores = [] # parallel to selected_neurons, with adjusted scores\n",
    "    dead_neurons = [] # DeepPath: store node with execution error\n",
    "    \n",
    "    for d_episode in range(p_config[\"meta_test\"][\"n_episode\"]):\n",
    "        \n",
    "        # retrieve the given meta-trained model for testing\n",
    "        test_model = copy.deepcopy(p_model)\n",
    "        test_model.train()\n",
    "        \n",
    "        # if doing random meta-testing\n",
    "        # then randomly generate a program for testing\n",
    "        ps_solution = p_generator.get_new_chain_program(\n",
    "            p_config[\"meta_test\"][\"fixed_depth\"],\n",
    "        )\n",
    "        \n",
    "        is_solved = False\n",
    "        \n",
    "        for d_attempt in range(p_config[\"meta_test\"][\"maxn_attempt\"]):\n",
    "            if is_solved:\n",
    "                # already solved in the last attempt, stop\n",
    "                break\n",
    "            \n",
    "            nth_attempt += 1\n",
    "            attempt_reward = None\n",
    "            \n",
    "            # in every new attempt, initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, ps_solution.inputs, ps_solution.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "                \n",
    "            d_step = 0\n",
    "            while d_step<p_config[\"meta_test\"][\"maxn_step\"]:\n",
    "                \n",
    "                # print the training progress\n",
    "                print(\"\\r# AC/EP:{}/{}, AT:{}, SP:{}, DN:{}, avg.attempt:{:.2f}, er:{:.2f}\".format(\n",
    "                    n_solved, d_episode, d_attempt, d_step, \n",
    "                    len(dead_neurons),\n",
    "                    sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else -1,\n",
    "                    p_config[\"meta_test\"][\"exploration_rate\"](d_episode,d_attempt),\n",
    "                ),end=\"\")\n",
    "                \n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                id_current = ps_current.get_strict_frontiers()[0]\n",
    "                var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "                var_output = ps_current.output\n",
    "                \n",
    "                map_current = p_interpreter.camb_get_abs(var_current)\n",
    "                map_output = p_interpreter.camb_get_abs(var_output)\n",
    "                \n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                \n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.long)).cuda()\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.long)).cuda()\n",
    "                else:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.long))\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.long))\n",
    "                    \n",
    "                # (B=1, fn_vocab_size)\n",
    "                td_pred = test_model(td_current, td_output)\n",
    "                \n",
    "                # no hints\n",
    "                if random.random()<=p_config[\"meta_test\"][\"exploration_rate\"](d_episode,d_attempt):\n",
    "                    # exploration\n",
    "                    tmp_id = random.choice(range(len(current_shell_list)))\n",
    "                else:\n",
    "                    # exploitation\n",
    "                    tmp_id = torch.multinomial(td_pred.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "                \n",
    "                # update ps_current\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if update_status:\n",
    "                    # record selected neuron\n",
    "                    selected_neurons.append(td_pred[0,tmp_id])\n",
    "                    \n",
    "                    id_very = ps_current.get_strict_frontiers()[0]\n",
    "                    var_very = ps_current.node_list[id_very].ps_data\n",
    "                    map_very = p_interpreter.camb_get_abs(var_very)\n",
    "                    if use_cuda:\n",
    "                        td_very = Variable(torch.tensor([map_very],dtype=torch.long)).cuda()\n",
    "                    else:\n",
    "                        td_very = Variable(torch.tensor([map_very],dtype=torch.long))\n",
    "                    ranker_scores.append(p_ranker.inference(td_very,td_output)[0,1])\n",
    "                    \n",
    "                    d_step += 1\n",
    "                    \n",
    "                    # succeed\n",
    "                    if ps_current.check_eq() is not None:\n",
    "                        # and solved!\n",
    "                        is_solved = True\n",
    "                        n_solved += 1\n",
    "                        attempt_reward = 1.0\n",
    "                        break\n",
    "                else:\n",
    "                    # DeepPath: fail, add to dead list\n",
    "                    dead_neurons.append(td_pred[0,tmp_id])\n",
    "                    if len(dead_neurons)>p_config[\"meta_test\"][\"dp_cap\"]:\n",
    "                        # exceed the max capacity of dead pool\n",
    "                        break\n",
    "            \n",
    "            # <END_FOR_STEP>\n",
    "            \n",
    "            # check the attempt_reward\n",
    "            if attempt_reward is None:\n",
    "                # means either failure in execution or exceeding max_step\n",
    "                attempt_reward = -1.\n",
    "            \n",
    "            # compute the loss (sequential selected)\n",
    "            for i in range(len(selected_neurons)):\n",
    "                # d_decay = p_config[\"meta_test\"][\"decay_rate\"]**(len(selected_neurons)-1-i)\n",
    "                # batch_lossA_list.append(\n",
    "                #     d_decay*attempt_reward*(-selected_neurons[i]) \n",
    "                # )\n",
    "                if attempt_reward>0: # success\n",
    "                    batch_lossA_list.append(\n",
    "                        attempt_reward*(-selected_neurons[i]) \n",
    "                    )\n",
    "                else: # fail\n",
    "                    if ranker_scores[i]>0.5:\n",
    "                        batch_lossA_list.append(\n",
    "                            0.5*(-selected_neurons[i]) \n",
    "                        )\n",
    "                    else:\n",
    "                        batch_lossA_list.append(\n",
    "                            (-0.5)*(-selected_neurons[i]) \n",
    "                        )\n",
    "            \n",
    "            # compute the loss (dead neurons)\n",
    "            for i in range(len(dead_neurons)):\n",
    "                batch_lossD_list.append(\n",
    "                    (-1.)*(-dead_neurons[i])\n",
    "                )\n",
    "            \n",
    "            if is_solved or nth_attempt>=p_config[\"meta_test\"][\"batch_size\"]:\n",
    "                # directly do the back-prop\n",
    "                if len(batch_lossD_list)>0:\n",
    "                    batch_lossD = sum(batch_lossD_list)/len(batch_lossD_list)\n",
    "                    p_optim.zero_grad()\n",
    "                    batch_lossD.backward()\n",
    "                    p_optim.step()\n",
    "                \n",
    "                if len(batch_lossA_list)>0:\n",
    "                    batch_lossA = sum(batch_lossA_list)/len(batch_lossA_list)\n",
    "                    p_optim.zero_grad()\n",
    "                    batch_lossA.backward()\n",
    "                    p_optim.step()\n",
    "            \n",
    "                nth_attempt = 0\n",
    "                batch_lossA_list = []\n",
    "                batch_lossD_list = []\n",
    "                selected_neurons = []\n",
    "                ranker_scores = []\n",
    "                dead_neurons = []\n",
    "                \n",
    "        # <END_FOR_ATTEMPT>     \n",
    "        \n",
    "        # after all the attempts\n",
    "        n_attempt_list.append(d_attempt)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\n",
    "                'avg.attempt',\n",
    "                sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else 0,\n",
    "                len(n_attempt_list),\n",
    "            )\n",
    "        \n",
    "#         if d_episode%100==0:\n",
    "#             # save the model\n",
    "#             torch.save(\n",
    "#                 p_model.state_dict(),\n",
    "#                 \"./saved_models/0713CAMB_RL2_camb3_ep{}.pt\".format(d_episode)\n",
    "#             )\n",
    "            \n",
    "    # <END_FOR_EPISODE>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    ")\n",
    "\n",
    "# dumb variable to help infer the shells\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")\n",
    "\n",
    "m_config = {\n",
    "    # ==== TransE Setting ==== #\n",
    "    \"val\":{\n",
    "        \"vocab_size\": len(m_interpreter.CAMB_LIST),\n",
    "        \"embd_dim\": 16, # embedding dim of CAMB abstract token\n",
    "        \"conv_n_kernels\": 512,\n",
    "        \"conv_kernel_size\": (1,m_interpreter.CAMB_NCOL), \n",
    "        \"pool_kernel_size\": (m_interpreter.CAMB_NROW,1), \n",
    "        \"IDX_PAD\": 0,\n",
    "    },\n",
    "    \"fn\":{\n",
    "        \"vocab_size\": len(m_ps.get_neighboring_shells())\n",
    "    },\n",
    "    \"embd_dim\": 128,\n",
    "    \"ranker\":{\n",
    "        \"from\": \"./saved_models/Zaina_ep52.pt\",\n",
    "    },\n",
    "    \"meta_test\":{\n",
    "        \"n_episode\": 100000,\n",
    "        \"batch_size\": 1, # how many attempts\n",
    "        \"fixed_depth\": 3,\n",
    "        \"maxn_attempt\": 100,\n",
    "        \"maxn_step\": 2, # program size\n",
    "        \"exploration_rate\": lambda pep,pat:0.1,\n",
    "        \"decay_rate\": 0.9,\n",
    "        \"dp_cap\": 50,\n",
    "    },\n",
    "}\n",
    "\n",
    "trans_neo = TransNeo(p_config=m_config)\n",
    "ranker = Ranker(p_config=m_config)\n",
    "ranker.load_state_dict(torch.load(m_config[\"ranker\"][\"from\"]))\n",
    "if use_cuda:\n",
    "    trans_neo = trans_neo.cuda()\n",
    "    ranker = ranker.cuda()\n",
    "optimizer = torch.optim.Adam(list(trans_neo.parameters()))\n",
    "\n",
    "# writer = SummaryWriter(\"runs/0713CAMB_RL2_camb3\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val': {'vocab_size': 150,\n",
       "  'embd_dim': 16,\n",
       "  'conv_n_kernels': 512,\n",
       "  'conv_kernel_size': (1, 15),\n",
       "  'pool_kernel_size': (15, 1),\n",
       "  'IDX_PAD': 0},\n",
       " 'fn': {'vocab_size': 120},\n",
       " 'embd_dim': 128,\n",
       " 'ranker': {'from': './saved_models/Zaina_ep52.pt'},\n",
       " 'meta_test': {'n_episode': 100000,\n",
       "  'batch_size': 1,\n",
       "  'fixed_depth': 3,\n",
       "  'maxn_attempt': 100,\n",
       "  'maxn_step': 2,\n",
       "  'exploration_rate': <function __main__.<lambda>(pep, pat)>,\n",
       "  'decay_rate': 0.9,\n",
       "  'dp_cap': 50}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start Meta-Test...\n",
      "# AC/EP:17/97, AT:35, SP:0, DN:1, avg.attempt:91.53, er:0.10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-61acaac36533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMetaTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_interpreter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_neo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-766b71bc72de>\u001b[0m in \u001b[0;36mMetaTest\u001b[0;34m(p_config, p_spec, p_interpreter, p_generator, p_model, p_ranker, p_optim, p_writer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mvar_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps_current\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mmap_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamb_get_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0mmap_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamb_get_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/MorpheusInterpreter.py\u001b[0m in \u001b[0;36mcamb_get_abs\u001b[0;34m(self, p_obj)\u001b[0m\n\u001b[1;32m    818\u001b[0m     '''\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcamb_get_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mnp_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamb_get_np_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0mhash_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAMB_NROW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAMB_NCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/MorpheusInterpreter.py\u001b[0m in \u001b[0;36mcamb_get_np_obj\u001b[0;34m(self, p_obj)\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                 \u001b[0mnp_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0mnp_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/vectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m   1261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    822\u001b[0m                             '1 positional argument')\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36msexpvector_to_ro\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    112\u001b[0m                                        vectors.IntMatrix, vectors.IntArray)\n\u001b[1;32m    113\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREALSXP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrclass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'POSIXct'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSIXct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/sexp.py\u001b[0m in \u001b[0;36mrclass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'StrSexpVector'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;34m\"\"\"Get or set the R \"class\" attribute for the object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrclass_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sexp__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/sexp.py\u001b[0m in \u001b[0;36mrclass_get\u001b[0;34m(scaps)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0mtypeof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRTYPES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                 classname = _DEFAULT_RCLASS_NAMES.get(\n\u001b[0;32m--> 516\u001b[0;31m                     typeof, str(typeof))\n\u001b[0m\u001b[1;32m    517\u001b[0m             classes = StrSexpVector.from_iterable(\n\u001b[1;32m    518\u001b[0m                 [classname])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MetaTest(m_config, m_spec, m_interpreter, m_generator, trans_neo, ranker, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = m_interpreter.random_table()\n",
    "map1 = m_interpreter.camb_get_abs(var1)\n",
    "td1 = Variable(torch.tensor([map1],dtype=torch.long)).cuda()\n",
    "print(var1)\n",
    "m_interpreter.print_obj(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2 = m_interpreter.random_table()\n",
    "map2 = m_interpreter.camb_get_abs(var2)\n",
    "td2 = Variable(torch.tensor([map2],dtype=torch.long)).cuda()\n",
    "print(var2)\n",
    "m_interpreter.print_obj(var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter.renv('TEST1 <- select({},1,2)'.format(var1))\n",
    "var3 = 'TEST1'\n",
    "map3 = m_interpreter.camb_get_abs(var3)\n",
    "td3 = Variable(torch.tensor([map3],dtype=torch.long)).cuda()\n",
    "m_interpreter.print_obj(var3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter.renv('TEST2 <- unite({},\"new\",c(1),c(2))'.format(var3))\n",
    "var4 = 'TEST2'\n",
    "map4 = m_interpreter.camb_get_abs(var4)\n",
    "td4 = Variable(torch.tensor([map4],dtype=torch.long)).cuda()\n",
    "m_interpreter.print_obj(var4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var3 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.inference(td1,td2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.inference(td1,td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.inference(td1,td4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.inference(td3,td4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker.inference(td2,td4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
