{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component/Abstraction Representation Learning using TransE\n",
    "- Stage: Cambrian\n",
    "- Version: Charniodiscus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlgoDataset(Dataset):\n",
    "    def __init__(self, p_len):\n",
    "        self.len = p_len\n",
    "        self.max_num = 32\n",
    "        self.min_num = -32\n",
    "        self.vals = [i for i in range(self.min_num,self.max_num+1)]\n",
    "        self.fns = [\n",
    "            \n",
    "#             lambda x:self.rectify(x+2),\n",
    "#             lambda x:self.rectify(x+3),\n",
    "#             lambda x:self.rectify(x+4),\n",
    "#             lambda x:self.rectify(x+5),\n",
    "#             lambda x:self.rectify(x+6),\n",
    "#             lambda x:self.rectify(x-2),\n",
    "#             lambda x:self.rectify(x-3),\n",
    "#             lambda x:self.rectify(x-4),\n",
    "#             lambda x:self.rectify(x-5),\n",
    "#             lambda x:self.rectify(x-6),\n",
    "            \n",
    "            lambda x:self.rectify(x+1),\n",
    "            lambda x:self.rectify(x-1),\n",
    "            lambda x:self.rectify(x+2),\n",
    "            lambda x:self.rectify(x-2),\n",
    "            lambda x:self.rectify(x+3),\n",
    "            lambda x:self.rectify(x-3),\n",
    "            lambda x:self.rectify(x+4),\n",
    "            lambda x:self.rectify(x-4),\n",
    "            lambda x:self.rectify(x+5),\n",
    "            lambda x:self.rectify(x-5),\n",
    "            \n",
    "            lambda x:self.rectify(x+6),\n",
    "            lambda x:self.rectify(x-6),\n",
    "        ]\n",
    "        self.val2id = {\n",
    "            self.vals[i]:i for i in range(len(self.vals))\n",
    "        }\n",
    "        \n",
    "    def rectify(self,x):\n",
    "#         dx = int(x)\n",
    "#         if dx>self.max_num:\n",
    "#             return self.max_num\n",
    "#         elif dx<self.min_num:\n",
    "#             return self.min_num\n",
    "#         else:\n",
    "#             return dx\n",
    "        return int(x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, p_ind):\n",
    "        while True:\n",
    "            tmp_in = random.choice(range(len(self.vals)))\n",
    "            tmp_fn = random.choice(range(len(self.fns)))\n",
    "            tmp_out = self.fns[tmp_fn](self.vals[tmp_in]) # still a value\n",
    "            if tmp_out>self.max_num or tmp_out<self.min_num:\n",
    "                continue\n",
    "            else:\n",
    "                tmp_out = self.val2id[tmp_out]\n",
    "                break\n",
    "                \n",
    "        # in this version, just replace the function called\n",
    "        while True:\n",
    "            rep_fn = random.choice(range(len(self.fns)))\n",
    "            rep_in = tmp_in\n",
    "            rep_out = tmp_out\n",
    "            if self.vals[rep_out]==self.fns[rep_fn](self.vals[rep_in]):\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return (tmp_in, tmp_fn, tmp_out,\n",
    "                rep_in, rep_fn, rep_out,)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarginLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pos, neg, margin):\n",
    "        if use_cuda:\n",
    "            zero_tensor = torch.tensor(pos.size(),dtype=torch.float).cuda()\n",
    "        else:\n",
    "            zero_tensor = torch.tensor(pos.size(),dtype=torch.float)\n",
    "        zero_tensor.zero_()\n",
    "        zero_tensor = Variable(zero_tensor)\n",
    "        return torch.sum(torch.max(pos - neg + margin, zero_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_loss(embeddings, dim=1):\n",
    "    norm = torch.sum(embeddings ** 2, dim=dim, keepdim=True)\n",
    "    if use_cuda:\n",
    "        return torch.sum(\n",
    "            torch.max(\n",
    "                norm - Variable(torch.tensor([1.0],dtype=torch.float)).cuda(), \n",
    "                Variable(torch.tensor([0.0],dtype=torch.float)).cuda(),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        return torch.sum(\n",
    "            torch.max(\n",
    "                norm - Variable(torch.tensor([1.0],dtype=torch.float)), \n",
    "                Variable(torch.tensor([0.0],dtype=torch.float)),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorphTransE(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(MorphTransE, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.val_vocab_size = self.config[\"val\"][\"vocab_size\"]\n",
    "        self.fn_vocab_size = self.config[\"fn\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"embd_dim\"]\n",
    "        \n",
    "        self.val_embedding = nn.Embedding(\n",
    "            self.val_vocab_size,\n",
    "            self.embd_dim,\n",
    "#             max_norm=1,\n",
    "        )\n",
    "        self.fn_embedding = nn.Embedding(\n",
    "            self.fn_vocab_size,\n",
    "            self.embd_dim,\n",
    "#             max_norm=1,\n",
    "        )\n",
    "        \n",
    "#         print(\"val-before:\")\n",
    "#         print(self.val_embedding.weight.data)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.val_embedding.weight.data)\n",
    "        self.val_embedding.weight.data = F.normalize(\n",
    "            self.val_embedding.weight.data, p=2, dim=1,\n",
    "        )\n",
    "        \n",
    "#         print(\"val-after:\")\n",
    "#         print(self.val_embedding.weight.data)\n",
    "#         input(\"PAUSE--0\")\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fn_embedding.weight.data)\n",
    "        self.fn_embedding.weight.data = F.normalize(\n",
    "            self.fn_embedding.weight.data, p=2, dim=1,\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, batch_triplets):\n",
    "        # print(\"batch_triplets:{}\".format(batch_triplets))\n",
    "        \n",
    "        v_in = self.val_embedding(batch_triplets[0])\n",
    "        v_fn = self.fn_embedding(batch_triplets[1])\n",
    "        v_out = self.val_embedding(batch_triplets[2])\n",
    "        \n",
    "        r_in = self.val_embedding(batch_triplets[3])\n",
    "        r_fn = self.fn_embedding(batch_triplets[4])\n",
    "        r_out = self.val_embedding(batch_triplets[5])\n",
    "        \n",
    "        pos_score = torch.sum((v_in + v_fn - v_out) ** 2, 1)\n",
    "        neg_score = torch.sum((r_in + r_fn - r_out) ** 2, 1)\n",
    "        # pos_score = torch.sum(torch.abs(v_in + v_fn - v_out), 1)\n",
    "        # neg_score = torch.sum(torch.abs(r_in + r_fn - r_out), 1)\n",
    "        \n",
    "        # (B, 1), ..\n",
    "        return (pos_score, neg_score)\n",
    "    \n",
    "    def dbg_infer_fn(self, ios):\n",
    "        # ios: (\n",
    "        #   (B, n_maps, map_r, map_c), --> input\n",
    "        #   (B, n_maps, map_r, map_c), --> output\n",
    "        # )\n",
    "        B = ios[0].shape[0]\n",
    "        \n",
    "        v_in = self.val_embedding(ios[0]) # (B, embd_dim)\n",
    "        v_out = self.val_embedding(ios[1]) # (B, embd_dim)\n",
    "        \n",
    "        est_fn = v_out-v_in # (B, embd_dim)\n",
    "        # print(est_fn.shape)\n",
    "        # print(self.fn_embedding.weight.data.shape)\n",
    "        # input(\"PAUSE\")\n",
    "        \n",
    "        nest_fn = est_fn.data.cpu().numpy()\n",
    "        nest_embd = self.fn_embedding.weight.data.cpu().numpy()\n",
    "        dist = pairwise_distances(nest_fn,nest_embd,metric='euclidean')\n",
    "            \n",
    "        return dist\n",
    "    \n",
    "    def infer_fn(self, ios):\n",
    "        # ios: (\n",
    "        #   (B, n_maps, map_r, map_c), --> input\n",
    "        #   (B, n_maps, map_r, map_c), --> output\n",
    "        # )\n",
    "        B = ios[0].shape[0]\n",
    "        \n",
    "        v_in = self.val_embedding(ios[0]) # (B, embd_dim)\n",
    "        v_out = self.val_embedding(ios[1]) # (B, embd_dim)\n",
    "        \n",
    "        est_fn = v_out-v_in # (B, embd_dim)\n",
    "        # print(est_fn.shape)\n",
    "        # print(self.fn_embedding.weight.data.shape)\n",
    "        # input(\"PAUSE\")\n",
    "        \n",
    "        dlist = []\n",
    "        for i in range(B):\n",
    "            sublist = []\n",
    "            for j in range(self.fn_vocab_size):\n",
    "                sublist.append(\n",
    "                    torch.dist(est_fn[i,:], self.fn_embedding.weight.data[j,:]) # (1,)\n",
    "                )\n",
    "            dlist.append(\n",
    "                torch.tensor([sublist])\n",
    "            )\n",
    "        \n",
    "        ret_dlist = torch.cat(dlist,dim=0)\n",
    "        # print(ret_dlist.shape)\n",
    "        # input(\"PAUSE____\")\n",
    "        \n",
    "        return ret_dlist\n",
    "    \n",
    "    def infer_output(self, ifs):\n",
    "        # input/function-s\n",
    "        B = ifs[0].shape[0]\n",
    "        \n",
    "        v_in = self.val_embedding(ifs[0])\n",
    "        v_fn = self.fn_embedding(ifs[1])\n",
    "        \n",
    "        est_out = v_in + v_fn # (B, embd_dim)\n",
    "        \n",
    "        dlist = []\n",
    "        for i in range(B):\n",
    "            sublist = []\n",
    "            for j in range(self.val_vocab_size):\n",
    "                sublist.append(\n",
    "                    torch.dist(est_out[i,:], self.val_embedding.weight.data[j,:]) # (1,)\n",
    "                )\n",
    "            dlist.append(\n",
    "                torch.tensor([sublist])\n",
    "            )\n",
    "            \n",
    "        ret_dlist = torch.cat(dlist,dim=0)\n",
    "        return ret_dlist\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "use the same ld in trainer if sampling randomly every time\n",
    "'''\n",
    "def MTETester(p_model, p_ld_data):\n",
    "    \n",
    "#     # ### OUTPUT prediction ### #\n",
    "#     rank_list = []\n",
    "#     for batch_idx, bts in enumerate(p_ld_data):\n",
    "#         p_model.eval()\n",
    "#         B = bts[0].shape[0]\n",
    "        \n",
    "#         if use_cuda:\n",
    "#             td_bts = [Variable(bts[i]).cuda() for i in range(len(bts))]\n",
    "#         else:\n",
    "#             td_bts = [Variable(bts[i]) for i in range(len(bts))]\n",
    "        \n",
    "#         # feed the true input and output, and infer the function\n",
    "#         # return the function scores\n",
    "#         # (B, fn_vocab_size)\n",
    "        \n",
    "#         d_scores = p_model.infer_output(\n",
    "#             (td_bts[0],td_bts[1])\n",
    "#         )\n",
    "#         sorted_scores = torch.argsort(d_scores,dim=1).cpu().numpy()\n",
    "#         for i in range(B):\n",
    "#             rank_list.append(\n",
    "#                 sorted_scores[i,:].tolist().index(bts[2][i])\n",
    "#                 # sorted_scores[i,bts[2][i]].item()\n",
    "#             )\n",
    "            \n",
    "#         print(\"\\r# TEST/OUTPUT B:{}\".format(batch_idx),end=\"\")\n",
    "        \n",
    "#     print()\n",
    "#     print(\"# TEST/OUTPUT avg.rank:{:.2f}, b:{:.2f}, w:{:.2f}, 50p:{:.2f}, 75p:{:.2f}, 90p:{:.2f}\".format(\n",
    "#         sum(rank_list)/len(rank_list), \n",
    "#         min(rank_list), \n",
    "#         max(rank_list), \n",
    "#         np.percentile(rank_list,50),\n",
    "#         np.percentile(rank_list,75),\n",
    "#         np.percentile(rank_list,90)\n",
    "#     ))\n",
    "    \n",
    "    \n",
    "    # ### FUNCTION prediction ### #\n",
    "    rank_list = []\n",
    "    for batch_idx, bts in enumerate(p_ld_data):\n",
    "        p_model.eval()\n",
    "        B = bts[0].shape[0]\n",
    "        \n",
    "        if use_cuda:\n",
    "            td_bts = [Variable(bts[i]).cuda() for i in range(len(bts))]\n",
    "        else:\n",
    "            td_bts = [Variable(bts[i]) for i in range(len(bts))]\n",
    "        \n",
    "        # feed the true input and output, and infer the function\n",
    "        # return the function scores\n",
    "        # (B, fn_vocab_size)\n",
    "        \n",
    "        d_scores = p_model.infer_fn(\n",
    "            (td_bts[0],td_bts[2])\n",
    "        )\n",
    "        \n",
    "#         d_scores = p_model.dbg_infer_fn(\n",
    "#             (td_bts[0],td_bts[2])\n",
    "#         )\n",
    "        \n",
    "        sorted_scores = torch.argsort(d_scores,dim=1).cpu().numpy()\n",
    "#         sorted_scores = np.argsort(d_scores,axis=1)\n",
    "        # print(sorted_scores.shape)\n",
    "        # print(sorted_scores)\n",
    "        # input(\"PAUSE\")\n",
    "        for i in range(B):\n",
    "            rank_list.append(\n",
    "                sorted_scores[i,:].tolist().index(bts[1][i])\n",
    "                # sorted_scores[i,bts[2][i]].item()\n",
    "            )\n",
    "            \n",
    "        print(\"\\r# TEST/FUNCTION B:{}\".format(batch_idx),end=\"\")\n",
    "        \n",
    "    print()\n",
    "    print(\"# TEST/FUNCTION avg.rank:{:.2f}, b:{:.2f}, w:{:.2f}, 50p:{:.2f}, 75p:{:.2f}, 90p:{:.2f}\".format(\n",
    "        sum(rank_list)/len(rank_list), \n",
    "        min(rank_list), \n",
    "        max(rank_list), \n",
    "        np.percentile(rank_list,50),\n",
    "        np.percentile(rank_list,75),\n",
    "        np.percentile(rank_list,90)\n",
    "    ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MTETrainer(p_nep, p_model, p_ld_train, p_ld_test, p_optim, p_lossfn):\n",
    "    MTETester(p_model, p_ld_test)\n",
    "    for d_ep in range(p_nep):\n",
    "        train_loss_list = []\n",
    "        for batch_idx, bts in enumerate(p_ld_train):\n",
    "            p_model.train()\n",
    "            if use_cuda:\n",
    "                td_bts = [Variable(bts[i]).cuda() for i in range(len(bts))]\n",
    "            else:\n",
    "                td_bts = [Variable(bts[i]) for i in range(len(bts))]\n",
    "            \n",
    "            d_scores = p_model(td_bts) # (pos,neg)\n",
    "            p_optim.zero_grad()\n",
    "            if use_cuda:\n",
    "                margin = Variable(torch.tensor([1],dtype=torch.float)).cuda()\n",
    "            else:\n",
    "                margin = Variable(torch.tensor([1],dtype=torch.float))\n",
    "            d_loss = p_lossfn(d_scores[0],d_scores[1],margin)\n",
    "            d_loss += norm_loss(p_model.val_embedding(td_bts[0]))\n",
    "            d_loss += norm_loss(p_model.fn_embedding(td_bts[1]))\n",
    "            d_loss += norm_loss(p_model.val_embedding(td_bts[2]))\n",
    "            d_loss += norm_loss(p_model.val_embedding(td_bts[3]))\n",
    "            d_loss += norm_loss(p_model.fn_embedding(td_bts[4]))\n",
    "            d_loss += norm_loss(p_model.val_embedding(td_bts[5]))\n",
    "            train_loss_list.append(d_loss)\n",
    "            d_loss.backward()\n",
    "            p_optim.step()\n",
    "            \n",
    "            print(\"\\r# TRAIN EP{}, B:{}, L:{:.4f}, AvgL:{:.4f}\".format(\n",
    "                d_ep, batch_idx, d_loss,\n",
    "                float(sum(train_loss_list))/float(len(train_loss_list))\n",
    "            ),end=\"\")\n",
    "        print()\n",
    "        if d_ep%10==0:\n",
    "            MTETester(p_model, p_ld_test)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_mg_train = AlgoDataset(p_len=980000)\n",
    "ld_mg_train = DataLoader(dataset=dt_mg_train, batch_size=9800, shuffle=False)\n",
    "\n",
    "dt_mg_test = AlgoDataset(p_len=10000)\n",
    "ld_mg_test = DataLoader(dataset=dt_mg_test, batch_size=8, shuffle=False)\n",
    "\n",
    "m_config = {\n",
    "    \"val\":{\n",
    "        \"vocab_size\":len(dt_mg_train.vals),\n",
    "    },\n",
    "    \"fn\":{\n",
    "        \"vocab_size\":len(dt_mg_train.fns),\n",
    "    },\n",
    "    \"embd_dim\":128,\n",
    "}\n",
    "\n",
    "mte = MorphTransE(p_config=m_config)\n",
    "# m_loss = nn.MarginRankingLoss(margin=m_config[\"margin\"])\n",
    "m_loss = MarginLoss()\n",
    "if use_cuda:\n",
    "    mte = mte.cuda()\n",
    "    m_loss = m_loss.cuda()\n",
    "optimizer = torch.optim.Adam(mte.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val': {'vocab_size': 65}, 'fn': {'vocab_size': 12}, 'embd_dim': 128}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 8, 38, 33, 10, 38)\n",
      "(10, 10, 16, 10, 6, 16)\n",
      "(22, 8, 27, 22, 4, 27)\n",
      "(36, 0, 37, 36, 11, 37)\n",
      "(43, 0, 44, 43, 4, 44)\n",
      "(44, 1, 43, 44, 5, 43)\n",
      "(47, 8, 52, 47, 3, 52)\n",
      "(23, 4, 26, 23, 11, 26)\n",
      "(0, 6, 4, 0, 2, 4)\n",
      "(18, 1, 17, 18, 9, 17)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(dt_mg_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# TEST/FUNCTION B:1249\n",
      "# TEST/FUNCTION avg.rank:5.47, b:0.00, w:11.00, 50p:6.00, 75p:8.00, 90p:10.00\n",
      "# TRAIN EP0, B:99, L:8954.5430, AvgL:9398.4231\n",
      "# TEST/FUNCTION B:1249\n",
      "# TEST/FUNCTION avg.rank:4.88, b:0.00, w:11.00, 50p:4.00, 75p:8.00, 90p:10.00\n",
      "# TRAIN EP1, B:99, L:8257.6318, AvgL:8631.0800\n",
      "# TRAIN EP2, B:99, L:7806.0615, AvgL:8023.9056\n",
      "# TRAIN EP3, B:99, L:7611.5474, AvgL:7667.4606\n",
      "# TRAIN EP4, B:99, L:7471.4717, AvgL:7521.9869\n",
      "# TRAIN EP5, B:99, L:7438.4160, AvgL:7459.1431\n",
      "# TRAIN EP6, B:99, L:7478.4141, AvgL:7420.6763\n",
      "# TRAIN EP7, B:99, L:7347.0479, AvgL:7408.3438\n",
      "# TRAIN EP8, B:99, L:7370.2432, AvgL:7393.7238\n",
      "# TRAIN EP9, B:99, L:7383.8872, AvgL:7390.6769\n",
      "# TRAIN EP10, B:99, L:7415.7095, AvgL:7396.5363\n",
      "# TEST/FUNCTION B:1249\n",
      "# TEST/FUNCTION avg.rank:2.90, b:0.00, w:11.00, 50p:3.00, 75p:4.00, 90p:5.00\n",
      "# TRAIN EP11, B:99, L:7353.1948, AvgL:7391.9294\n",
      "# TRAIN EP12, B:99, L:7374.3008, AvgL:7391.2081\n",
      "# TRAIN EP13, B:99, L:7399.2085, AvgL:7384.8881\n",
      "# TRAIN EP14, B:99, L:7420.8350, AvgL:7395.4550\n",
      "# TRAIN EP15, B:99, L:7409.0200, AvgL:7389.6825\n",
      "# TRAIN EP16, B:99, L:7460.7134, AvgL:7389.6100\n",
      "# TRAIN EP17, B:99, L:7386.2334, AvgL:7393.5850\n",
      "# TRAIN EP18, B:99, L:7352.4272, AvgL:7389.5769\n",
      "# TRAIN EP19, B:99, L:7376.5918, AvgL:7386.2244\n",
      "# TRAIN EP20, B:99, L:7303.3403, AvgL:7384.7675\n",
      "# TEST/FUNCTION B:1249\n",
      "# TEST/FUNCTION avg.rank:2.96, b:0.00, w:11.00, 50p:3.00, 75p:4.00, 90p:5.00\n",
      "# TRAIN EP21, B:99, L:7364.7397, AvgL:7390.6725\n",
      "# TRAIN EP22, B:99, L:7369.5474, AvgL:7383.2350\n",
      "# TRAIN EP23, B:99, L:7362.5049, AvgL:7379.3138\n",
      "# TRAIN EP24, B:99, L:7406.6270, AvgL:7379.5794\n",
      "# TRAIN EP25, B:99, L:7373.2368, AvgL:7381.8219\n",
      "# TRAIN EP26, B:99, L:7371.5801, AvgL:7385.9187\n",
      "# TRAIN EP27, B:99, L:7455.3584, AvgL:7391.7000\n",
      "# TRAIN EP28, B:99, L:7411.9688, AvgL:7385.9225\n",
      "# TRAIN EP29, B:99, L:7388.1274, AvgL:7381.8425\n",
      "# TRAIN EP30, B:99, L:7379.0200, AvgL:7386.3006\n",
      "# TEST/FUNCTION B:1249\n",
      "# TEST/FUNCTION avg.rank:2.91, b:0.00, w:9.00, 50p:3.00, 75p:5.00, 90p:5.00\n",
      "# TRAIN EP31, B:99, L:7397.7080, AvgL:7380.6231\n",
      "# TRAIN EP32, B:99, L:7409.7402, AvgL:7384.2700\n",
      "# TRAIN EP33, B:99, L:7398.6929, AvgL:7381.2156\n",
      "# TRAIN EP34, B:99, L:7391.6948, AvgL:7378.6231\n",
      "# TRAIN EP35, B:99, L:7406.7612, AvgL:7387.2381\n",
      "# TRAIN EP36, B:99, L:7438.2480, AvgL:7387.2669\n",
      "# TRAIN EP37, B:99, L:7380.2900, AvgL:7390.9769\n",
      "# TRAIN EP38, B:99, L:7436.6167, AvgL:7381.1375\n",
      "# TRAIN EP39, B:99, L:7357.0312, AvgL:7382.9237\n",
      "# TRAIN EP40, B:99, L:7352.9116, AvgL:7384.5744\n",
      "# TEST/FUNCTION B:1249\n",
      "# TEST/FUNCTION avg.rank:2.85, b:0.00, w:11.00, 50p:3.00, 75p:4.00, 90p:5.00\n",
      "# TRAIN EP41, B:99, L:7389.7593, AvgL:7385.5181\n",
      "# TRAIN EP42, B:99, L:7407.1904, AvgL:7390.5106\n",
      "# TRAIN EP43, B:99, L:7325.1875, AvgL:7387.7456\n",
      "# TRAIN EP44, B:99, L:7385.1973, AvgL:7386.9656\n",
      "# TRAIN EP45, B:99, L:7379.6562, AvgL:7382.4838\n",
      "# TRAIN EP46, B:99, L:7411.1108, AvgL:7383.3175\n",
      "# TRAIN EP47, B:99, L:7443.6108, AvgL:7385.1300\n",
      "# TRAIN EP48, B:99, L:7391.3447, AvgL:7386.2006\n",
      "# TRAIN EP49, B:99, L:7304.6416, AvgL:7383.6631\n",
      "# TRAIN EP50, B:99, L:7384.0146, AvgL:7382.6375\n",
      "# TEST/FUNCTION B:1249\n",
      "# TEST/FUNCTION avg.rank:3.03, b:0.00, w:11.00, 50p:3.00, 75p:5.00, 90p:5.00\n",
      "# TRAIN EP51, B:99, L:7368.0381, AvgL:7383.9644\n",
      "# TRAIN EP52, B:49, L:7461.6108, AvgL:7384.3713"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b312d53f6add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMTETrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mld_mg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mld_mg_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-b69d8aed4342>\u001b[0m in \u001b[0;36mMTETrainer\u001b[0;34m(p_nep, p_model, p_ld_train, p_ld_test, p_optim, p_lossfn)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0md_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnorm_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd_bts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mp_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MTETrainer(1000000, mte, ld_mg_train, ld_mg_test, optimizer, m_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_mg_train.write_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mte.val_embedding.weight[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mte.val_embedding.weight[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mte.fn_embedding.weight[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mte.val_embedding.weight[0,:] + mte.fn_embedding.weight[0,:] - mte.val_embedding.weight[1,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
