{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaNeo for Max Length of 1 (depth of 2)\n",
    "\n",
    "```\n",
    "tensorboard --logdir runs\n",
    "```\n",
    "\n",
    "```\n",
    "cd ./Trinity/\n",
    "python ./AlphaNeo_Cambrian_pworker.py 1\n",
    "```\n",
    "\n",
    "```\n",
    "nohup jupyter lab > jupyter.log &\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import fcntl\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.interpreter import Interpreter, PostOrderInterpreter, GeneralError, InterpreterError\n",
    "from tyrell.enumerator import Enumerator, SmtEnumerator, RandomEnumerator, DesignatedEnumerator, RandomEnumeratorS, ExhaustiveEnumerator\n",
    "from tyrell.decider import Example, ExampleConstraintPruningDecider, ExampleDecider, TestDecider\n",
    "from tyrell.synthesizer import Synthesizer\n",
    "from tyrell.logger import get_logger\n",
    "from sexpdata import Symbol\n",
    "from tyrell import dsl as D\n",
    "from typing import Callable, NamedTuple, List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "import dill as pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morpheus Version\n",
    "from utils_morpheus import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug block\n",
    "DBG_VAR = None\n",
    "DBG_VAR2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListModule(object):\n",
    "    def __init__(self, module, prefix, *args):\n",
    "        self.module = module\n",
    "        self.prefix = prefix\n",
    "        self.num_module = 0\n",
    "        for new_module in args:\n",
    "            self.append(new_module)\n",
    "    \n",
    "    def append(self, new_module):\n",
    "        if not isinstance(new_module, nn.Module):\n",
    "            raise ValueError('Not a Module')\n",
    "        else:\n",
    "            self.module.add_module(self.prefix + str(self.num_module), new_module)\n",
    "            self.num_module += 1\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.num_module\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i<0 or i>=self.num_module:\n",
    "            raise IndexError('Out of bound')\n",
    "        return getattr(self.module, self.prefix+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Node Encoder for ParamNode & ApplyNode\n",
    "'''\n",
    "class NodeEncoderABS(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(NodeEncoderABS, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.vocab_size = self.config[\"abs\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"abs\"][\"embd_dim\"]\n",
    "        self.node_dim = self.config[\"node_dim\"] # shared between tml/abs\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embd_dim,\n",
    "            self.config[\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.convs = ListModule(self, \"abs_convs_\")\n",
    "        self.pools = ListModule(self, \"abs_pools_\")\n",
    "        for i in range(len(self.config[\"abs\"][\"conv_n_kernels\"])):\n",
    "            self.convs.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels = self.config[\"abs\"][\"embd_dim\"],\n",
    "                    out_channels = self.config[\"abs\"][\"conv_n_kernels\"][i],\n",
    "                    kernel_size = self.config[\"abs\"][\"conv_kernel_sizes\"][i],\n",
    "                )\n",
    "            )\n",
    "            self.pools.append(\n",
    "                nn.MaxPool2d(\n",
    "                    kernel_size = self.config[\"abs\"][\"pool_kernel_sizes\"][i],\n",
    "                    padding = self.config[\"IDX_PAD\"],\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        self.fc = nn.Linear(\n",
    "            sum(self.config[\"abs\"][\"conv_n_kernels\"]),\n",
    "            self.config[\"node_dim\"],\n",
    "        )\n",
    "            \n",
    "    def forward(self, pmaps):\n",
    "        # pmaps: list of maps of batch_size=1\n",
    "        \n",
    "        d_embds = [\n",
    "            self.embedding(pmaps[i]).permute(0,3,1,2)\n",
    "            for i in range(self.config[\"abs\"][\"n_maps\"])\n",
    "            # (1, dim, nrow, ncol) -> (1, n_kernel, nrow, 1)\n",
    "        ]\n",
    "        d_convs = [\n",
    "            F.relu(self.convs[i](d_embds[i]))\n",
    "            for i in range(self.config[\"abs\"][\"n_maps\"])\n",
    "            # (1, dim, nrow, ncol) -> (1, n_kernel, nrow, 1)\n",
    "        ]\n",
    "        d_pools = [\n",
    "            self.pools[i](d_convs[i]).view(1, self.config[\"abs\"][\"conv_n_kernels\"][i])\n",
    "            for i in range(self.config[\"abs\"][\"n_maps\"])\n",
    "            # (1, n_kernel, nrow, 1) -> (1, n_kernel, 1, 1) -> (1, n_kernel)\n",
    "        ]\n",
    "        \n",
    "        d_known = torch.cat(d_pools, dim=1) # (1, n_kernel*n_maps)\n",
    "        d_out = F.relu(self.fc(d_known))\n",
    "        \n",
    "        # (1, node_dim)\n",
    "        return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Node Encoder for AtomNode & Candidate Node\n",
    "'''\n",
    "class NodeEncoderGCN(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(NodeEncoderGCN, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        # NOTICE:\n",
    "        # vocab_size should be the size of all EnumNode only\n",
    "        # no ParamNode are included\n",
    "        self.vocab_size = self.config[\"tml\"][\"vocab_size\"]\n",
    "        self.node_dim = self.config[\"node_dim\"]\n",
    "        \n",
    "        self.tml_h = Parameter(torch.Tensor(\n",
    "            self.vocab_size,\n",
    "            self.node_dim,\n",
    "        ))\n",
    "        self.tml_w = Parameter(torch.Tensor(\n",
    "            self.node_dim,\n",
    "            self.node_dim,\n",
    "        ))\n",
    "        # should initialize the parameter\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def forward(self, adjmtx, sensp):\n",
    "        # adjmtx / (vocab_size+new_n,vocab_size+new_n), no batch: normalized adjacency matrix\n",
    "        # sensp / (new_n, node_dim): stacked new sensed nodes in designated dimension\n",
    "        \n",
    "        # first concatenate the features/node_dim\n",
    "        # (vocab_size+new_n, node_dim)\n",
    "        stacked_h = torch.cat((self.tml_h,sensp),dim=0)\n",
    "        \n",
    "        # then do GCN forward\n",
    "        # don't forget the activation function\n",
    "        # (vocab_size+new_n, node_dim)\n",
    "        out_embd = F.relu(\n",
    "            adjmtx.matmul(stacked_h).matmul(self.tml_w)\n",
    "        )\n",
    "        \n",
    "        return out_embd\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.tml_h)\n",
    "        nn.init.normal_(self.tml_w)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(AlphaNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.abs_encoder = NodeEncoderABS(p_config=p_config)\n",
    "        self.tml_encoder = NodeEncoderGCN(p_config=p_config)\n",
    "        self.policy = nn.Linear(\n",
    "            self.config[\"node_dim\"],\n",
    "            self.config[\"node_dim\"],\n",
    "        )\n",
    "        \n",
    "        # using all prods (including EnumProduction)\n",
    "        # so some of them may never be used (EnumProduction)\n",
    "        self.prods = ListModule(self, \"prods_\")\n",
    "        for i in range(self.config[\"n_prods\"]):\n",
    "            self.prods.append(\n",
    "                nn.Linear(\n",
    "                    self.config[\"node_dim\"],\n",
    "                    self.config[\"node_dim\"]\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    '''\n",
    "    single batch behavior, no batch dim expected\n",
    "    '''\n",
    "    def forward(self, adjmtx, all_maps, frontier_ids, out_map, candidate_shells):\n",
    "        # adjmtx / (vocab_size+new_n,vocab_size+new_n), no batch: normalized adjacency matrix\n",
    "        # all_maps / new_n * [(a,b,c,d,...), (), ...]\n",
    "        # frontier_ids / list: node ids used for aggregation\n",
    "        # out_map: output map\n",
    "        # candidate_shells: call get_neighboring_shells\n",
    "        \n",
    "        d_feats = [\n",
    "            self.abs_encoder(all_maps[i])\n",
    "            for i in range(len(all_maps))\n",
    "            # (1, node_dim)\n",
    "        ]\n",
    "        # (new_n, node_dim)\n",
    "        d_sensp = torch.cat(d_feats, dim=0)\n",
    "        \n",
    "        # (1, node_dim)\n",
    "        out_feat = self.abs_encoder(out_map)\n",
    "        \n",
    "        # (vocab_size+new_n, node_dim)\n",
    "        gcn_embd = self.tml_encoder(adjmtx, d_sensp)\n",
    "        \n",
    "        # then we do aggregation\n",
    "        # (1, node_dim)\n",
    "        graph_encoding = torch.mean(gcn_embd[frontier_ids,:], dim=0, keepdim=True)\n",
    "        \n",
    "        # then compute the encoding of every candidate shells\n",
    "        cand_embds = [\n",
    "            self.prods[p[0]](torch.mean(gcn_embd[p[1],:], dim=0, keepdim=True))\n",
    "            for p in candidate_shells\n",
    "            # (1, node_dim)\n",
    "        ]\n",
    "        \n",
    "        # (n_cand, node_dim)\n",
    "        cand_encoding = torch.cat(cand_embds, dim=0)\n",
    "        \n",
    "        # perform a soft forward\n",
    "        # (n_cand, node_dim) x (node_dim, 1) -> (n_cand, 1)\n",
    "        score_mtx = F.log_softmax(cand_encoding.matmul(graph_encoding.t()).flatten(),dim=0)\n",
    "        \n",
    "        # (n_cand,)\n",
    "        return score_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlphaNeoTrainer(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer):\n",
    "    reward_list = []\n",
    "    n_batch = 1\n",
    "    batch_loss = 0.\n",
    "    c_nth = 0\n",
    "    \n",
    "    total_ac = {1:0,2:0,3:0}\n",
    "    \n",
    "    is_solved = False\n",
    "    solved_rewards = []\n",
    "    solved_attempts = []\n",
    "    n_attempt = 0\n",
    "    # initialize a program first\n",
    "    while True:\n",
    "        p_input = p_interpreter.random_table()\n",
    "        p_prog, p_example = p_generator.generate(\n",
    "            fixed_depth=p_config[\"max_depth\"],\n",
    "            example=Example(input=[p_input], output=None),\n",
    "        )\n",
    "        # make sure at least one function call\n",
    "        if p_prog is not None and p_prog.is_apply():\n",
    "            break\n",
    "    # one program each step\n",
    "    for d_step in range(p_config[\"n_steps\"]):\n",
    "        p_model.train()\n",
    "        \n",
    "        if is_solved:\n",
    "            is_solved = False\n",
    "            solved_rewards = []\n",
    "            solved_attempts.append(n_attempt)\n",
    "            n_attempt = 0\n",
    "            while True:\n",
    "                p_input = p_interpreter.random_table()\n",
    "                p_prog, p_example = p_generator.generate(\n",
    "                    fixed_depth=p_config[\"max_depth\"],\n",
    "                    example=Example(input=[p_input], output=None),\n",
    "                )\n",
    "                # make sure at least one function call\n",
    "                if p_prog is not None and p_prog.is_apply():\n",
    "                    break\n",
    "        else:\n",
    "            n_attempt += 1\n",
    "        # else: use the same data and perform RL again until it converges\n",
    "        # in this case, n_batch should always be 1\n",
    "            \n",
    "            \n",
    "        # start from the first state\n",
    "        ps_current = ProgramSpace(\n",
    "            p_spec, p_interpreter, p_example.input, p_example.output,\n",
    "        )\n",
    "        d_reward = None\n",
    "        selected_edges = []\n",
    "        \n",
    "        # store computed features\n",
    "        # put the ParamNode in first\n",
    "        # ==== TODO: temporarily based on input[0] ====\n",
    "        stored_maps = [\n",
    "            camb_get_features(ps_current.inputs[0], ps_current.inputs[i])\n",
    "            for i in range(len(ps_current.inputs))\n",
    "        ]\n",
    "        output_map = camb_get_features(ps_current.inputs[0], ps_current.output)\n",
    "        if use_cuda:\n",
    "            td_out = [\n",
    "                Variable(torch.LongTensor( [output_map[i]] )).cuda()\n",
    "                for i in range(len(output_map))\n",
    "            ]\n",
    "        else:\n",
    "            td_out = [\n",
    "                Variable(torch.LongTensor( [output_map[i]] ))\n",
    "                for i in range(len(output_map))\n",
    "            ]\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            current_frontiers = ps_current.get_frontiers()\n",
    "            current_candidates = ps_current.get_neighboring_shells()\n",
    "            current_adjmtx = ps_current.get_normalized_adjacency_matrix_u()\n",
    "            \n",
    "            \n",
    "            if use_cuda:\n",
    "                td_maps = [\n",
    "                    [\n",
    "                        Variable(torch.LongTensor( [stored_maps[i][j]] )).cuda()\n",
    "                        for j in range(len(stored_maps[i]))\n",
    "                    ]\n",
    "                    for i in range(len(stored_maps))\n",
    "                ]\n",
    "                td_adj = Variable(torch.FloatTensor(current_adjmtx)).cuda()\n",
    "            else:\n",
    "                td_maps = [\n",
    "                    [\n",
    "                        Variable(torch.LongTensor( [stored_maps[i][j]] ))\n",
    "                        for j in range(len(stored_maps[i]))\n",
    "                    ]\n",
    "                    for i in range(len(stored_maps))\n",
    "                ]\n",
    "                td_adj = Variable(torch.FloatTensor(current_adjmtx))\n",
    "                       \n",
    "            # (n_cand,)\n",
    "            td_output = p_model(\n",
    "                td_adj,\n",
    "                td_maps,\n",
    "                current_frontiers,\n",
    "                td_out,\n",
    "                current_candidates,\n",
    "            )\n",
    "\n",
    "            if random.random()<=p_config[\"exploration_rate\"](d_step):\n",
    "                # exploration\n",
    "                selected_id = random.choice(range(len(current_candidates)))\n",
    "            else:\n",
    "                # exploitation\n",
    "                selected_id = torch.multinomial(td_output.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "            \n",
    "            # keep track of selected edges\n",
    "            selected_edges.append(td_output[selected_id])\n",
    "            # add selected edges and fill\n",
    "            ret = ps_current.add_neighboring_shell(current_candidates[selected_id])\n",
    "            \n",
    "            if ret==False:\n",
    "                # failed interpretation\n",
    "                d_reward = -0.1\n",
    "                solved_rewards.append(d_reward)\n",
    "                break\n",
    "            else:\n",
    "                # TODO: don't forget to add features to stored_map\n",
    "                stored_maps.append(\n",
    "                    camb_get_features(ps_current.inputs[0], ps_current.node_list[-1])\n",
    "                    # the last one, use -1 to index\n",
    "                )\n",
    "                # succeeded\n",
    "                # see if it's solved or not              \n",
    "                pid = ps_current.check_eq()\n",
    "                if pid is not None:\n",
    "                    # solved in depth less than or equal to max_depth\n",
    "                    d_reward = 1.\n",
    "                    solved_rewards.append(d_reward)\n",
    "                    total_ac[ps_current.get_ncalls(pid=pid)] += 1\n",
    "                    is_solved = True\n",
    "                    break\n",
    "                elif ps_current.get_ncalls()>=p_config[\"max_calls\"]:\n",
    "                    d_reward = -0.1\n",
    "                    solved_rewards.append(d_reward)\n",
    "                    break\n",
    "                    \n",
    "        \n",
    "        # finally compute the loss\n",
    "        d_loss = 0.\n",
    "        ns = len(selected_edges)\n",
    "        for i in range(ns):\n",
    "            d_decay = p_config[\"gamma\"]**(ns-1-i)\n",
    "            # should negate the log probabilities\n",
    "            d_loss += d_decay*d_reward*(-selected_edges[i])\n",
    "\n",
    "        if is_solved:\n",
    "            reward_list.append(\n",
    "                sum(solved_rewards)/len(solved_rewards)\n",
    "            )\n",
    "        batch_loss += d_loss\n",
    "\n",
    "        print(\"\\r# Attempt{}, reward:{:.4f}, avg.reward:{:.4f}, avg.attempt:{:.2f}, ac: 1->{}, 2->{}, 3->{}\".format(\n",
    "            n_attempt, d_reward, \n",
    "            sum(reward_list)/len(reward_list) if len(reward_list)>0 else 0,\n",
    "            sum(solved_attempts)/len(solved_attempts) if len(solved_attempts)>0 else 0,\n",
    "            total_ac[1], total_ac[2], total_ac[3],\n",
    "        ), end=\"\")\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\n",
    "                'avg.reward/step',\n",
    "                sum(reward_list)/len(reward_list) if len(reward_list)>0 else 0,\n",
    "                # d_step,\n",
    "                # use number of programs as step(episode), not number of attempts\n",
    "                total_ac[1]+total_ac[2]+total_ac[3],\n",
    "            )\n",
    "        \n",
    "        \n",
    "        c_nth += 1\n",
    "        if c_nth%n_batch==0:\n",
    "            c_nth = 0\n",
    "            # perform gradient in every batch\n",
    "            batch_loss.backward()\n",
    "            p_optim.step()\n",
    "            p_optim.zero_grad()\n",
    "            batch_loss = 0.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/set_select.tyrell')\n",
    "m_eq = eq_r\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    "    sfn=m_interpreter.sanity_check,\n",
    ")\n",
    "m_ps = ProgramSpaceChainOneNB(\n",
    "    m_spec, m_interpreter, m_eq, None, None,\n",
    ")\n",
    "m_config = {\n",
    "    \"n_prods\": m_spec.num_productions(), # include all prods\n",
    "    \"abs\": {\n",
    "        \"n_maps\": 4,\n",
    "        \"vocab_size\": len(CAMB_LIST),\n",
    "        \"embd_dim\": 10,\n",
    "        \"conv_n_kernels\": None,\n",
    "        \"conv_kernel_sizes\": None,\n",
    "        \"pool_kernel_sizes\": None,\n",
    "    },\n",
    "    \"tml\": {\n",
    "        # all EnumProd\n",
    "        \"vocab_size\": len(list(filter(lambda x:x.is_enum(),m_spec.productions()))),\n",
    "    },\n",
    "    \"node_dim\": 128,\n",
    "    \"IDX_PAD\": 0,\n",
    "    \"n_steps\": 10000000,\n",
    "    \"gamma\": 0.618,\n",
    "    \"exploration_rate\": lambda x:0.9-0.8*(min(1, x/2500)),\n",
    "    \"max_depth\": 2,\n",
    "    \"max_calls\": 10,\n",
    "}\n",
    "m_config[\"abs\"][\"conv_n_kernels\"] = [10 for _ in range(m_config[\"abs\"][\"n_maps\"])]\n",
    "m_config[\"abs\"][\"conv_kernel_sizes\"] = [\n",
    "    (1,CAMB_NCOL) \n",
    "    for _ in range(m_config[\"abs\"][\"n_maps\"])\n",
    "]\n",
    "m_config[\"abs\"][\"pool_kernel_sizes\"] = [\n",
    "    (1,1), (CAMB_NROW,1), (1,1), (CAMB_NROW,1)\n",
    "    # a:1, b:nrow, c:1, d:nrow\n",
    "]\n",
    "\n",
    "# print(m_config)\n",
    "\n",
    "alpha_neo = AlphaNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    alpha_neo = alpha_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(alpha_neo.parameters()))\n",
    "writer = SummaryWriter(\"runs/0701CAMB_RL1_select\")\n",
    "# writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_prods': 72,\n",
       " 'abs': {'n_maps': 4,\n",
       "  'vocab_size': 600,\n",
       "  'embd_dim': 10,\n",
       "  'conv_n_kernels': [10, 10, 10, 10],\n",
       "  'conv_kernel_sizes': [(1, 20), (1, 20), (1, 20), (1, 20)],\n",
       "  'pool_kernel_sizes': [(1, 1), (50, 1), (1, 1), (50, 1)]},\n",
       " 'tml': {'vocab_size': 69},\n",
       " 'node_dim': 128,\n",
       " 'IDX_PAD': 0,\n",
       " 'n_steps': 10000000,\n",
       " 'gamma': 0.618,\n",
       " 'exploration_rate': <function __main__.<lambda>(x)>,\n",
       " 'max_depth': 2,\n",
       " 'max_calls': 10}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_ps.shell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Attempt5, reward:-0.1000, avg.reward:0.4088, avg.attempt:3.50, ac: 1->4, 2->0, 3->0"
     ]
    }
   ],
   "source": [
    "AlphaNeoTrainer(m_config, m_spec, m_interpreter, m_generator, alpha_neo, optimizer, writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
