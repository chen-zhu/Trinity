{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behaviral Law Engine\n",
    "- Stage: Cambrian\n",
    "- Version: Pomoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramDataset(Dataset):\n",
    "    def __init__(self, p_config=None, pn_program=None, p_generator=None, p_sourceps=None):\n",
    "        self.config = p_config\n",
    "        self.n_program = pn_program\n",
    "        self.generator = p_generator\n",
    "        self.source_ps = p_sourceps\n",
    "        \n",
    "        self.shell_list = self.source_ps.get_neighboring_shells()\n",
    "        self.shell_dict = {\n",
    "            self.shell_list[i]:i for i in range(len(self.shell_list))\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_program\n",
    "    \n",
    "    '''\n",
    "    shortened method: only valid for size 1 programs\n",
    "    '''\n",
    "    def __getitem__(self, p_ind):\n",
    "        d_solution = self.generator.get_new_chain_program(2)\n",
    "        d_shell = d_solution.shells[0]\n",
    "        dind_shell = self.shell_dict[d_shell]\n",
    "        dabs_input = d_solution.interpreter.camb_get_ventogyrus(d_solution.inputs[0])\n",
    "        return (np.array(dind_shell), np.array(dabs_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLE(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(BLE,self).__init__()\n",
    "        self.config = p_config\n",
    "        self.fc1 = nn.Linear(\n",
    "            self.config[\"BLE\"][\"input_size\"],\n",
    "            2048,\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            2048,\n",
    "            self.config[\"BLE\"][\"output_size\"],\n",
    "        )\n",
    "    def forward(self, p_abs):\n",
    "        # p_abs: (B, 15*7+1)\n",
    "        out1 = F.relu(self.fc1(p_abs))\n",
    "        out2 = torch.log_softmax(self.fc2(out1),dim=1)\n",
    "        return out2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLETrain(p_config, p_engine, pld_data, p_optim, p_lossfn):\n",
    "    for d_ep in range(p_config[\"BLE\"][\"n_epoch\"]):\n",
    "        ep_loss_list = []\n",
    "        for batch_idx, (b_ind, b_input) in enumerate(pld_data):\n",
    "            p_engine.train()\n",
    "            if use_cuda:\n",
    "                tb_ind = Variable(b_ind).long().cuda()\n",
    "                tb_input = Variable(b_input).float().cuda()\n",
    "            else:\n",
    "                tb_ind = Variable(b_ind).long()\n",
    "                tb_input = Variable(b_input).float()\n",
    "            \n",
    "            tb_preds = p_engine(tb_input) # (B, output_size)\n",
    "            tb_loss = p_lossfn(tb_preds, tb_ind)\n",
    "            ep_loss_list.append(tb_loss)\n",
    "            p_optim.zero_grad()\n",
    "            tb_loss.backward()\n",
    "            p_optim.step()\n",
    "            \n",
    "            print(\"\\r# Train Ep:{}, B:{}, epLoss:{:.2f}\".format(\n",
    "                d_ep, batch_idx, sum(ep_loss_list)/len(ep_loss_list)\n",
    "            ),end=\"\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb5.tyrell')\n",
    "m_generator = MorpheusGenerator(m_spec, m_interpreter)\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_config = {\n",
    "    \"BLE\":{\n",
    "        \"ntrain_program\":1000,\n",
    "        \"input_size\": 15*7+1,\n",
    "        \"output_size\": len(m_ps.get_neighboring_shells()),\n",
    "        \"n_epoch\": 100,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pd = ProgramDataset(\n",
    "    p_config=m_config, \n",
    "    pn_program=m_config[\"BLE\"][\"ntrain_program\"], \n",
    "    p_generator=m_generator, \n",
    "    p_sourceps=m_ps\n",
    ")\n",
    "ld_pd = DataLoader(dataset=dt_pd, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ble = BLE(p_config=m_config)\n",
    "m_lossfn = nn.NLLLoss()\n",
    "m_optim = torch.optim.Adam(ble.parameters())\n",
    "if use_cuda:\n",
    "    ble = ble.cuda()\n",
    "    m_lossfn = m_lossfn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train Ep:0, B:96, epLoss:4.61"
     ]
    }
   ],
   "source": [
    "BLETrain(m_config, ble, ld_pd, m_optim, m_lossfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
