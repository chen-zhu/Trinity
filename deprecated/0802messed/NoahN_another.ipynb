{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransNeo/AlphaNeo\n",
    "- AlphaNeo using pre-trained TransE embeddings (optional)\n",
    "- Stage: Cambrian\n",
    "- Version: Spriggina\n",
    "- Update Logs\n",
    "    - 0713: with DeepPath style rollback at training\n",
    "    - **0716: new learning paradigm, see memo for details**\n",
    "\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(TransNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        # predict a fixed number of shells\n",
    "#         self.policy = nn.Linear(\n",
    "#             self.config[\"embd_dim\"],\n",
    "#             self.config[\"fn\"][\"vocab_size\"],\n",
    "#         )\n",
    "        \n",
    "        # deeper\n",
    "        self.policy0 = nn.Linear(\n",
    "            self.config[\"embd_dim\"],\n",
    "            128,\n",
    "        )\n",
    "        self.policy1 = nn.Linear(\n",
    "            128,\n",
    "            self.config[\"fn\"][\"vocab_size\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, p_mapin, p_mapout):\n",
    "        # p_mapin/p_mapout: (B, 15*3)\n",
    "        v_delta = p_mapout-p_mapin\n",
    "#         tmp_out = torch.log_softmax(\n",
    "#             self.policy(v_delta),dim=1\n",
    "#         )\n",
    "        tmp_out = torch.log_softmax(\n",
    "            self.policy1(\n",
    "                F.relu(\n",
    "                    self.policy0(\n",
    "                        v_delta\n",
    "                    )\n",
    "                )\n",
    "            ),dim=1\n",
    "        )\n",
    "        \n",
    "        return tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranker(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(Ranker, self).__init__()\n",
    "        self.config = p_config\n",
    "        self.value_embedding = nn.Embedding(\n",
    "            self.config[\"ranker\"][\"vocab_size\"],\n",
    "            self.config[\"ranker\"][\"embd_dim\"],\n",
    "        )\n",
    "        self.fc0 = nn.Linear(\n",
    "            self.config[\"ranker\"][\"embd_dim\"] * self.config[\"ranker\"][\"max_length\"] * 2,\n",
    "            4096,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            4096,\n",
    "            2048,\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            2048,\n",
    "            128\n",
    "        )\n",
    "        self.fc3 = nn.Linear(\n",
    "            128,\n",
    "            2\n",
    "        )\n",
    "        \n",
    "    def forward(self, pA, pB, pC, pD):\n",
    "        # pA/pB/pC/pD: (B=1, seq)\n",
    "        B = pA.shape[0]\n",
    "        \n",
    "        # (B, seq, embd_dim)\n",
    "        vA = self.value_embedding(pA).view(B, self.config[\"ranker\"][\"max_length\"]*self.config[\"ranker\"][\"embd_dim\"])\n",
    "        vB = self.value_embedding(pB).view(B, self.config[\"ranker\"][\"max_length\"]*self.config[\"ranker\"][\"embd_dim\"])\n",
    "        vC = self.value_embedding(pC).view(B, self.config[\"ranker\"][\"max_length\"]*self.config[\"ranker\"][\"embd_dim\"])\n",
    "        vD = self.value_embedding(pD).view(B, self.config[\"ranker\"][\"max_length\"]*self.config[\"ranker\"][\"embd_dim\"])\n",
    "        \n",
    "        # (B=2, embd_dim * 2)\n",
    "        vPOS = torch.cat(\n",
    "            [\n",
    "                torch.cat([vA,vB],dim=1),\n",
    "                torch.cat([vA,vC],dim=1),\n",
    "            ],dim=0\n",
    "        )\n",
    "        \n",
    "        # (B=10, embd_dim * 2)\n",
    "        vNEG = torch.cat(\n",
    "            [\n",
    "                torch.cat([vB,vA],dim=1),\n",
    "                torch.cat([vB,vC],dim=1),\n",
    "                torch.cat([vC,vA],dim=1),\n",
    "                torch.cat([vC,vB],dim=1),\n",
    "            ],dim=0\n",
    "        )\n",
    "        \n",
    "        # (B=4*3=12, embd_dim * 2)\n",
    "        vII = torch.cat([vPOS,vNEG],dim=0)\n",
    "        \n",
    "        v00 = F.relu(self.fc0(vII))\n",
    "        v01 = F.relu(self.fc1(v00))\n",
    "        v02 = F.relu(self.fc2(v01))\n",
    "        v03 = self.fc3(v02)\n",
    "        # == Notice: don't do any activation at the last layer ==\n",
    "        # (B=4*3=12, 2)\n",
    "        \n",
    "        return v03\n",
    "    \n",
    "    def inference(self, pX, pY):\n",
    "        # pX/pY: (B=1, seq)\n",
    "        B = pX.shape[0]\n",
    "        \n",
    "        # (B, seq, embd_dim)\n",
    "        vX = self.value_embedding(pX).view(B, self.config[\"ranker\"][\"max_length\"]*self.config[\"ranker\"][\"embd_dim\"])\n",
    "        vY = self.value_embedding(pY).view(B, self.config[\"ranker\"][\"max_length\"]*self.config[\"ranker\"][\"embd_dim\"])\n",
    "        vIN = torch.cat([vX,vY],dim=1) # (B, 2*seq*embd_dim)\n",
    "        v00 = F.relu(self.fc0(vIN))\n",
    "        v01 = F.relu(self.fc1(v00))\n",
    "        v02 = F.relu(self.fc2(v01))\n",
    "        v03 = F.softmax(self.fc3(v02),dim=1) # (B, 2)\n",
    "        return v03[:,1].detach() # (B, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sketch(ps0,ps1):\n",
    "    if len(ps0.node_list)!=len(ps1.node_list):\n",
    "        return False\n",
    "    for i in range(len(ps0.shells)):\n",
    "        if ps0.node_list[-i-1].name != ps1.node_list[-i-1].name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "'''\n",
    "meta-test an agent, directly run into testing / online adaptation\n",
    "'''\n",
    "def MetaTest(p_config, p_spec, p_interpreter, p_generator, p_model, p_bmrks, p_optim, p_writer):\n",
    "    print(\"# Start Meta-Test...\")\n",
    "    \n",
    "    n_solved = 0 # track the number of solved problem\n",
    "    n_sketch_solved = 0\n",
    "    n_attempt_list = [] # track the number of attempts in every episode\n",
    "    n_sketch_atlist = [] # track the number of attempts when hitting the sketch\n",
    "    \n",
    "    for d_episode in range(p_config[\"meta_test\"][\"n_episode\"]):\n",
    "        \n",
    "        # retrieve the given meta-trained model for testing\n",
    "        test_model = copy.deepcopy(p_model)\n",
    "        test_model.train()\n",
    "        test_optim = torch.optim.Adam(list(test_model.parameters()))\n",
    "        \n",
    "        # ==== prepare the benchmark ====\n",
    "        bmrk_prog, bmrk_str_example = p_bmrks[d_episode]\n",
    "        bmrk_example = Example(\n",
    "            input=[p_interpreter.load_data_into_var(p) for p in bmrk_str_example.input],\n",
    "            output=p_interpreter.load_data_into_var(bmrk_str_example.output),\n",
    "        )\n",
    "        ps_solution = ProgramSpace(\n",
    "            p_spec, p_interpreter, bmrk_example.input, bmrk_example.output,\n",
    "        )\n",
    "        ps_solution.init_by_prog(bmrk_prog)\n",
    "        solution_prod_names = [\n",
    "            ps_solution.prod_list[p[0]].name for p in ps_solution.shells\n",
    "        ]\n",
    "        solution_shells = ps_solution.shells\n",
    "        \n",
    "        # solution self-check\n",
    "        if ps_solution.check_eq() is None:\n",
    "            print(\"ERROR, SOLUTION NOT CONSISTENT!\")\n",
    "        \n",
    "        \n",
    "#         f = open(\"./outputs/Sarah3/Problem_{}.txt\".format(d_episode), \"w\")\n",
    "#         f.write(\"# Problem: {}\\n\\n\".format(str(ps_solution.node_list[-1])))\n",
    "#         f.write(\"# Input:\\n{}\\n\".format(p_interpreter.renv(ps_solution.inputs[0])))\n",
    "#         f.write(\"# Output:\\n{}\\n\".format(p_interpreter.renv(ps_solution.output)))\n",
    "#         f.flush()\n",
    "        \n",
    "        is_solved = False\n",
    "        is_sketch_solved = False\n",
    "        \n",
    "        for d_attempt in range(p_config[\"meta_test\"][\"maxn_attempt\"]):\n",
    "            \n",
    "            current_prod_names = []\n",
    "            current_shells = []\n",
    "            current_outputs = []\n",
    "            \n",
    "            selected_neurons = []\n",
    "            stored_groups = [] # with lists of neurons of the same production name\n",
    "            \n",
    "            # in every new attempt, initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, ps_solution.inputs, ps_solution.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "                \n",
    "            d_step = 0\n",
    "            while d_step<p_config[\"meta_test\"][\"maxn_step\"]:\n",
    "                \n",
    "                # print the training progress\n",
    "                print(\"\\r# AC/SK/EP:{}/{}/{}, AT:{}, SP:{}, att.ske.:{:.2f}, att.prog.:{:.2f},\".format(\n",
    "                    n_solved, n_sketch_solved, d_episode, d_attempt, d_step,\n",
    "                    sum(n_sketch_atlist)/len(n_sketch_atlist) if len(n_sketch_atlist)>0 else -1,\n",
    "                    sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else -1,\n",
    "                ),end=\"\")\n",
    "                \n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                id_current = ps_current.get_strict_frontiers()[0]\n",
    "                var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "                var_output = ps_current.output\n",
    "                \n",
    "                map_current = p_interpreter.camb_get_shash_abs(var_current)\n",
    "                map_output = p_interpreter.camb_get_shash_abs(var_output)\n",
    "                \n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                \n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float)).cuda()\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float)).cuda()\n",
    "                else:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float))\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float))\n",
    "                    \n",
    "                # (B=1, fn_vocab_size)\n",
    "                td_pred = test_model(td_current, td_output)\n",
    "                \n",
    "                # no hints\n",
    "                if random.random()<=p_config[\"meta_test\"][\"exploration_rate\"]:\n",
    "                    # exploration\n",
    "                    tmp_id = random.choice(range(len(current_shell_list)))\n",
    "                else:\n",
    "                    # exploitation\n",
    "                    # tmp_id = torch.multinomial(td_pred.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "                    tmp_id = torch.argmax(td_pred.flatten()).cpu().tolist()\n",
    "                    \n",
    "                    \n",
    "                # == Yorgia ==\n",
    "                # find out all other shells that share the same product name\n",
    "                tmp_component_name = ps_current.prod_list[current_shell_list[tmp_id][0]].name\n",
    "                tmp_group = []\n",
    "                for i in range(len(current_shell_list)):\n",
    "                    if ps_current.prod_list[current_shell_list[i][0]].name==tmp_component_name:\n",
    "                        tmp_group.append(td_pred[0,i])\n",
    "                stored_groups.append(tmp_group)\n",
    "                    \n",
    "                # == Yorgia ==\n",
    "                # add prod names first\n",
    "                current_prod_names.append(tmp_component_name)\n",
    "                # then add shells\n",
    "                current_shells.append(current_shell_list[tmp_id])\n",
    "                \n",
    "                # update ps_current\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if update_status:\n",
    "                    # record selected neuron\n",
    "                    selected_neurons.append((True, td_pred[0,tmp_id]))\n",
    "                    current_outputs.append(ps_current.node_list[-1].ps_data)\n",
    "                    d_step += 1\n",
    "                    \n",
    "                    # succeed\n",
    "                    if ps_current.check_eq() is not None:\n",
    "                        # and solved!\n",
    "                        is_solved = True\n",
    "                        n_solved += 1\n",
    "                        break\n",
    "                else:\n",
    "                    selected_neurons.append((False, td_pred[0,tmp_id]))\n",
    "                    break\n",
    "            \n",
    "            # <END_FOR_STEP>\n",
    "#             f.write(\"# ({}) Proposed {}/{}: {}\\n\".format(\n",
    "#                 \"accept\" if is_solved else \"reject\",\n",
    "#                 d_attempt, p_config[\"meta_test\"][\"maxn_attempt\"],\n",
    "#                 str(ps_current.node_list[-1])\n",
    "#             ))\n",
    "#             f.flush()\n",
    "            \n",
    "            if not is_sketch_solved:\n",
    "                if compare_sketch(ps_current, ps_solution):\n",
    "                    n_sketch_atlist.append(d_attempt)\n",
    "                    is_sketch_solved = True\n",
    "                    n_sketch_solved += 1\n",
    "                    \n",
    "            if is_solved:\n",
    "                n_attempt_list.append(d_attempt)\n",
    "                break\n",
    "            \n",
    "            # print(\"# Current Sketch: {}\".format(current_prod_names))\n",
    "            # == Yorgia ==\n",
    "            # compute the loss according to the loss computation rules\n",
    "            # first component, then function call\n",
    "            batch_loss_list = []\n",
    "            for i in range(len(current_prod_names)):\n",
    "                batch_loss_list.append(\n",
    "                    (-1.0)*(-selected_neurons[i][1])\n",
    "                )\n",
    "#                 if solution_prod_names[i]==current_prod_names[i]:\n",
    "#                     # component match, promote the whole group\n",
    "#                     for j in range(len(stored_groups[i])):\n",
    "#                         batch_loss_list.append(\n",
    "#                             (+1.0)*(-stored_groups[i][j])\n",
    "#                         )\n",
    "#                 else:\n",
    "#                     for j in range(len(stored_groups[i])):\n",
    "#                         batch_loss_list.append(\n",
    "#                             (-1.0)*(-stored_groups[i][j])\n",
    "#                         )\n",
    "#                 # then compare function call\n",
    "#                 if solution_shells[i]==current_shells[i]:\n",
    "#                     batch_loss_list.append(\n",
    "#                         (+1.0)*(-selected_neurons[i][1])\n",
    "#                     )\n",
    "#                 else:\n",
    "#                     batch_loss_list.append(\n",
    "#                         (-1.0)*(-selected_neurons[i][1])\n",
    "#                     )\n",
    "            \n",
    "            batch_loss = sum(batch_loss_list)\n",
    "            test_optim.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            test_optim.step()\n",
    "            \n",
    "                \n",
    "        # <END_FOR_ATTEMPT>     \n",
    "        \n",
    "#         f.close()\n",
    "            \n",
    "    # <END_FOR_EPISODE>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    ")\n",
    "\n",
    "# dumb variable to help infer the shells\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")\n",
    "\n",
    "m_config = {\n",
    "    \"fn\":{\n",
    "        \"vocab_size\": len(m_ps.get_neighboring_shells())\n",
    "    },\n",
    "    \"embd_dim\": 15*5,\n",
    "    \"meta_test\":{\n",
    "        \"n_episode\": 250, # only pick the first 250\n",
    "        \"batch_size\": 1, # how many attempts\n",
    "        # \"fixed_depth\": 4,\n",
    "        \"maxn_attempt\": 1000,\n",
    "        \"maxn_step\": 3, # program size\n",
    "        \"exploration_rate\": 0,\n",
    "        \"benchmarks\": \"./0731MDsize3.pkl\",\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(m_config[\"meta_test\"][\"benchmarks\"],\"rb\") as f:\n",
    "    bmrks = pickle.load(f)\n",
    "\n",
    "trans_neo = TransNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    trans_neo = trans_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(trans_neo.parameters()))\n",
    "\n",
    "# writer = SummaryWriter(\"runs/0713CAMB_RL2_camb3\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fn': {'vocab_size': 120},\n",
       " 'embd_dim': 75,\n",
       " 'meta_test': {'n_episode': 250,\n",
       "  'batch_size': 1,\n",
       "  'maxn_attempt': 1000,\n",
       "  'maxn_step': 3,\n",
       "  'exploration_rate': 0,\n",
       "  'benchmarks': './0731MDsize3.pkl'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start Meta-Test...\n",
      "# AC/SK/EP:3/10/32, AT:547, SP:2, att.ske.:336.40, att.prog.:114.00,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From cffi callback <function _consolewrite_ex at 0x7f0b629aae18>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/callbacks.py\", line 122, in _consolewrite_ex\n",
      "    @ffi.callback(WRITECONSOLE_EX_SIGNATURE)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AC/SK/EP:3/10/32, AT:552, SP:0, att.ske.:336.40, att.prog.:114.00,Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-7c3e2755fa43>\", line 1, in <module>\n",
      "    MetaTest(m_config, m_spec, m_interpreter, m_generator, trans_neo, bmrks, optimizer, writer)\n",
      "  File \"<ipython-input-8-01e66dd3866d>\", line 94, in MetaTest\n",
      "    map_current = p_interpreter.camb_get_shash_abs(var_current)\n",
      "  File \"/home/ju-ucsb/Trinity/MorpheusInterpreter.py\", line 904, in camb_get_shash_abs\n",
      "    df_rhash_val = self.hash(str(self.renv(p_obj))[::-1])%15\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 389, in __call__\n",
      "    res = self.eval(p)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 364, in __getattribute__\n",
      "    return self.__getitem__(attr)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 370, in __getitem__\n",
      "    res = conversion.rpy2py(res)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/functools.py\", line 824, in wrapper\n",
      "    return dispatch(args[0].__class__)(*args, **kw)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 207, in _rpy2py_sexpclosure\n",
      "    return SignatureTranslatedFunction(obj)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\", line 177, in __init__\n",
      "    reserved_pynames = set(dir(self))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "MetaTest(m_config, m_spec, m_interpreter, m_generator, trans_neo, bmrks, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3/16/46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmrk_prog, bmrk_str_example = bmrks[0]\n",
    "# bmrk_example = Example(\n",
    "#     input=[m_interpreter.load_data_into_var(p) for p in bmrk_str_example.input],\n",
    "#     output=m_interpreter.load_data_into_var(bmrk_str_example.output),\n",
    "# )\n",
    "# ps_solution = ProgramSpace(\n",
    "#     m_spec, m_interpreter, bmrk_example.input, bmrk_example.output,\n",
    "# )\n",
    "# ps_solution.init_by_prog(bmrk_prog)\n",
    "# # solution_prod_names = [\n",
    "# #     ps_solution.prod_list[p[0]].name for p in ps_solution.shells\n",
    "# # ]\n",
    "# # solution_shells = ps_solution.shells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
