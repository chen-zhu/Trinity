{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaNeo Ranker\n",
    "- tell which pair of tables are functionally/logically closer on execution chain\n",
    "- Stage: Cambrian\n",
    "- Version: Yorgia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataset for training: load random positive/negative examples every time\n",
    "'''\n",
    "class RankerDataset(Dataset):\n",
    "    def __init__(self, p_config=None, p_dataset=None, p_interpreter=None, p_spec=None):\n",
    "        self.n_sample = None # should manually assign\n",
    "        self.interpreter = p_interpreter\n",
    "        self.spec = p_spec\n",
    "        self.dataset = p_dataset\n",
    "        self.config = p_config\n",
    "        \n",
    "        # record all possible programs\n",
    "        self.progs = [\n",
    "            self.dataset[dkey][0][0]\n",
    "            for dkey in self.dataset.keys()\n",
    "        ]\n",
    "        \n",
    "        self.n_exp = len(self.progs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_sample\n",
    "    \n",
    "    '''\n",
    "    return a single triangle sample\n",
    "    (input, output1, output2)\n",
    "    A->B, A->C\n",
    "    pos: (A,B), (A,C)\n",
    "    neg: (B,A), (C,A)\n",
    "    neg: (B,C), (C,B)\n",
    "    '''\n",
    "    def get_triangle(self, verbose=False):\n",
    "        # sample (A,B)\n",
    "        while True:\n",
    "            d_progAB = random.choice(self.progs)\n",
    "            d_inputA = self.interpreter.random_table()\n",
    "            try:\n",
    "                d_evalB = self.interpreter.eval(\n",
    "                    d_progAB,\n",
    "                    [d_inputA],\n",
    "                )\n",
    "            except Exception:\n",
    "                continue\n",
    "            d_exampleAB = Example(\n",
    "                input=[d_inputA],\n",
    "                output=d_evalB,\n",
    "            )\n",
    "            d_psAB = ProgramSpace(\n",
    "                self.spec, self.interpreter,\n",
    "                d_exampleAB.input, d_exampleAB.output,\n",
    "            )\n",
    "            d_psAB.init_by_prog(d_progAB)\n",
    "            d_checkAB = self.interpreter.sanity_check(d_psAB)\n",
    "            if d_checkAB[0]:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # sample (A,C)\n",
    "        while True:\n",
    "            d_progAC = random.choice(self.progs)\n",
    "            # avoid conflict on sketch level\n",
    "            if d_progAC.name==d_progAB.name:\n",
    "                continue\n",
    "            try:\n",
    "                d_evalC = self.interpreter.eval(\n",
    "                    d_progAC,\n",
    "                    [d_inputA],\n",
    "                )\n",
    "            except Exception:\n",
    "                continue\n",
    "            d_exampleAC = Example(\n",
    "                input=[d_inputA],\n",
    "                output=d_evalC,\n",
    "            )\n",
    "            d_psAC = ProgramSpace(\n",
    "                self.spec, self.interpreter,\n",
    "                d_exampleAC.input, d_exampleAC.output,\n",
    "            )\n",
    "            d_psAC.init_by_prog(d_progAC)\n",
    "            d_checkAC = self.interpreter.sanity_check(d_psAC)\n",
    "            if d_checkAC[0]:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # all (map_r, map_c)\n",
    "        map_inputA = numpy.array([self.interpreter.camb_get_yorgia(d_inputA,modn=self.config[\"vocab_size\"])])\n",
    "        map_evalB = numpy.array([self.interpreter.camb_get_yorgia(d_evalB,modn=self.config[\"vocab_size\"])])\n",
    "        map_evalC = numpy.array([self.interpreter.camb_get_yorgia(d_evalC,modn=self.config[\"vocab_size\"])])\n",
    "        \n",
    "        if verbose:\n",
    "            print(d_progAB.name)\n",
    "            print(d_progAC.name)\n",
    "            self.interpreter.print_obj(d_inputA)\n",
    "            self.interpreter.print_obj(d_evalB)\n",
    "            self.interpreter.print_obj(d_evalC)\n",
    "        \n",
    "        return (map_inputA, map_evalB, map_evalC)\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    should always use batch_size=1 so as to ensure the ratio of negative examples\n",
    "    '''\n",
    "    def __getitem__(self, p_ind):\n",
    "        return self.get_triangle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranker(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(Ranker, self).__init__()\n",
    "        self.config = p_config\n",
    "        self.value_embedding = nn.Embedding(\n",
    "            self.config[\"vocab_size\"],\n",
    "            self.config[\"embd_dim\"],\n",
    "        )\n",
    "        self.fc0 = nn.Linear(\n",
    "            self.config[\"embd_dim\"] * self.config[\"max_length\"] * 2,\n",
    "            4096,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            4096,\n",
    "            2048,\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            2048,\n",
    "            128\n",
    "        )\n",
    "        self.fc3 = nn.Linear(\n",
    "            128,\n",
    "            2\n",
    "        )\n",
    "        \n",
    "    def forward(self, pA, pB, pC):\n",
    "        # pA/pB/pC: (B=1, seq)\n",
    "        B = pA.shape[0]\n",
    "        \n",
    "        # (B, seq, embd_dim)\n",
    "        vA = self.value_embedding(pA).view(B, self.config[\"max_length\"]*self.config[\"embd_dim\"])\n",
    "        vB = self.value_embedding(pB).view(B, self.config[\"max_length\"]*self.config[\"embd_dim\"])\n",
    "        vC = self.value_embedding(pC).view(B, self.config[\"max_length\"]*self.config[\"embd_dim\"])\n",
    "        \n",
    "        # (B=2, embd_dim * 2)\n",
    "        vPOS = torch.cat(\n",
    "            [\n",
    "                torch.cat([vA,vB],dim=1),\n",
    "                torch.cat([vA,vC],dim=1),\n",
    "            ],dim=0\n",
    "        )\n",
    "        \n",
    "        # (B=4, embd_dim * 2)\n",
    "        vNEG = torch.cat(\n",
    "            [\n",
    "                torch.cat([vB,vA],dim=1),\n",
    "                torch.cat([vB,vC],dim=1),\n",
    "                torch.cat([vC,vA],dim=1),\n",
    "                torch.cat([vC,vB],dim=1),\n",
    "            ],dim=0\n",
    "        )\n",
    "        \n",
    "        # (B=6, embd_dim * 2)\n",
    "        vII = torch.cat([vPOS,vNEG],dim=0)\n",
    "        # print(vII.shape)\n",
    "        \n",
    "        v00 = F.relu(self.fc0(vII))\n",
    "        v01 = F.relu(self.fc1(v00))\n",
    "        v02 = F.relu(self.fc2(v01))\n",
    "        v03 = self.fc3(v02)\n",
    "        # == Notice: don't do any activation at the last layer ==\n",
    "        # (B=4*3=12, 2)\n",
    "        \n",
    "        return v03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RankerTester(p_config, p_model, pld_test, p_lossfn):\n",
    "    test_loss_list = []\n",
    "    test_pPOS_list = []\n",
    "    test_pNEG_list = []\n",
    "    test_aPOS_list = []\n",
    "    test_aNEG_list = []\n",
    "    test_sPOS_list = []\n",
    "    test_sNEG_list = []\n",
    "    for batch_idx, (dA, dB, dC) in enumerate(pld_test):\n",
    "        p_model.eval()\n",
    "        if use_cuda:\n",
    "            tdA = Variable(dA).cuda() # (B=1, map_r, map_c)\n",
    "            tdB = Variable(dB).cuda() # (B=1, map_r, map_c)\n",
    "            tdC = Variable(dC).cuda() # (B=1, map_r, map_c)\n",
    "            td_label = Variable(torch.tensor(\n",
    "                [1 for _ in range(2)]+\\\n",
    "                [0 for _ in range(4)]\n",
    "            )).cuda()\n",
    "        else:\n",
    "            tdA = Variable(dA) # (B=1, map_r, map_c)\n",
    "            tdB = Variable(dB) # (B=1, map_r, map_c)\n",
    "            tdC = Variable(dC) # (B=1, map_r, map_c)\n",
    "            td_label = Variable(torch.tensor(\n",
    "                [1 for _ in range(2)]+\\\n",
    "                [0 for _ in range(4)]\n",
    "            ))\n",
    "            \n",
    "        d_output = p_model(tdA, tdB, tdC) # (B, 2)\n",
    "        d_loss = p_lossfn(\n",
    "            F.log_softmax(d_output, dim=1),\n",
    "            td_label,\n",
    "        )\n",
    "        \n",
    "        test_loss_list.append(d_loss.cpu().data.numpy())\n",
    "        test_pPOS_list += F.softmax(d_output,dim=1)[:2,1].cpu().data.tolist()\n",
    "        test_pNEG_list += F.softmax(d_output,dim=1)[2:,0].cpu().data.tolist()\n",
    "        test_aPOS_list += (torch.argmax(d_output,dim=1)[:2]==td_label[:2]).cpu().data.tolist()\n",
    "        test_aNEG_list += (torch.argmax(d_output,dim=1)[2:]==td_label[2:]).cpu().data.tolist()\n",
    "        test_sPOS_list += F.softmax(d_output,dim=1)[:2,1].cpu().data.tolist()\n",
    "        test_sNEG_list += F.softmax(d_output,dim=1)[2:,1].cpu().data.tolist()\n",
    "        \n",
    "    print(\"# Test avg.loss:{:.2f}, avg.prob.:{:.2f}/{:.2f}, avg.acc.:{:.2f}/{:.2f}, avg.score:{:.2f}/{:.2f}\".format(\n",
    "        sum(test_loss_list)/len(test_loss_list),\n",
    "        sum(test_pNEG_list)/len(test_pNEG_list),\n",
    "        sum(test_pPOS_list)/len(test_pPOS_list),\n",
    "        sum(test_aNEG_list)/len(test_aNEG_list),\n",
    "        sum(test_aPOS_list)/len(test_aPOS_list),\n",
    "        sum(test_sNEG_list)/len(test_sNEG_list), # score is the similarity score\n",
    "        sum(test_sPOS_list)/len(test_sPOS_list),\n",
    "    ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RankerTrainer(p_config, p_model, pld_train, pld_test, p_optim, p_lossfn):\n",
    "    RankerTester(p_config, p_model, pld_test, p_lossfn)\n",
    "    for d_ep in range(p_config[\"ranker\"][\"n_ep\"]):\n",
    "        epoch_loss_list = []\n",
    "        for batch_idx, (dA, dB, dC) in enumerate(pld_train):\n",
    "            p_model.train()\n",
    "            \n",
    "            if use_cuda:\n",
    "                tdA = Variable(dA).cuda() # (B=1, map_r, map_c)\n",
    "                tdB = Variable(dB).cuda() # (B=1, map_r, map_c)\n",
    "                tdC = Variable(dC).cuda() # (B=1, map_r, map_c)\n",
    "                td_label = Variable(torch.tensor(\n",
    "                    [1 for _ in range(2)]+\\\n",
    "                    [0 for _ in range(4)]\n",
    "                )).cuda()\n",
    "            else:\n",
    "                tdA = Variable(dA) # (B=1, map_r, map_c)\n",
    "                tdB = Variable(dB) # (B=1, map_r, map_c)\n",
    "                tdC = Variable(dC) # (B=1, map_r, map_c)\n",
    "                td_label = Variable(torch.tensor(\n",
    "                    [1 for _ in range(2)]+\\\n",
    "                    [0 for _ in range(4)]\n",
    "                ))\n",
    "                \n",
    "            # (B=12, 2)\n",
    "            d_output = p_model(tdA, tdB, tdC)\n",
    "            p_optim.zero_grad()\n",
    "            d_loss = p_lossfn(\n",
    "                F.log_softmax(d_output, dim=1),\n",
    "                td_label,\n",
    "            )\n",
    "            epoch_loss_list.append(d_loss.cpu().data.numpy())\n",
    "            d_loss.backward()\n",
    "            p_optim.step()\n",
    "            \n",
    "            print(\"\\r# Training EP:{}, B:{}, ep.loss:{:.2f}\".format(\n",
    "                d_ep, batch_idx, sum(epoch_loss_list),\n",
    "            ),end=\"\")\n",
    "        \n",
    "        # end of epoch print a new line\n",
    "        print()\n",
    "        RankerTester(p_config, p_model, pld_test, p_lossfn)\n",
    "        \n",
    "        # save the model\n",
    "#         if d_ep%10==0:\n",
    "#             torch.save(p_model.state_dict(), \"./saved_models/0731Ranker_Zaki_ep{}.pt\".format(d_ep))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "\n",
    "m_config = {\n",
    "    \"vocab_size\": 128,\n",
    "    \"embd_dim\": 4,\n",
    "    \"max_length\": m_interpreter.CAMB_NROW + m_interpreter.CAMB_NCOL,\n",
    "    \"ranker\":{\n",
    "        \"data_path\": \"./0716MDsize1.pkl\",\n",
    "        \"train_size\": 1000, # how many samples in every epoch\n",
    "        \"test_size\": 100,\n",
    "        \"n_ep\": 1000000,\n",
    "    },\n",
    "}\n",
    "\n",
    "# ########### BIG NOTICE ########### #\n",
    "# The dataset 0716MDsize1.pkl is problematic\n",
    "# and please only use the program not the table variables\n",
    "# due to hash inconsistency\n",
    "# ########### BIG NOTICE ########### #\n",
    "\n",
    "# load the data and dataset\n",
    "with open(m_config[\"ranker\"][\"data_path\"],\"rb\") as f:\n",
    "    m_data = pickle.load(f)\n",
    "    \n",
    "dt_train = RankerDataset(\n",
    "    p_config=m_config, \n",
    "    p_dataset=m_data, \n",
    "    p_interpreter=m_interpreter,\n",
    "    p_spec=m_spec,\n",
    ")\n",
    "dt_train.n_sample = m_config[\"ranker\"][\"train_size\"]\n",
    "ld_train = DataLoader(dataset=dt_train, batch_size=1, shuffle=True)\n",
    "\n",
    "dt_test = RankerDataset(\n",
    "    p_config=m_config, \n",
    "    p_dataset=m_data, \n",
    "    p_interpreter=m_interpreter,\n",
    "    p_spec=m_spec,\n",
    ")\n",
    "dt_test.n_sample = m_config[\"ranker\"][\"test_size\"]\n",
    "ld_test = DataLoader(dataset=dt_test, batch_size=1, shuffle=True)\n",
    "\n",
    "m_ranker = Ranker(p_config=m_config)\n",
    "if use_cuda:\n",
    "    m_ranker = m_ranker.cuda()\n",
    "optimizer = torch.optim.Adam(list(m_ranker.parameters()))\n",
    "lossfn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_train.get_triangle(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test avg.loss:0.67, avg.prob.:0.54/0.46, avg.acc.:1.00/0.00, avg.score:0.46/0.46\n",
      "# Training EP:0, B:999, ep.loss:498.99\n",
      "# Test avg.loss:0.45, avg.prob.:0.81/0.46, avg.acc.:0.92/0.34, avg.score:0.19/0.46\n",
      "# Training EP:1, B:999, ep.loss:433.28\n",
      "# Test avg.loss:0.36, avg.prob.:0.79/0.71, avg.acc.:0.79/0.86, avg.score:0.21/0.71\n",
      "# Training EP:2, B:999, ep.loss:411.66\n",
      "# Test avg.loss:0.38, avg.prob.:0.82/0.62, avg.acc.:0.79/0.83, avg.score:0.18/0.62\n",
      "# Training EP:3, B:999, ep.loss:396.44\n",
      "# Test avg.loss:0.35, avg.prob.:0.80/0.65, avg.acc.:0.86/0.82, avg.score:0.20/0.65\n",
      "# Training EP:4, B:999, ep.loss:354.28\n",
      "# Test avg.loss:0.34, avg.prob.:0.81/0.68, avg.acc.:0.81/0.87, avg.score:0.19/0.68\n",
      "# Training EP:5, B:999, ep.loss:361.65\n",
      "# Test avg.loss:0.34, avg.prob.:0.86/0.57, avg.acc.:0.92/0.73, avg.score:0.14/0.57\n",
      "# Training EP:6, B:999, ep.loss:354.12\n",
      "# Test avg.loss:0.35, avg.prob.:0.82/0.61, avg.acc.:0.86/0.72, avg.score:0.18/0.61\n",
      "# Training EP:7, B:999, ep.loss:371.23\n",
      "# Test avg.loss:0.35, avg.prob.:0.82/0.62, avg.acc.:0.87/0.82, avg.score:0.18/0.62\n",
      "# Training EP:8, B:999, ep.loss:346.56\n",
      "# Test avg.loss:0.31, avg.prob.:0.84/0.68, avg.acc.:0.87/0.77, avg.score:0.16/0.68\n",
      "# Training EP:9, B:999, ep.loss:340.08\n",
      "# Test avg.loss:0.36, avg.prob.:0.80/0.68, avg.acc.:0.83/0.76, avg.score:0.20/0.68\n",
      "# Training EP:10, B:999, ep.loss:343.22\n",
      "# Test avg.loss:0.35, avg.prob.:0.82/0.64, avg.acc.:0.89/0.70, avg.score:0.18/0.64\n",
      "# Training EP:11, B:999, ep.loss:352.62\n",
      "# Test avg.loss:0.38, avg.prob.:0.84/0.69, avg.acc.:0.85/0.71, avg.score:0.16/0.69\n",
      "# Training EP:12, B:999, ep.loss:319.52\n",
      "# Test avg.loss:0.34, avg.prob.:0.82/0.65, avg.acc.:0.90/0.69, avg.score:0.18/0.65\n",
      "# Training EP:13, B:999, ep.loss:318.36\n",
      "# Test avg.loss:0.28, avg.prob.:0.87/0.69, avg.acc.:0.93/0.74, avg.score:0.13/0.69\n",
      "# Training EP:14, B:999, ep.loss:319.12\n",
      "# Test avg.loss:0.30, avg.prob.:0.84/0.72, avg.acc.:0.90/0.73, avg.score:0.16/0.72\n",
      "# Training EP:15, B:999, ep.loss:304.76\n",
      "# Test avg.loss:0.34, avg.prob.:0.78/0.68, avg.acc.:0.91/0.77, avg.score:0.22/0.68\n",
      "# Training EP:16, B:999, ep.loss:306.77\n",
      "# Test avg.loss:0.31, avg.prob.:0.84/0.68, avg.acc.:0.92/0.73, avg.score:0.16/0.68\n",
      "# Training EP:17, B:999, ep.loss:315.97\n",
      "# Test avg.loss:0.26, avg.prob.:0.87/0.74, avg.acc.:0.93/0.77, avg.score:0.13/0.74\n",
      "# Training EP:18, B:999, ep.loss:317.98\n",
      "# Test avg.loss:0.31, avg.prob.:0.84/0.72, avg.acc.:0.94/0.76, avg.score:0.16/0.72\n",
      "# Training EP:19, B:999, ep.loss:308.52\n",
      "# Test avg.loss:0.35, avg.prob.:0.83/0.67, avg.acc.:0.89/0.69, avg.score:0.17/0.67\n",
      "# Training EP:20, B:999, ep.loss:320.18\n",
      "# Test avg.loss:0.31, avg.prob.:0.84/0.70, avg.acc.:0.92/0.72, avg.score:0.16/0.70\n",
      "# Training EP:21, B:999, ep.loss:302.73\n",
      "# Test avg.loss:0.26, avg.prob.:0.90/0.73, avg.acc.:0.97/0.71, avg.score:0.10/0.73\n",
      "# Training EP:22, B:999, ep.loss:294.28\n",
      "# Test avg.loss:0.26, avg.prob.:0.87/0.69, avg.acc.:0.96/0.74, avg.score:0.13/0.69\n",
      "# Training EP:23, B:999, ep.loss:327.08\n",
      "# Test avg.loss:0.39, avg.prob.:0.78/0.70, avg.acc.:0.92/0.66, avg.score:0.22/0.70\n",
      "# Training EP:24, B:999, ep.loss:308.51\n",
      "# Test avg.loss:0.33, avg.prob.:0.82/0.66, avg.acc.:0.86/0.69, avg.score:0.18/0.66\n",
      "# Training EP:25, B:999, ep.loss:311.53\n",
      "# Test avg.loss:0.28, avg.prob.:0.85/0.71, avg.acc.:0.95/0.73, avg.score:0.15/0.71\n",
      "# Training EP:26, B:999, ep.loss:323.65\n",
      "# Test avg.loss:0.27, avg.prob.:0.86/0.70, avg.acc.:0.96/0.70, avg.score:0.14/0.70\n",
      "# Training EP:27, B:999, ep.loss:312.75\n",
      "# Test avg.loss:0.24, avg.prob.:0.87/0.73, avg.acc.:0.96/0.75, avg.score:0.13/0.73\n",
      "# Training EP:28, B:999, ep.loss:295.80\n",
      "# Test avg.loss:0.30, avg.prob.:0.83/0.76, avg.acc.:0.85/0.84, avg.score:0.17/0.76\n",
      "# Training EP:29, B:999, ep.loss:292.29\n",
      "# Test avg.loss:0.31, avg.prob.:0.89/0.66, avg.acc.:0.94/0.72, avg.score:0.11/0.66\n",
      "# Training EP:30, B:999, ep.loss:296.78\n",
      "# Test avg.loss:0.30, avg.prob.:0.86/0.76, avg.acc.:0.91/0.76, avg.score:0.14/0.76\n",
      "# Training EP:31, B:999, ep.loss:293.21\n",
      "# Test avg.loss:0.31, avg.prob.:0.86/0.72, avg.acc.:0.93/0.72, avg.score:0.14/0.72\n",
      "# Training EP:32, B:999, ep.loss:298.13\n",
      "# Test avg.loss:0.27, avg.prob.:0.85/0.71, avg.acc.:0.94/0.73, avg.score:0.15/0.71\n",
      "# Training EP:33, B:999, ep.loss:307.39\n",
      "# Test avg.loss:0.30, avg.prob.:0.85/0.69, avg.acc.:0.93/0.72, avg.score:0.15/0.69\n",
      "# Training EP:34, B:999, ep.loss:309.06\n",
      "# Test avg.loss:0.32, avg.prob.:0.83/0.71, avg.acc.:0.92/0.69, avg.score:0.17/0.71\n",
      "# Training EP:35, B:999, ep.loss:315.62\n",
      "# Test avg.loss:0.33, avg.prob.:0.84/0.74, avg.acc.:0.90/0.74, avg.score:0.16/0.74\n",
      "# Training EP:36, B:999, ep.loss:302.29\n",
      "# Test avg.loss:0.27, avg.prob.:0.87/0.72, avg.acc.:0.93/0.79, avg.score:0.13/0.72\n",
      "# Training EP:37, B:999, ep.loss:319.22\n",
      "# Test avg.loss:0.35, avg.prob.:0.86/0.62, avg.acc.:0.91/0.68, avg.score:0.14/0.62\n",
      "# Training EP:38, B:999, ep.loss:309.32\n",
      "# Test avg.loss:0.37, avg.prob.:0.81/0.68, avg.acc.:0.88/0.64, avg.score:0.19/0.68\n",
      "# Training EP:39, B:999, ep.loss:312.05\n",
      "# Test avg.loss:0.30, avg.prob.:0.86/0.68, avg.acc.:0.93/0.69, avg.score:0.14/0.68\n",
      "# Training EP:40, B:999, ep.loss:317.69\n",
      "# Test avg.loss:0.23, avg.prob.:0.87/0.76, avg.acc.:0.95/0.82, avg.score:0.13/0.76\n",
      "# Training EP:41, B:999, ep.loss:307.91\n",
      "# Test avg.loss:0.35, avg.prob.:0.85/0.74, avg.acc.:0.87/0.77, avg.score:0.15/0.74\n",
      "# Training EP:42, B:999, ep.loss:302.48\n",
      "# Test avg.loss:0.32, avg.prob.:0.84/0.74, avg.acc.:0.93/0.71, avg.score:0.16/0.74\n",
      "# Training EP:43, B:999, ep.loss:299.79\n",
      "# Test avg.loss:0.33, avg.prob.:0.86/0.65, avg.acc.:0.92/0.59, avg.score:0.14/0.65\n",
      "# Training EP:44, B:999, ep.loss:294.37\n",
      "# Test avg.loss:0.22, avg.prob.:0.89/0.76, avg.acc.:0.94/0.82, avg.score:0.11/0.76\n",
      "# Training EP:45, B:999, ep.loss:283.41\n",
      "# Test avg.loss:0.29, avg.prob.:0.87/0.69, avg.acc.:0.93/0.73, avg.score:0.13/0.69\n",
      "# Training EP:46, B:999, ep.loss:291.73\n",
      "# Test avg.loss:0.36, avg.prob.:0.87/0.70, avg.acc.:0.92/0.69, avg.score:0.13/0.70\n",
      "# Training EP:47, B:999, ep.loss:287.08\n",
      "# Test avg.loss:0.30, avg.prob.:0.86/0.74, avg.acc.:0.94/0.72, avg.score:0.14/0.74\n",
      "# Training EP:48, B:999, ep.loss:287.37\n",
      "# Test avg.loss:0.27, avg.prob.:0.87/0.81, avg.acc.:0.85/0.88, avg.score:0.13/0.81\n",
      "# Training EP:49, B:999, ep.loss:311.59\n",
      "# Test avg.loss:0.33, avg.prob.:0.84/0.68, avg.acc.:0.91/0.69, avg.score:0.16/0.68\n",
      "# Training EP:50, B:999, ep.loss:312.60\n",
      "# Test avg.loss:0.32, avg.prob.:0.84/0.71, avg.acc.:0.91/0.72, avg.score:0.16/0.71\n",
      "# Training EP:51, B:999, ep.loss:294.00\n",
      "# Test avg.loss:0.30, avg.prob.:0.85/0.75, avg.acc.:0.93/0.77, avg.score:0.15/0.75\n",
      "# Training EP:52, B:999, ep.loss:302.34\n",
      "# Test avg.loss:0.29, avg.prob.:0.85/0.77, avg.acc.:0.90/0.76, avg.score:0.15/0.77\n",
      "# Training EP:53, B:999, ep.loss:293.73\n",
      "# Test avg.loss:0.43, avg.prob.:0.84/0.68, avg.acc.:0.92/0.66, avg.score:0.16/0.68\n",
      "# Training EP:54, B:999, ep.loss:317.67\n",
      "# Test avg.loss:0.33, avg.prob.:0.83/0.75, avg.acc.:0.90/0.73, avg.score:0.17/0.75\n",
      "# Training EP:55, B:999, ep.loss:301.20\n",
      "# Test avg.loss:0.30, avg.prob.:0.84/0.71, avg.acc.:0.92/0.72, avg.score:0.16/0.71\n",
      "# Training EP:56, B:999, ep.loss:305.53\n",
      "# Test avg.loss:0.27, avg.prob.:0.87/0.70, avg.acc.:0.95/0.72, avg.score:0.13/0.70\n",
      "# Training EP:57, B:999, ep.loss:277.58\n",
      "# Test avg.loss:0.27, avg.prob.:0.86/0.75, avg.acc.:0.93/0.76, avg.score:0.14/0.75\n",
      "# Training EP:58, B:999, ep.loss:312.22\n",
      "# Test avg.loss:0.25, avg.prob.:0.88/0.73, avg.acc.:0.95/0.75, avg.score:0.12/0.73\n",
      "# Training EP:59, B:999, ep.loss:295.13\n",
      "# Test avg.loss:0.28, avg.prob.:0.87/0.73, avg.acc.:0.94/0.70, avg.score:0.13/0.73\n",
      "# Training EP:60, B:999, ep.loss:295.80\n",
      "# Test avg.loss:0.28, avg.prob.:0.86/0.70, avg.acc.:0.93/0.69, avg.score:0.14/0.70\n",
      "# Training EP:61, B:999, ep.loss:301.12\n",
      "# Test avg.loss:0.33, avg.prob.:0.85/0.66, avg.acc.:0.92/0.68, avg.score:0.15/0.66\n",
      "# Training EP:62, B:999, ep.loss:296.44\n",
      "# Test avg.loss:0.26, avg.prob.:0.88/0.70, avg.acc.:0.94/0.73, avg.score:0.12/0.70\n",
      "# Training EP:63, B:999, ep.loss:298.44\n",
      "# Test avg.loss:0.29, avg.prob.:0.85/0.66, avg.acc.:0.94/0.73, avg.score:0.15/0.66\n",
      "# Training EP:64, B:999, ep.loss:286.60\n",
      "# Test avg.loss:0.32, avg.prob.:0.84/0.71, avg.acc.:0.90/0.71, avg.score:0.16/0.71\n",
      "# Training EP:65, B:497, ep.loss:150.43Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-d2e73a8cc945>\", line 1, in <module>\n",
      "    RankerTrainer(m_config, m_ranker, ld_train, ld_test, optimizer, lossfn)\n",
      "  File \"<ipython-input-8-b388ef1f01da>\", line 5, in RankerTrainer\n",
      "    for batch_idx, (dA, dB, dC) in enumerate(pld_train):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 615, in __next__\n",
      "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 615, in <listcomp>\n",
      "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "  File \"<ipython-input-5-13bc0757fddd>\", line 105, in __getitem__\n",
      "    return self.get_triangle()\n",
      "  File \"<ipython-input-5-13bc0757fddd>\", line 80, in get_triangle\n",
      "    d_checkAC = self.interpreter.sanity_check(d_psAC)\n",
      "  File \"/home/ju-ucsb/Trinity/MorpheusInterpreter.py\", line 305, in sanity_check\n",
      "    ret_val = self.renv(tmp_script)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 389, in __call__\n",
      "    res = self.eval(p)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 364, in __getattribute__\n",
      "    return self.__getitem__(attr)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 370, in __getitem__\n",
      "    res = conversion.rpy2py(res)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/functools.py\", line 824, in wrapper\n",
      "    return dispatch(args[0].__class__)(*args, **kw)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\", line 207, in _rpy2py_sexpclosure\n",
      "    return SignatureTranslatedFunction(obj)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\", line 158, in __init__\n",
      "    formals = self.formals()\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\", line 129, in formals\n",
      "    res = _formals_fixed(self)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\", line 26, in _formals_fixed\n",
      "    tmp = __args(func)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/conversion.py\", line 28, in _\n",
      "    cdata = function(*args, **kwargs)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface.py\", line 766, in __call__\n",
      "    kwargs.items()))\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\", line 215, in build_rcall\n",
      "    rlib.SETCAR(item, cdata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "RankerTrainer(m_config, m_ranker, ld_train, ld_test, optimizer, lossfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
