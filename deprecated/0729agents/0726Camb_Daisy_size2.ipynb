{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaNeo\n",
    "- a version using meta information only, while excluding value-based features\n",
    "- Stage: Cambrian\n",
    "- Version: Yorgia\n",
    "- Update Logs\n",
    "    - 0713: with DeepPath style rollback at training\n",
    "    - 0716: new learning paradigm, see memo for details\n",
    "    - 0726: this is a interactive debugging version, with dead pool deactivated\n",
    "\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(MetaNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        # predict a fixed number of shells\n",
    "#         self.policy = nn.Linear(\n",
    "#             self.config[\"embd_dim\"],\n",
    "#             self.config[\"fn\"][\"vocab_size\"],\n",
    "#         )\n",
    "        \n",
    "        # deeper\n",
    "        self.policy0 = nn.Linear(\n",
    "            self.config[\"embd_dim\"],\n",
    "            128,\n",
    "        )\n",
    "        self.policy1 = nn.Linear(\n",
    "            128,\n",
    "            self.config[\"fn\"][\"vocab_size\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, p_mapin, p_mapout):\n",
    "        # p_mapin/p_mapout: (B, 15*3)\n",
    "        v_delta = p_mapout-p_mapin\n",
    "#         tmp_out = torch.log_softmax(\n",
    "#             self.policy(v_delta),dim=1\n",
    "#         )\n",
    "        tmp_out = torch.log_softmax(\n",
    "            self.policy1(\n",
    "                F.relu(\n",
    "                    self.policy0(\n",
    "                        v_delta\n",
    "                    )\n",
    "                )\n",
    "            ),dim=1\n",
    "        )\n",
    "        \n",
    "        return tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))\n",
    "\n",
    "\n",
    "# '''\n",
    "# meta-train the agent in a supervised way\n",
    "# epoch -> episode, one attempt with hint\n",
    "# NOTICE: only valid for size 1 training\n",
    "# '''\n",
    "# def MetaTrain(p_config, p_spec, p_interpreter, p_model, p_data, p_optim, p_writer):\n",
    "#     print(\"# Start Meta-Train...\")\n",
    "#     for d_epoch in range(p_config[\"meta_train\"][\"n_epoch\"]):\n",
    "#         p_model.train()\n",
    "        \n",
    "#         epoch_loss_list = []\n",
    "#         batch_loss_list = []\n",
    "#         random.shuffle(p_data)\n",
    "#         train_data = p_data[:p_config[\"meta_train\"][\"n_truncated\"]]\n",
    "        \n",
    "#         for d_ind in range(len(train_data)):\n",
    "#             print(\"\\r# epoch:{}, index:{}/{}, avg.loss:{:.2f}\".format(\n",
    "#                 d_epoch, d_ind, len(train_data),\n",
    "#                 sum(epoch_loss_list)/len(epoch_loss_list)\n",
    "#                 if len(epoch_loss_list)>0 else 0,\n",
    "#             ),end=\"\")\n",
    "#             d_prog, dstr_example = train_data[d_ind]\n",
    "#             d_example = Example(\n",
    "#                 input=[\n",
    "#                     p_interpreter.load_data_into_var(p)\n",
    "#                     for p in dstr_example.input\n",
    "#                 ],\n",
    "#                 output=p_interpreter.load_data_into_var(\n",
    "#                     dstr_example.output\n",
    "#                 )\n",
    "#             )\n",
    "            \n",
    "#             # initialize a solution\n",
    "#             ps_solution = ProgramSpace(\n",
    "#                 p_spec, p_interpreter, d_example.input, d_example.output,\n",
    "#             )\n",
    "#             ps_solution.init_by_prog(d_prog) # this constructs a solution for this problem\n",
    "            \n",
    "#             # initialize a new ProgramSpace\n",
    "#             ps_current = ProgramSpace(\n",
    "#                 p_spec, p_interpreter, d_example.input, d_example.output,\n",
    "#             )\n",
    "#             # then initialize a shell template\n",
    "#             tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "#             tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "#             # replace the Param Node id in shells with -1 to make them templates\n",
    "#             template_list = [\n",
    "#                 modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "#                 for i in range(len(tmp_shell_list))\n",
    "#             ]\n",
    "            \n",
    "#             id_current = ps_current.get_strict_frontiers()[0]\n",
    "#             var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "#             var_output = d_example.output\n",
    "            \n",
    "#             map_current = p_interpreter.camb_get_simp_abs(var_current)\n",
    "#             map_output = p_interpreter.camb_get_simp_abs(var_output)\n",
    "            \n",
    "#             # make current shell list\n",
    "#             current_shell_list = [\n",
    "#                 modify_shell(template_list[i],-1,id_current)\n",
    "#                 for i in range(len(template_list))\n",
    "#             ]\n",
    "            \n",
    "#             # wrap in B=1\n",
    "#             if use_cuda:\n",
    "#                 td_current = Variable(torch.tensor([map_current],dtype=torch.float)).cuda()\n",
    "#                 td_output = Variable(torch.tensor([map_output],dtype=torch.float)).cuda()\n",
    "#             else:\n",
    "#                 td_current = Variable(torch.tensor([map_current],dtype=torch.float))\n",
    "#                 td_output = Variable(torch.tensor([map_output],dtype=torch.float))\n",
    "\n",
    "#             # (B=1, fn_vocab_size)\n",
    "#             td_pred = p_model(td_current, td_output)\n",
    "#             # directly give the hint / supervised, ps.solution.shell[0] works for 1\n",
    "#             tmp_id = current_shell_list.index(ps_solution.shells[0])\n",
    "#             d_loss = (+1)*(-td_pred[0,tmp_id])\n",
    "#             batch_loss_list.append(\n",
    "#                 d_loss, # supervised / always correct with +1 reward\n",
    "#             )\n",
    "#             epoch_loss_list.append(\n",
    "#                 d_loss.cpu().data.numpy(),\n",
    "#             )\n",
    "            \n",
    "#             if len(batch_loss_list)%p_config[\"meta_train\"][\"batch_size\"]==0 or len(batch_loss_list)==len(train_data):\n",
    "#                 # do back-prop.\n",
    "#                 if len(batch_loss_list)>0:\n",
    "#                     batch_loss = sum(batch_loss_list)/len(batch_loss_list)\n",
    "#                     p_optim.zero_grad()\n",
    "#                     batch_loss.backward()\n",
    "#                     p_optim.step()\n",
    "#                 # after back-prop., clean up\n",
    "#                 batch_loss = None\n",
    "#                 batch_loss_list = []\n",
    "                \n",
    "#         print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sketch(ps0,ps1):\n",
    "    if len(ps0.node_list)!=len(ps1.node_list):\n",
    "        return False\n",
    "    for i in range(len(ps0.shells)):\n",
    "        if ps0.node_list[-i-1].name != ps1.node_list[-i-1].name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "'''\n",
    "meta-test an agent, directly run into testing / online adaptation\n",
    "'''\n",
    "def MetaTest(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer):\n",
    "    print(\"# Start Meta-Test...\")\n",
    "    \n",
    "    nth_attempt = 0 # tell whether to back-prop or not\n",
    "    batch_loss_list = []\n",
    "    \n",
    "    n_solved = 0 # track the number of solved problem\n",
    "    n_sketch_solved = 0\n",
    "    n_attempt_list = [] # track the number of attempts in every episode\n",
    "    \n",
    "    stored_neurons = []\n",
    "    stored_nodes = []\n",
    "    \n",
    "    for d_episode in range(p_config[\"meta_test\"][\"n_episode\"]):\n",
    "        \n",
    "        # retrieve the given meta-trained model for testing\n",
    "        test_model = copy.deepcopy(p_model)\n",
    "        test_model.train()\n",
    "        \n",
    "        # if doing random meta-testing\n",
    "        # then randomly generate a program for testing\n",
    "        ps_solution = p_generator.get_new_chain_program(\n",
    "            p_config[\"meta_test\"][\"fixed_depth\"],\n",
    "        )\n",
    "        print(\"# benchmark program: {}\".format(\n",
    "            \" -> \".join(\n",
    "                [\n",
    "                    str(ps_solution.node_list[-p_config[\"meta_test\"][\"maxn_step\"]+i]).replace(str(ps_solution.node_list[-p_config[\"meta_test\"][\"maxn_step\"]+i-1]),\"@output\") if i>=1 else str(ps_solution.node_list[-p_config[\"meta_test\"][\"maxn_step\"]+i])\n",
    "                    for i in range(p_config[\"meta_test\"][\"maxn_step\"])\n",
    "                ]\n",
    "            )\n",
    "        ))\n",
    "        print(\"# === input ===\")\n",
    "        print(p_interpreter.renv(ps_solution.inputs[0]))\n",
    "        print(\"# === output ===\")\n",
    "        print(p_interpreter.renv(ps_solution.output))\n",
    "        \n",
    "        is_solved = False\n",
    "        is_sketch_solved = False\n",
    "        \n",
    "        for d_attempt in range(p_config[\"meta_test\"][\"maxn_attempt\"]):\n",
    "            if is_solved:\n",
    "                # already solved in the last attempt, stop\n",
    "                break\n",
    "            \n",
    "            nth_attempt += 1\n",
    "            attempt_reward = None\n",
    "            \n",
    "            # in every new attempt, initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, ps_solution.inputs, ps_solution.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "                \n",
    "            d_step = 0\n",
    "            while d_step<p_config[\"meta_test\"][\"maxn_step\"]:\n",
    "                \n",
    "#                 # print the training progress\n",
    "#                 print(\"\\r# AC/SK/EP:{}/{}/{}, AT:{}, SP:{}, DN:{}, avg.attempt:{:.2f}, er:{:.2f}\".format(\n",
    "#                     n_solved, n_sketch_solved, d_episode, d_attempt, d_step, \n",
    "#                     len(dead_neurons),\n",
    "#                     sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else -1,\n",
    "#                     p_config[\"meta_test\"][\"exploration_rate\"](d_episode,d_attempt),\n",
    "#                 ),end=\"\")\n",
    "                \n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                id_current = ps_current.get_strict_frontiers()[0]\n",
    "                var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "                var_output = ps_current.output\n",
    "                \n",
    "                map_current = p_interpreter.camb_get_simp_abs(var_current)\n",
    "                map_output = p_interpreter.camb_get_simp_abs(var_output)\n",
    "                \n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                \n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float)).cuda()\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float)).cuda()\n",
    "                else:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float))\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float))\n",
    "                    \n",
    "                # (B=1, fn_vocab_size)\n",
    "                td_pred = test_model(td_current, td_output)\n",
    "                \n",
    "                # no hints\n",
    "                if random.random()<=p_config[\"meta_test\"][\"exploration_rate\"](d_episode,d_attempt):\n",
    "                    # exploration\n",
    "                    tmp_id = random.choice(range(len(current_shell_list)))\n",
    "                else:\n",
    "                    # exploitation\n",
    "                    tmp_id = torch.multinomial(td_pred.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "                \n",
    "                # == Yorgia ==\n",
    "                # append before adding shell to ProgramSpace\n",
    "                stored_nodes.append(ps_current.get_node_from_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                ))\n",
    "                \n",
    "                # update ps_current\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if update_status:\n",
    "                    # record selected neuron\n",
    "                    stored_neurons.append(\n",
    "                        (td_pred[0,tmp_id], True)\n",
    "                    )\n",
    "                    d_step += 1\n",
    "                    \n",
    "                    # succeed\n",
    "                    if ps_current.check_eq() is not None:\n",
    "                        # and solved!\n",
    "                        is_solved = True\n",
    "                        n_solved += 1\n",
    "                        break\n",
    "                else:\n",
    "                    stored_neurons.append(\n",
    "                        (td_pred[0,tmp_id], False)\n",
    "                    )\n",
    "                    break\n",
    "            \n",
    "            \n",
    "            if not is_sketch_solved:\n",
    "                if compare_sketch(ps_current, ps_solution):\n",
    "                    is_sketch_solved = True\n",
    "                    n_sketch_solved += 1\n",
    "            \n",
    "            # ask for separate rewards for every step\n",
    "            ar = input(\"# attempt {}, input reward(s) for: {}\".format(\n",
    "                nth_attempt,\n",
    "                \" -> \".join([\n",
    "                    \"({}){}\".format(\n",
    "                        \"✓\" if stored_neurons[i][1] else \"x\",\n",
    "                        str(stored_nodes[i]).replace(str(stored_nodes[i-1]),\"@output\") if i>=1 else str(stored_nodes[i]),\n",
    "                    ) for i in range(len(stored_nodes))\n",
    "                ]),\n",
    "            ))\n",
    "            assigned_rewards = eval(\"[{}]\".format(ar))\n",
    "                \n",
    "            \n",
    "            # compute the loss (sequential selected)\n",
    "            for i in range(len(stored_neurons)):\n",
    "                batch_loss_list.append(\n",
    "                    assigned_rewards[i]*(-stored_neurons[i][0]) \n",
    "                )\n",
    "            \n",
    "            # directly do the back-prop\n",
    "            batch_loss = sum(batch_loss_list)/len(batch_loss_list)\n",
    "            p_optim.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            p_optim.step()\n",
    "            \n",
    "            batch_loss_list = []\n",
    "            stored_neurons = []\n",
    "            stored_nodes = []\n",
    "            \n",
    "            if is_solved:\n",
    "                nth_attempt = 0\n",
    "                break\n",
    "                \n",
    "        # <END_FOR_ATTEMPT> \n",
    "        \n",
    "            \n",
    "    # <END_FOR_EPISODE>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    ")\n",
    "\n",
    "# dumb variable to help infer the shells\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")\n",
    "\n",
    "m_config = {\n",
    "    \"fn\":{\n",
    "        \"vocab_size\": len(m_ps.get_neighboring_shells())\n",
    "    },\n",
    "    \"embd_dim\": 15*3,\n",
    "    # ==== Meta-Learning Setting ==== #\n",
    "#     \"meta_train\":{\n",
    "#         \"n_epoch\": 10,\n",
    "#         \"batch_size\": 4, # how many indices\n",
    "#         \"data_path\": \"./0716MDsize1.pkl\",\n",
    "#         \"n_truncated\": 1000,\n",
    "#     },\n",
    "    \"meta_test\":{\n",
    "        \"n_episode\": 100000,\n",
    "        \"batch_size\": 1, # how many attempts\n",
    "        \"fixed_depth\": 3,\n",
    "        \"maxn_attempt\": 1000000,\n",
    "        \"maxn_step\": 2, # program size\n",
    "        \"exploration_rate\": lambda pep,pat:0.1,\n",
    "        \"decay_rate\": 0.9,\n",
    "        \"dp_cap\": 50,\n",
    "    },\n",
    "}\n",
    "\n",
    "# load the size 1 supervised data\n",
    "# with open(m_config[\"meta_train\"][\"data_path\"],\"rb\") as f:\n",
    "#     dt_data = pickle.load(f)\n",
    "# m_data = [\n",
    "#     dt_data[dkey][i]\n",
    "#     for dkey in dt_data.keys()\n",
    "#     for i in range(len(dt_data[dkey]))\n",
    "# ]\n",
    "# print(\"# Total Meta-Train Data: {}\".format(len(m_data)))\n",
    "\n",
    "meta_neo = MetaNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    meta_neo = meta_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(meta_neo.parameters()))\n",
    "\n",
    "# writer = SummaryWriter(\"runs/0713CAMB_RL2_camb3\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fn': {'vocab_size': 120},\n",
       " 'embd_dim': 45,\n",
       " 'meta_test': {'n_episode': 100000,\n",
       "  'batch_size': 1,\n",
       "  'fixed_depth': 3,\n",
       "  'maxn_attempt': 100,\n",
       "  'maxn_step': 2,\n",
       "  'exploration_rate': <function __main__.<lambda>(pep, pat)>,\n",
       "  'decay_rate': 0.9,\n",
       "  'dp_cap': 50}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MetaTrain(m_config, m_spec, m_interpreter, meta_neo, m_data, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start Meta-Test...\n",
      "# benchmark program: gather(@param0, ['2', '4']) -> unite(@output, 3, 5)\n",
      "# === input ===\n",
      "  choppily upwent   saxonite unsprouting    roleo\n",
      "1        2    -95 preneglect          72 sciolist\n",
      "2       11     76 preneglect         -94 cajolers\n",
      "3      -20     96 preneglect          51 sciolist\n",
      "4       43    -69 cosmozoism          55  staples\n",
      "5       48     77 preneglect          62  staples\n",
      "\n",
      "# === output ===\n",
      "   choppily   saxonite    bipinnate     clinked\n",
      "1         2 preneglect sciolist_-95      upwent\n",
      "2        11 preneglect  cajolers_76      upwent\n",
      "3       -20 preneglect  sciolist_96      upwent\n",
      "4        43 cosmozoism  staples_-69      upwent\n",
      "5        48 preneglect   staples_77      upwent\n",
      "6         2 preneglect  sciolist_72 unsprouting\n",
      "7        11 preneglect cajolers_-94 unsprouting\n",
      "8       -20 preneglect  sciolist_51 unsprouting\n",
      "9        43 cosmozoism   staples_55 unsprouting\n",
      "10       48 preneglect   staples_62 unsprouting\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "# attempt 1, input reward(s) for: (✓)unite(@param0, 3, 2) -> (x)spread(@output, 3, 5) -1,-1\n",
      "# attempt 2, input reward(s) for: (x)gather(@param0, ['3', '4']) 0.5\n",
      "# attempt 3, input reward(s) for: (x)spread(@param0, 6, 4) -1\n",
      "# attempt 4, input reward(s) for: (x)gather(@param0, ['2', '3']) 0.5\n",
      "# attempt 5, input reward(s) for: (x)spread(@param0, 5, 3) -1\n",
      "# attempt 6, input reward(s) for: (x)separate(@param0, 1) -1\n",
      "# attempt 7, input reward(s) for: (x)spread(@param0, 6, 6) -1\n",
      "# attempt 8, input reward(s) for: (x)separate(@param0, 2) -1\n",
      "# attempt 9, input reward(s) for: (✓)unite(@param0, 5, 3) -> (x)spread(@output, 3, 2) -1,-1\n",
      "# attempt 10, input reward(s) for: (x)gather(@param0, ['6']) 0.5\n",
      "# attempt 11, input reward(s) for: (✓)separate(@param0, 3) -> (x)unite(@output, 4, 4) -1,-1\n",
      "# attempt 12, input reward(s) for: (✓)unite(@param0, 3, 4) -> (x)unite(@output, 5, 3) -1,-1\n",
      "# attempt 13, input reward(s) for: (✓)unite(@param0, 3, 5) -> (✓)select(@output, ['1', '4']) -1,-1\n",
      "# attempt 14, input reward(s) for: (x)gather(@param0, ['2', '6']) 0.5\n",
      "# attempt 15, input reward(s) for: (✓)gather(@param0, ['1']) -> (x)spread(@output, 4, 2) 0.5,-1\n",
      "# attempt 16, input reward(s) for: (✓)select(@param0, ['2', '4']) -> (x)spread(@output, 5, 3) -1,-1\n",
      "# attempt 17, input reward(s) for: (x)spread(@param0, 1, 1) -1\n",
      "# attempt 18, input reward(s) for: (x)select(@param0, ['1', '6']) -1\n",
      "# attempt 19, input reward(s) for: (✓)unite(@param0, 2, 5) -> (✓)gather(@output, ['2']) -1,-1\n",
      "# attempt 20, input reward(s) for: (✓)select(@param0, ['1', '2']) -> (x)spread(@output, 4, 2) -1,-1\n",
      "# attempt 21, input reward(s) for: (✓)separate(@param0, 3) -> (x)spread(@output, 5, 2) -1,-1\n",
      "# attempt 22, input reward(s) for: (✓)unite(@param0, 2, 3) -> (✓)select(@output, ['1']) -1,-1\n",
      "# attempt 23, input reward(s) for: (✓)gather(@param0, ['3']) -> (x)spread(@output, 5, 2) 0.5,-1\n",
      "# attempt 24, input reward(s) for: (✓)spread(@param0, 1, 3) -> (✓)unite(@output, 6, 4) -1,-1\n",
      "# attempt 25, input reward(s) for: (x)gather(@param0, ['1', '6']) 0.5\n",
      "# attempt 26, input reward(s) for: (x)gather(@param0, ['2', '5']) 0.5\n",
      "# attempt 27, input reward(s) for: (x)spread(@param0, 4, 1) -1\n",
      "# attempt 28, input reward(s) for: (✓)gather(@param0, ['1', '4']) -> (x)spread(@output, 3, 3) 0.5,-1\n",
      "# attempt 29, input reward(s) for: (x)spread(@param0, 4, 6) -1\n",
      "# attempt 30, input reward(s) for: (x)separate(@param0, 6) -1\n",
      "# attempt 31, input reward(s) for: (x)unite(@param0, 2, 6) -1\n",
      "# attempt 32, input reward(s) for: (✓)select(@param0, ['4']) -> (x)spread(@output, 4, 2) -1,-1\n",
      "# attempt 33, input reward(s) for: (x)select(@param0, ['1', '6']) -1\n",
      "# attempt 34, input reward(s) for: (✓)spread(@param0, 2, 3) -> (✓)gather(@output, ['4', '5']) -1,-1\n",
      "# attempt 35, input reward(s) for: (✓)select(@param0, ['3']) -> (x)select(@output, ['2', '6']) -1,-1\n",
      "# attempt 36, input reward(s) for: (✓)gather(@param0, ['1']) -> (x)separate(@output, 3) 0.5,-1\n",
      "# attempt 37, input reward(s) for: (x)spread(@param0, 4, 2) -1\n",
      "# attempt 38, input reward(s) for: (✓)unite(@param0, 3, 1) -> (x)select(@output, ['5', '6']) -1,-1\n",
      "# attempt 39, input reward(s) for: (x)spread(@param0, 4, 6) -1\n",
      "# attempt 40, input reward(s) for: (x)gather(@param0, ['2', '5']) 0.5\n",
      "# attempt 41, input reward(s) for: (x)unite(@param0, 3, 3) -1\n",
      "# attempt 42, input reward(s) for: (x)unite(@param0, 6, 5) -1\n",
      "# attempt 43, input reward(s) for: (✓)select(@param0, ['1', '4']) -> (✓)gather(@output, ['1', '2']) -1,-1\n",
      "# attempt 44, input reward(s) for: (x)select(@param0, ['3', '6']) -1\n",
      "# attempt 45, input reward(s) for: (x)spread(@param0, 3, 6) -1\n",
      "# attempt 46, input reward(s) for: (x)spread(@param0, 1, 1) -1\n",
      "# attempt 47, input reward(s) for: (✓)select(@param0, ['1', '5']) -> (x)unite(@output, 1, 1) -1,-1\n",
      "# attempt 48, input reward(s) for: (✓)separate(@param0, 5) -> (✓)gather(@output, ['1', '4']) -1,-1\n",
      "# attempt 49, input reward(s) for: (x)spread(@param0, 4, 3) -1\n",
      "# attempt 50, input reward(s) for: (✓)spread(@param0, 2, 5) -> (✓)unite(@output, 4, 2) -1,-1\n",
      "# attempt 51, input reward(s) for: (✓)gather(@param0, ['3']) -> (x)spread(@output, 6, 3) 0.5,-1\n",
      "# attempt 52, input reward(s) for: (x)unite(@param0, 3, 3) -1\n",
      "# attempt 53, input reward(s) for: (✓)gather(@param0, ['5']) -> (✓)unite(@output, 3, 6) 0.5,0.5\n",
      "# attempt 54, input reward(s) for: (x)spread(@param0, 4, 1) -1\n",
      "# attempt 55, input reward(s) for: (x)spread(@param0, 6, 5) -1\n",
      "# attempt 56, input reward(s) for: (✓)spread(@param0, 1, 2) -> (✓)select(@output, ['1', '3']) -1,-1\n",
      "# attempt 57, input reward(s) for: (x)spread(@param0, 6, 1) -1\n",
      "# attempt 58, input reward(s) for: (x)spread(@param0, 4, 6) -1\n",
      "# attempt 59, input reward(s) for: (✓)unite(@param0, 2, 5) -> (x)select(@output, ['5']) -1,-1\n",
      "# attempt 60, input reward(s) for: (x)spread(@param0, 5, 6) -1\n",
      "# attempt 61, input reward(s) for: (✓)spread(@param0, 2, 3) -> (✓)unite(@output, 4, 1) -1,-1\n",
      "# attempt 62, input reward(s) for: (x)spread(@param0, 5, 2) -1\n",
      "# attempt 63, input reward(s) for: (✓)spread(@param0, 1, 3) -> (x)unite(@output, 4, 4) -1,-1\n",
      "# attempt 64, input reward(s) for: (✓)unite(@param0, 2, 1) -> (x)spread(@output, 4, 2) -1,-1\n",
      "# attempt 65, input reward(s) for: (x)spread(@param0, 6, 4) -1\n",
      "# attempt 66, input reward(s) for: (x)spread(@param0, 6, 3) -1\n",
      "# attempt 67, input reward(s) for: (x)unite(@param0, 2, 6) -1\n",
      "# attempt 68, input reward(s) for: (x)spread(@param0, 2, 1) -1\n",
      "# attempt 69, input reward(s) for: (x)spread(@param0, 6, 6) -1\n",
      "# attempt 70, input reward(s) for: (x)unite(@param0, 6, 3) -1\n",
      "# attempt 71, input reward(s) for: (x)spread(@param0, 6, 4) -1\n",
      "# attempt 72, input reward(s) for: (x)spread(@param0, 2, 6) -1\n",
      "# attempt 73, input reward(s) for: (✓)unite(@param0, 5, 1) -> (x)spread(@output, 1, 1) -1,-1\n",
      "# attempt 74, input reward(s) for: (x)spread(@param0, 5, 1) -1\n",
      "# attempt 75, input reward(s) for: (x)gather(@param0, ['3', '4']) 0.5\n",
      "# attempt 76, input reward(s) for: (x)unite(@param0, 5, 5) -1\n",
      "# attempt 77, input reward(s) for: (x)spread(@param0, 6, 3) -1\n",
      "# attempt 78, input reward(s) for: (x)unite(@param0, 2, 6) -1\n",
      "# attempt 79, input reward(s) for: (x)select(@param0, ['6']) -1\n",
      "# attempt 80, input reward(s) for: (x)gather(@param0, ['1', '6']) 0.5\n",
      "# attempt 81, input reward(s) for: (✓)select(@param0, ['5']) -> (x)spread(@output, 3, 5) -1,-1\n",
      "# attempt 82, input reward(s) for: (✓)unite(@param0, 3, 5) -> (✓)gather(@output, ['1', '4']) -1,-1\n",
      "# attempt 83, input reward(s) for: (x)gather(@param0, ['2', '5']) 0.5\n",
      "# attempt 84, input reward(s) for: (✓)unite(@param0, 1, 4) -> (x)spread(@output, 3, 6) -1,-1\n",
      "# attempt 85, input reward(s) for: (✓)unite(@param0, 5, 3) -> (x)select(@output, ['2', '5']) -1,-1\n",
      "# attempt 86, input reward(s) for: (x)gather(@param0, ['1', '3']) 0.5\n",
      "# attempt 87, input reward(s) for: (x)spread(@param0, 4, 1) -1\n",
      "# attempt 88, input reward(s) for: (x)spread(@param0, 1, 6) -1\n",
      "# attempt 89, input reward(s) for: (✓)spread(@param0, 3, 4) -> (x)spread(@output, 6, 3) -1,-1\n",
      "# attempt 90, input reward(s) for: (x)spread(@param0, 4, 1) -1\n",
      "# attempt 91, input reward(s) for: (✓)spread(@param0, 1, 4) -> (✓)unite(@output, 6, 2) -1,-1\n",
      "# attempt 92, input reward(s) for: (x)gather(@param0, ['1', '3']) 0.5\n",
      "# attempt 93, input reward(s) for: (x)gather(@param0, ['2', '3']) 0.5\n",
      "# attempt 94, input reward(s) for: (✓)separate(@param0, 3) -> (✓)select(@output, ['1', '6']) -1,-1\n",
      "# attempt 95, input reward(s) for: (✓)spread(@param0, 1, 3) -> (✓)gather(@output, ['2']) -1,-1\n",
      "# attempt 96, input reward(s) for: (✓)gather(@param0, ['1', '4']) -> (x)spread(@output, 3, 3) 0.5,-1\n",
      "# attempt 97, input reward(s) for: (✓)select(@param0, ['2']) -> (x)spread(@output, 5, 1) -1,-1\n",
      "# attempt 98, input reward(s) for: (x)unite(@param0, 1, 1) -1\n",
      "# attempt 99, input reward(s) for: (✓)gather(@param0, ['1']) -> (✓)unite(@output, 1, 4) 0.5,0.5\n",
      "# attempt 100, input reward(s) for: (x)unite(@param0, 3, 6) -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# benchmark program: unite(@param0, 2, 1) -> separate(@output, 1)\n",
      "# === input ===\n",
      "  hindsight     esonarthex kochia pavin    misfielded rheologists\n",
      "1        -7 frankeniaceous    -17    -3      sucriers       68.24\n",
      "2        -7 frankeniaceous     80    47      pericarp       95.16\n",
      "3       -99 frankeniaceous    -17    23   horseshoers      -88.14\n",
      "4        -7     drawcansir    -17    32        whorls       67.37\n",
      "5       -43 frankeniaceous    -17     9     neomycins      -49.64\n",
      "6       -43 frankeniaceous     80   -23      agonista      -98.62\n",
      "7       -43 frankeniaceous    -17   -48       hummeri       96.95\n",
      "8        -7 frankeniaceous     80   -98 nonremittably        1.70\n",
      "\n",
      "# === output ===\n",
      "      centroidal epauliere kochia pavin    misfielded rheologists\n",
      "1 frankeniaceous         7    -17    -3      sucriers       68.24\n",
      "2 frankeniaceous         7     80    47      pericarp       95.16\n",
      "3 frankeniaceous        99    -17    23   horseshoers      -88.14\n",
      "4     drawcansir         7    -17    32        whorls       67.37\n",
      "5 frankeniaceous        43    -17     9     neomycins      -49.64\n",
      "6 frankeniaceous        43     80   -23      agonista      -98.62\n",
      "7 frankeniaceous        43    -17   -48       hummeri       96.95\n",
      "8 frankeniaceous         7     80   -98 nonremittably        1.70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MetaTest(m_config, m_spec, m_interpreter, m_generator, meta_neo, optimizer, writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
