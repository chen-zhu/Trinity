{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransNeo/AlphaNeo\n",
    "- AlphaNeo using pre-trained TransE embeddings (optional)\n",
    "- Stage: Cambrian\n",
    "- Version: Spriggina\n",
    "- Update Logs\n",
    "    - 0713: with DeepPath style rollback at training\n",
    "    - **0716: new learning paradigm, see memo for details**\n",
    "\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(TransNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        # predict a fixed number of shells\n",
    "#         self.policy = nn.Linear(\n",
    "#             self.config[\"embd_dim\"],\n",
    "#             self.config[\"fn\"][\"vocab_size\"],\n",
    "#         )\n",
    "        \n",
    "        # deeper\n",
    "        self.policy0 = nn.Linear(\n",
    "            self.config[\"embd_dim\"],\n",
    "            128,\n",
    "        )\n",
    "        self.policy1 = nn.Linear(\n",
    "            128,\n",
    "            self.config[\"fn\"][\"vocab_size\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, p_mapin, p_mapout):\n",
    "        # p_mapin/p_mapout: (B, 15*3)\n",
    "        v_delta = p_mapout-p_mapin\n",
    "#         tmp_out = torch.log_softmax(\n",
    "#             self.policy(v_delta),dim=1\n",
    "#         )\n",
    "        tmp_out = torch.log_softmax(\n",
    "            self.policy1(\n",
    "                F.relu(\n",
    "                    self.policy0(\n",
    "                        v_delta\n",
    "                    )\n",
    "                )\n",
    "            ),dim=1\n",
    "        )\n",
    "        \n",
    "        return tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))\n",
    "\n",
    "\n",
    "'''\n",
    "meta-train the agent in a supervised way\n",
    "epoch -> episode, one attempt with hint\n",
    "NOTICE: only valid for size 1 training\n",
    "'''\n",
    "def MetaTrain(p_config, p_spec, p_interpreter, p_model, p_data, p_optim, p_writer):\n",
    "    print(\"# Start Meta-Train...\")\n",
    "    for d_epoch in range(p_config[\"meta_train\"][\"n_epoch\"]):\n",
    "        p_model.train()\n",
    "        \n",
    "        epoch_loss_list = []\n",
    "        batch_loss_list = []\n",
    "        random.shuffle(p_data)\n",
    "        train_data = p_data[:p_config[\"meta_train\"][\"n_truncated\"]]\n",
    "        \n",
    "        for d_ind in range(len(train_data)):\n",
    "            print(\"\\r# epoch:{}, index:{}/{}, avg.loss:{:.2f}\".format(\n",
    "                d_epoch, d_ind, len(train_data),\n",
    "                sum(epoch_loss_list)/len(epoch_loss_list)\n",
    "                if len(epoch_loss_list)>0 else 0,\n",
    "            ),end=\"\")\n",
    "            d_prog, dstr_example = train_data[d_ind]\n",
    "            d_example = Example(\n",
    "                input=[\n",
    "                    p_interpreter.load_data_into_var(p)\n",
    "                    for p in dstr_example.input\n",
    "                ],\n",
    "                output=p_interpreter.load_data_into_var(\n",
    "                    dstr_example.output\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # initialize a solution\n",
    "            ps_solution = ProgramSpace(\n",
    "                p_spec, p_interpreter, d_example.input, d_example.output,\n",
    "            )\n",
    "            ps_solution.init_by_prog(d_prog) # this constructs a solution for this problem\n",
    "            \n",
    "            # initialize a new ProgramSpace\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, d_example.input, d_example.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "            \n",
    "            id_current = ps_current.get_strict_frontiers()[0]\n",
    "            var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "            var_output = d_example.output\n",
    "            \n",
    "            map_current = p_interpreter.camb_get_simp_abs(var_current)\n",
    "            map_output = p_interpreter.camb_get_simp_abs(var_output)\n",
    "            \n",
    "            # make current shell list\n",
    "            current_shell_list = [\n",
    "                modify_shell(template_list[i],-1,id_current)\n",
    "                for i in range(len(template_list))\n",
    "            ]\n",
    "            \n",
    "            # wrap in B=1\n",
    "            if use_cuda:\n",
    "                td_current = Variable(torch.tensor([map_current],dtype=torch.float)).cuda()\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.float)).cuda()\n",
    "            else:\n",
    "                td_current = Variable(torch.tensor([map_current],dtype=torch.float))\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.float))\n",
    "\n",
    "            # (B=1, fn_vocab_size)\n",
    "            td_pred = p_model(td_current, td_output)\n",
    "            # directly give the hint / supervised, ps.solution.shell[0] works for 1\n",
    "            tmp_id = current_shell_list.index(ps_solution.shells[0])\n",
    "            d_loss = (+1)*(-td_pred[0,tmp_id])\n",
    "            batch_loss_list.append(\n",
    "                d_loss, # supervised / always correct with +1 reward\n",
    "            )\n",
    "            epoch_loss_list.append(\n",
    "                d_loss.cpu().data.numpy(),\n",
    "            )\n",
    "            \n",
    "            if len(batch_loss_list)%p_config[\"meta_train\"][\"batch_size\"]==0 or len(batch_loss_list)==len(train_data):\n",
    "                # do back-prop.\n",
    "                if len(batch_loss_list)>0:\n",
    "                    batch_loss = sum(batch_loss_list)/len(batch_loss_list)\n",
    "                    p_optim.zero_grad()\n",
    "                    batch_loss.backward()\n",
    "                    p_optim.step()\n",
    "                # after back-prop., clean up\n",
    "                batch_loss = None\n",
    "                batch_loss_list = []\n",
    "                \n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sketch(ps0,ps1):\n",
    "    if len(ps0.node_list)!=len(ps1.node_list):\n",
    "        return False\n",
    "    for i in range(len(ps0.shells)):\n",
    "        if ps0.node_list[-i-1].name != ps1.node_list[-i-1].name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "'''\n",
    "meta-test an agent, directly run into testing / online adaptation\n",
    "'''\n",
    "def MetaTest(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer):\n",
    "    print(\"# Start Meta-Test...\")\n",
    "    \n",
    "    nth_attempt = 0 # tell whether to back-prop or not\n",
    "    batch_lossA_list = []\n",
    "    batch_lossD_list = []\n",
    "    \n",
    "    n_solved = 0 # track the number of solved problem\n",
    "    n_sketch_solved = 0\n",
    "    n_attempt_list = [] # track the number of attempts in every episode\n",
    "    \n",
    "    selected_neurons = []\n",
    "    dead_neurons = [] # DeepPath: store node with execution error\n",
    "    \n",
    "    for d_episode in range(p_config[\"meta_test\"][\"n_episode\"]):\n",
    "        \n",
    "        # retrieve the given meta-trained model for testing\n",
    "        test_model = copy.deepcopy(p_model)\n",
    "        test_model.train()\n",
    "        test_optim = torch.optim.Adam(list(test_model.parameters()))\n",
    "        \n",
    "        # if doing random meta-testing\n",
    "        # then randomly generate a program for testing\n",
    "        ps_solution = p_generator.get_new_chain_program(\n",
    "            p_config[\"meta_test\"][\"fixed_depth\"],\n",
    "        )\n",
    "        \n",
    "        f = open(\"./outputs/Alice2/Problem_{}.txt\".format(d_episode), \"w\")\n",
    "        f.write(\"# Problem: {}\\n\\n\".format(str(ps_solution.node_list[-1])))\n",
    "        f.write(\"# Input:\\n{}\\n\".format(p_interpreter.renv(ps_solution.inputs[0])))\n",
    "        f.write(\"# Output:\\n{}\\n\".format(p_interpreter.renv(ps_solution.output)))\n",
    "        f.flush()\n",
    "        \n",
    "        is_solved = False\n",
    "        is_sketch_solved = False\n",
    "        \n",
    "        for d_attempt in range(p_config[\"meta_test\"][\"maxn_attempt\"]):\n",
    "            if is_solved:\n",
    "                # already solved in the last attempt, stop\n",
    "                break\n",
    "            \n",
    "            nth_attempt += 1\n",
    "            attempt_reward = None\n",
    "            \n",
    "            # in every new attempt, initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, ps_solution.inputs, ps_solution.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "                \n",
    "            d_step = 0\n",
    "            while d_step<p_config[\"meta_test\"][\"maxn_step\"]:\n",
    "                \n",
    "                # print the training progress\n",
    "                print(\"\\r# AC/SK/EP:{}/{}/{}, AT:{}, SP:{}, DN:{}, avg.attempt:{:.2f}, er:{:.2f}\".format(\n",
    "                    n_solved, n_sketch_solved, d_episode, d_attempt, d_step, \n",
    "                    len(dead_neurons),\n",
    "                    sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else -1,\n",
    "                    p_config[\"meta_test\"][\"exploration_rate\"](d_episode,d_attempt),\n",
    "                ),end=\"\")\n",
    "                \n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                id_current = ps_current.get_strict_frontiers()[0]\n",
    "                var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "                var_output = ps_current.output\n",
    "                \n",
    "                map_current = p_interpreter.camb_get_simp_abs(var_current)\n",
    "                map_output = p_interpreter.camb_get_simp_abs(var_output)\n",
    "                \n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                \n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float)).cuda()\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float)).cuda()\n",
    "                else:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float))\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float))\n",
    "                    \n",
    "                # (B=1, fn_vocab_size)\n",
    "                td_pred = test_model(td_current, td_output)\n",
    "                \n",
    "                # no hints\n",
    "                if random.random()<=p_config[\"meta_test\"][\"exploration_rate\"](d_episode,d_attempt):\n",
    "                    # exploration\n",
    "                    tmp_id = random.choice(range(len(current_shell_list)))\n",
    "                else:\n",
    "                    # exploitation\n",
    "                    tmp_id = torch.multinomial(td_pred.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "                \n",
    "                # update ps_current\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if update_status:\n",
    "                    # record selected neuron\n",
    "                    selected_neurons.append(td_pred[0,tmp_id])\n",
    "                    d_step += 1\n",
    "                    \n",
    "                    # succeed\n",
    "                    if ps_current.check_eq() is not None:\n",
    "                        # and solved!\n",
    "                        is_solved = True\n",
    "                        n_solved += 1\n",
    "                        attempt_reward = 1.0\n",
    "                        break\n",
    "                else:\n",
    "                    # DeepPath: fail, add to dead list\n",
    "                    dead_neurons.append(td_pred[0,tmp_id])\n",
    "                    if len(dead_neurons)>p_config[\"meta_test\"][\"dp_cap\"]:\n",
    "                        # exceed the max capacity of dead pool\n",
    "                        break\n",
    "            \n",
    "            # <END_FOR_STEP>\n",
    "            f.write(\"# ({}) Proposed {}/{}: {}\\n\".format(\n",
    "                \"accept\" if is_solved else \"reject\",\n",
    "                d_attempt, p_config[\"meta_test\"][\"maxn_attempt\"],\n",
    "                str(ps_current.node_list[-1])\n",
    "            ))\n",
    "            f.flush()\n",
    "            \n",
    "            if not is_sketch_solved:\n",
    "                if compare_sketch(ps_current, ps_solution):\n",
    "                    is_sketch_solved = True\n",
    "                    n_sketch_solved += 1\n",
    "            \n",
    "            # check the attempt_reward\n",
    "            if attempt_reward is None:\n",
    "                # means either failure in execution or exceeding max_step\n",
    "                attempt_reward = -1.\n",
    "            \n",
    "            # compute the loss (sequential selected)\n",
    "            for i in range(len(selected_neurons)):\n",
    "                d_decay = p_config[\"meta_test\"][\"decay_rate\"]**(len(selected_neurons)-1-i)\n",
    "                batch_lossA_list.append(\n",
    "                    d_decay*attempt_reward*(-selected_neurons[i]) \n",
    "                )\n",
    "            \n",
    "            # compute the loss (dead neurons)\n",
    "            for i in range(len(dead_neurons)):\n",
    "                batch_lossD_list.append(\n",
    "                    (-1.)*(-dead_neurons[i])\n",
    "                )\n",
    "            \n",
    "            if is_solved or nth_attempt>=p_config[\"meta_test\"][\"batch_size\"]:\n",
    "                # directly do the back-prop\n",
    "                if len(batch_lossD_list)>0:\n",
    "                    batch_lossD = sum(batch_lossD_list)/len(batch_lossD_list)\n",
    "                    test_optim.zero_grad()\n",
    "                    batch_lossD.backward()\n",
    "                    test_optim.step()\n",
    "                \n",
    "                if len(batch_lossA_list)>0:\n",
    "                    batch_lossA = sum(batch_lossA_list)/len(batch_lossA_list)\n",
    "                    test_optim.zero_grad()\n",
    "                    batch_lossA.backward()\n",
    "                    test_optim.step()\n",
    "            \n",
    "                nth_attempt = 0\n",
    "                batch_lossA_list = []\n",
    "                batch_lossD_list = []\n",
    "                selected_neurons = []\n",
    "                dead_neurons = []\n",
    "                \n",
    "        # <END_FOR_ATTEMPT>     \n",
    "        \n",
    "        # after all the attempts\n",
    "        n_attempt_list.append(d_attempt)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\n",
    "                'avg.attempt',\n",
    "                sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else 0,\n",
    "                len(n_attempt_list),\n",
    "            )\n",
    "        \n",
    "        f.close()\n",
    "            \n",
    "    # <END_FOR_EPISODE>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Total Meta-Train Data: 77038\n"
     ]
    }
   ],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    ")\n",
    "\n",
    "# dumb variable to help infer the shells\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")\n",
    "\n",
    "m_config = {\n",
    "    \"fn\":{\n",
    "        \"vocab_size\": len(m_ps.get_neighboring_shells())\n",
    "    },\n",
    "    \"embd_dim\": 15*3,\n",
    "    # ==== Meta-Learning Setting ==== #\n",
    "    \"meta_train\":{\n",
    "        \"n_epoch\": 10,\n",
    "        \"batch_size\": 4, # how many indices\n",
    "        \"data_path\": \"./0716MDsize1.pkl\",\n",
    "        \"n_truncated\": 1000,\n",
    "    },\n",
    "    \"meta_test\":{\n",
    "        \"n_episode\": 100000,\n",
    "        \"batch_size\": 1, # how many attempts\n",
    "        \"fixed_depth\": 3,\n",
    "        \"maxn_attempt\": 100,\n",
    "        \"maxn_step\": 2, # program size\n",
    "        \"exploration_rate\": lambda pep,pat:0.1,\n",
    "        \"decay_rate\": 0.9,\n",
    "        \"dp_cap\": 50,\n",
    "    },\n",
    "}\n",
    "\n",
    "# load the size 1 supervised data\n",
    "with open(m_config[\"meta_train\"][\"data_path\"],\"rb\") as f:\n",
    "    dt_data = pickle.load(f)\n",
    "m_data = [\n",
    "    dt_data[dkey][i]\n",
    "    for dkey in dt_data.keys()\n",
    "    for i in range(len(dt_data[dkey]))\n",
    "]\n",
    "print(\"# Total Meta-Train Data: {}\".format(len(m_data)))\n",
    "\n",
    "trans_neo = TransNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    trans_neo = trans_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(trans_neo.parameters()))\n",
    "\n",
    "# writer = SummaryWriter(\"runs/0713CAMB_RL2_camb3\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fn': {'vocab_size': 120},\n",
       " 'embd_dim': 45,\n",
       " 'meta_train': {'n_epoch': 10,\n",
       "  'batch_size': 4,\n",
       "  'data_path': './0716MDsize1.pkl',\n",
       "  'n_truncated': 1000},\n",
       " 'meta_test': {'n_episode': 100000,\n",
       "  'batch_size': 1,\n",
       "  'fixed_depth': 3,\n",
       "  'maxn_attempt': 100,\n",
       "  'maxn_step': 2,\n",
       "  'exploration_rate': <function __main__.<lambda>(pep, pat)>,\n",
       "  'decay_rate': 0.9,\n",
       "  'dp_cap': 50}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start Meta-Train...\n",
      "# epoch:0, index:999/1000, avg.loss:4.31\n",
      "# epoch:1, index:999/1000, avg.loss:3.18\n",
      "# epoch:2, index:999/1000, avg.loss:2.50\n",
      "# epoch:3, index:999/1000, avg.loss:2.27\n",
      "# epoch:4, index:999/1000, avg.loss:2.19\n",
      "# epoch:5, index:999/1000, avg.loss:2.13\n",
      "# epoch:6, index:999/1000, avg.loss:2.10\n",
      "# epoch:7, index:999/1000, avg.loss:2.04\n",
      "# epoch:8, index:999/1000, avg.loss:2.04\n",
      "# epoch:9, index:999/1000, avg.loss:1.96\n"
     ]
    }
   ],
   "source": [
    "MetaTrain(m_config, m_spec, m_interpreter, trans_neo, m_data, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start Meta-Test...\n",
      "# AC/SK/EP:30/90/99, AT:67, SP:0, DN:0, avg.attempt:78.41, er:0.10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cdc6b9d424ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMetaTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_interpreter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_neo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-e81a6df06cd9>\u001b[0m in \u001b[0;36mMetaTest\u001b[0;34m(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mvar_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps_current\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mmap_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamb_get_simp_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mmap_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamb_get_simp_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/MorpheusInterpreter.py\u001b[0m in \u001b[0;36mcamb_get_simp_abs\u001b[0;34m(self, p_obj, verbose)\u001b[0m\n\u001b[1;32m    838\u001b[0m     '''\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcamb_get_simp_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0mnp_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamb_get_np_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0mone_hot_nrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAMB_NROW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/MorpheusInterpreter.py\u001b[0m in \u001b[0;36mcamb_get_np_obj\u001b[0;34m(self, p_obj)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;31m# deal with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;31m# \"data frame with 0 columns and 10 rows\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrow({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m             \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ncol({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStrSexpVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/conversion.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cdata_res_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# TODO: test cdata is of the expected CType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cdata_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m                     \u001b[0mcall_r\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                     \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobalenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sexp__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                     error_occured))\n\u001b[0m\u001b[1;32m    772\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_occured\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_geterrmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MetaTest(m_config, m_spec, m_interpreter, m_generator, trans_neo, optimizer, writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
