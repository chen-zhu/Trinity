{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransNeo/AlphaNeo\n",
    "- AlphaNeo using pre-trained TransE embeddings (optional)\n",
    "- Stage: Cambrian\n",
    "- Version: Spriggina\n",
    "- Update Logs\n",
    "    - 0713: with DeepPath style rollback at training\n",
    "    - **0716: new learning paradigm, see memo for details**\n",
    "\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(TransNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        # predict a fixed number of shells\n",
    "#         self.policy = nn.Linear(\n",
    "#             self.config[\"embd_dim\"],\n",
    "#             self.config[\"fn\"][\"vocab_size\"],\n",
    "#         )\n",
    "        \n",
    "        # deeper\n",
    "        self.policy0 = nn.Linear(\n",
    "            self.config[\"embd_dim\"],\n",
    "            128,\n",
    "        )\n",
    "        self.policy1 = nn.Linear(\n",
    "            128,\n",
    "            self.config[\"fn\"][\"vocab_size\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, p_mapin, p_mapout):\n",
    "        # p_mapin/p_mapout: (B, 15*3)\n",
    "        v_delta = p_mapout-p_mapin\n",
    "#         tmp_out = torch.log_softmax(\n",
    "#             self.policy(v_delta),dim=1\n",
    "#         )\n",
    "        tmp_out = torch.log_softmax(\n",
    "            self.policy1(\n",
    "                F.relu(\n",
    "                    self.policy0(\n",
    "                        v_delta\n",
    "                    )\n",
    "                )\n",
    "            ),dim=1\n",
    "        )\n",
    "        \n",
    "        return tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))\n",
    "\n",
    "\n",
    "'''\n",
    "meta-train the agent in a supervised way\n",
    "epoch -> episode, one attempt with hint\n",
    "NOTICE: only valid for size 1 training\n",
    "'''\n",
    "def MetaTrain(p_config, p_spec, p_interpreter, p_model, p_data, p_optim, p_writer):\n",
    "    print(\"# Start Meta-Train...\")\n",
    "    for d_epoch in range(p_config[\"meta_train\"][\"n_epoch\"]):\n",
    "        p_model.train()\n",
    "        \n",
    "        epoch_loss_list = []\n",
    "        batch_loss_list = []\n",
    "        random.shuffle(p_data)\n",
    "        train_data = p_data[:p_config[\"meta_train\"][\"n_truncated\"]]\n",
    "        \n",
    "        for d_ind in range(len(train_data)):\n",
    "            print(\"\\r# epoch:{}, index:{}/{}, avg.loss:{:.2f}\".format(\n",
    "                d_epoch, d_ind, len(train_data),\n",
    "                sum(epoch_loss_list)/len(epoch_loss_list)\n",
    "                if len(epoch_loss_list)>0 else 0,\n",
    "            ),end=\"\")\n",
    "            d_prog, dstr_example = train_data[d_ind]\n",
    "            d_example = Example(\n",
    "                input=[\n",
    "                    p_interpreter.load_data_into_var(p)\n",
    "                    for p in dstr_example.input\n",
    "                ],\n",
    "                output=p_interpreter.load_data_into_var(\n",
    "                    dstr_example.output\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # initialize a solution\n",
    "            ps_solution = ProgramSpace(\n",
    "                p_spec, p_interpreter, d_example.input, d_example.output,\n",
    "            )\n",
    "            ps_solution.init_by_prog(d_prog) # this constructs a solution for this problem\n",
    "            \n",
    "            # initialize a new ProgramSpace\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, d_example.input, d_example.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "            \n",
    "            id_current = ps_current.get_strict_frontiers()[0]\n",
    "            var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "            var_output = d_example.output\n",
    "            \n",
    "            map_current = p_interpreter.camb_get_simp_abs(var_current)\n",
    "            map_output = p_interpreter.camb_get_simp_abs(var_output)\n",
    "            \n",
    "            # make current shell list\n",
    "            current_shell_list = [\n",
    "                modify_shell(template_list[i],-1,id_current)\n",
    "                for i in range(len(template_list))\n",
    "            ]\n",
    "            \n",
    "            # wrap in B=1\n",
    "            if use_cuda:\n",
    "                td_current = Variable(torch.tensor([map_current],dtype=torch.float)).cuda()\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.float)).cuda()\n",
    "            else:\n",
    "                td_current = Variable(torch.tensor([map_current],dtype=torch.float))\n",
    "                td_output = Variable(torch.tensor([map_output],dtype=torch.float))\n",
    "\n",
    "            # (B=1, fn_vocab_size)\n",
    "            td_pred = p_model(td_current, td_output)\n",
    "            # directly give the hint / supervised, ps.solution.shell[0] works for 1\n",
    "            tmp_id = current_shell_list.index(ps_solution.shells[0])\n",
    "            d_loss = (+1)*(-td_pred[0,tmp_id])\n",
    "            batch_loss_list.append(\n",
    "                d_loss, # supervised / always correct with +1 reward\n",
    "            )\n",
    "            epoch_loss_list.append(\n",
    "                d_loss.cpu().data.numpy(),\n",
    "            )\n",
    "            \n",
    "            if len(batch_loss_list)%p_config[\"meta_train\"][\"batch_size\"]==0 or len(batch_loss_list)==len(train_data):\n",
    "                # do back-prop.\n",
    "                if len(batch_loss_list)>0:\n",
    "                    batch_loss = sum(batch_loss_list)/len(batch_loss_list)\n",
    "                    p_optim.zero_grad()\n",
    "                    batch_loss.backward()\n",
    "                    p_optim.step()\n",
    "                # after back-prop., clean up\n",
    "                batch_loss = None\n",
    "                batch_loss_list = []\n",
    "                \n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sketch(ps0,ps1):\n",
    "    if len(ps0.node_list)!=len(ps1.node_list):\n",
    "        return False\n",
    "    for i in range(len(ps0.shells)):\n",
    "        if ps0.node_list[-i-1].name != ps1.node_list[-i-1].name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "'''\n",
    "meta-test an agent, directly run into testing / online adaptation\n",
    "'''\n",
    "def MetaTest(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer):\n",
    "    print(\"# Start Meta-Test...\")\n",
    "    \n",
    "    nth_attempt = 0 # tell whether to back-prop or not\n",
    "    batch_lossA_list = []\n",
    "    batch_lossD_list = []\n",
    "    \n",
    "    n_solved = 0 # track the number of solved problem\n",
    "    n_sketch_solved = 0\n",
    "    n_attempt_list = [] # track the number of attempts in every episode\n",
    "    \n",
    "    selected_neurons = []\n",
    "    dead_neurons = [] # DeepPath: store node with execution error\n",
    "    \n",
    "    for d_episode in range(p_config[\"meta_test\"][\"n_episode\"]):\n",
    "        \n",
    "        # retrieve the given meta-trained model for testing\n",
    "        test_model = copy.deepcopy(p_model)\n",
    "        test_model.train()\n",
    "        test_optim = torch.optim.Adam(list(test_model.parameters()))\n",
    "        print(list(test_model.parameters()))\n",
    "        \n",
    "        # if doing random meta-testing\n",
    "        # then randomly generate a program for testing\n",
    "        ps_solution = p_generator.get_new_chain_program(\n",
    "            p_config[\"meta_test\"][\"fixed_depth\"],\n",
    "        )\n",
    "        \n",
    "        f = open(\"./outputs/Alice2/Problem_{}.txt\".format(d_episode), \"w\")\n",
    "        f.write(\"# Problem: {}\\n\\n\".format(str(ps_solution.node_list[-1])))\n",
    "        f.write(\"# Input:\\n{}\\n\".format(p_interpreter.renv(ps_solution.inputs[0])))\n",
    "        f.write(\"# Output:\\n{}\\n\".format(p_interpreter.renv(ps_solution.output)))\n",
    "        f.flush()\n",
    "        \n",
    "        is_solved = False\n",
    "        is_sketch_solved = False\n",
    "        \n",
    "        for d_attempt in range(p_config[\"meta_test\"][\"maxn_attempt\"]):\n",
    "            if is_solved:\n",
    "                # already solved in the last attempt, stop\n",
    "                break\n",
    "            \n",
    "            nth_attempt += 1\n",
    "            attempt_reward = None\n",
    "            \n",
    "            # in every new attempt, initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, ps_solution.inputs, ps_solution.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "                \n",
    "            d_step = 0\n",
    "            while d_step<p_config[\"meta_test\"][\"maxn_step\"]:\n",
    "                \n",
    "                # print the training progress\n",
    "                print(\"\\r# AC/SK/EP:{}/{}/{}, AT:{}, SP:{}, DN:{}, avg.attempt:{:.2f}, er:{:.2f}\".format(\n",
    "                    n_solved, n_sketch_solved, d_episode, d_attempt, d_step, \n",
    "                    len(dead_neurons),\n",
    "                    sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else -1,\n",
    "                    p_config[\"meta_test\"][\"exploration_rate\"](d_episode,d_attempt),\n",
    "                ),end=\"\")\n",
    "                \n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                id_current = ps_current.get_strict_frontiers()[0]\n",
    "                var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "                var_output = ps_current.output\n",
    "                \n",
    "                map_current = p_interpreter.camb_get_simp_abs(var_current)\n",
    "                map_output = p_interpreter.camb_get_simp_abs(var_output)\n",
    "                \n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                \n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float)).cuda()\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float)).cuda()\n",
    "                else:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float))\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float))\n",
    "                    \n",
    "                # (B=1, fn_vocab_size)\n",
    "                td_pred = test_model(td_current, td_output)\n",
    "                \n",
    "                # no hints\n",
    "                if random.random()<=p_config[\"meta_test\"][\"exploration_rate\"](d_episode,d_attempt):\n",
    "                    # exploration\n",
    "                    tmp_id = random.choice(range(len(current_shell_list)))\n",
    "                else:\n",
    "                    # exploitation\n",
    "                    # tmp_id = torch.multinomial(td_pred.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "                    tmp_id = torch.argmax(td_pred.flatten()).cpu().tolist()\n",
    "                \n",
    "                # update ps_current\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if update_status:\n",
    "                    # record selected neuron\n",
    "                    selected_neurons.append(td_pred[0,tmp_id])\n",
    "                    d_step += 1\n",
    "                    \n",
    "                    # succeed\n",
    "                    if ps_current.check_eq() is not None:\n",
    "                        # and solved!\n",
    "                        is_solved = True\n",
    "                        n_solved += 1\n",
    "                        attempt_reward = 1.0\n",
    "                        break\n",
    "                else:\n",
    "                    # DeepPath: fail, add to dead list\n",
    "                    dead_neurons.append(td_pred[0,tmp_id])\n",
    "                    if len(dead_neurons)>p_config[\"meta_test\"][\"dp_cap\"]:\n",
    "                        # exceed the max capacity of dead pool\n",
    "                        break\n",
    "            \n",
    "            # <END_FOR_STEP>\n",
    "            f.write(\"# ({}) Proposed {}/{}: {}\\n\".format(\n",
    "                \"accept\" if is_solved else \"reject\",\n",
    "                d_attempt, p_config[\"meta_test\"][\"maxn_attempt\"],\n",
    "                str(ps_current.node_list[-1])\n",
    "            ))\n",
    "            f.flush()\n",
    "            \n",
    "            if not is_sketch_solved:\n",
    "                if compare_sketch(ps_current, ps_solution):\n",
    "                    is_sketch_solved = True\n",
    "                    n_sketch_solved += 1\n",
    "            \n",
    "            # check the attempt_reward\n",
    "            if attempt_reward is None:\n",
    "                # means either failure in execution or exceeding max_step\n",
    "                attempt_reward = -1.\n",
    "            \n",
    "            # compute the loss (sequential selected)\n",
    "            for i in range(len(selected_neurons)):\n",
    "                d_decay = p_config[\"meta_test\"][\"decay_rate\"]**(len(selected_neurons)-1-i)\n",
    "                batch_lossA_list.append(\n",
    "                    d_decay*attempt_reward*(-selected_neurons[i]) \n",
    "                )\n",
    "            \n",
    "            # compute the loss (dead neurons)\n",
    "            for i in range(len(dead_neurons)):\n",
    "                batch_lossD_list.append(\n",
    "                    (-1.)*(-dead_neurons[i])\n",
    "                )\n",
    "            \n",
    "            if is_solved or nth_attempt>=p_config[\"meta_test\"][\"batch_size\"]:\n",
    "                # directly do the back-prop\n",
    "                if len(batch_lossD_list)>0:\n",
    "                    batch_lossD = sum(batch_lossD_list)/len(batch_lossD_list)\n",
    "                    test_optim.zero_grad()\n",
    "                    batch_lossD.backward()\n",
    "                    test_optim.step()\n",
    "                \n",
    "                if len(batch_lossA_list)>0:\n",
    "                    batch_lossA = sum(batch_lossA_list)/len(batch_lossA_list)\n",
    "                    test_optim.zero_grad()\n",
    "                    batch_lossA.backward()\n",
    "                    test_optim.step()\n",
    "            \n",
    "                nth_attempt = 0\n",
    "                batch_lossA_list = []\n",
    "                batch_lossD_list = []\n",
    "                selected_neurons = []\n",
    "                dead_neurons = []\n",
    "                \n",
    "        # <END_FOR_ATTEMPT>     \n",
    "        \n",
    "        # after all the attempts\n",
    "        n_attempt_list.append(d_attempt)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\n",
    "                'avg.attempt',\n",
    "                sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else 0,\n",
    "                len(n_attempt_list),\n",
    "            )\n",
    "        \n",
    "        f.close()\n",
    "            \n",
    "    # <END_FOR_EPISODE>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Total Meta-Train Data: 77038\n"
     ]
    }
   ],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    ")\n",
    "\n",
    "# dumb variable to help infer the shells\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")\n",
    "\n",
    "m_config = {\n",
    "    \"fn\":{\n",
    "        \"vocab_size\": len(m_ps.get_neighboring_shells())\n",
    "    },\n",
    "    \"embd_dim\": 15*3,\n",
    "    # ==== Meta-Learning Setting ==== #\n",
    "    \"meta_train\":{\n",
    "        \"n_epoch\": 10,\n",
    "        \"batch_size\": 4, # how many indices\n",
    "        \"data_path\": \"./0716MDsize1.pkl\",\n",
    "        \"n_truncated\": 1000,\n",
    "    },\n",
    "    \"meta_test\":{\n",
    "        \"n_episode\": 100000,\n",
    "        \"batch_size\": 1, # how many attempts\n",
    "        \"fixed_depth\": 3,\n",
    "        \"maxn_attempt\": 100,\n",
    "        \"maxn_step\": 2, # program size\n",
    "        \"exploration_rate\": lambda pep,pat:0,\n",
    "        \"decay_rate\": 0.9,\n",
    "        \"dp_cap\": 50,\n",
    "    },\n",
    "}\n",
    "\n",
    "# load the size 1 supervised data\n",
    "with open(m_config[\"meta_train\"][\"data_path\"],\"rb\") as f:\n",
    "    dt_data = pickle.load(f)\n",
    "m_data = [\n",
    "    dt_data[dkey][i]\n",
    "    for dkey in dt_data.keys()\n",
    "    for i in range(len(dt_data[dkey]))\n",
    "]\n",
    "print(\"# Total Meta-Train Data: {}\".format(len(m_data)))\n",
    "\n",
    "trans_neo = TransNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    trans_neo = trans_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(trans_neo.parameters()))\n",
    "\n",
    "# writer = SummaryWriter(\"runs/0713CAMB_RL2_camb3\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fn': {'vocab_size': 120},\n",
       " 'embd_dim': 45,\n",
       " 'meta_train': {'n_epoch': 10,\n",
       "  'batch_size': 4,\n",
       "  'data_path': './0716MDsize1.pkl',\n",
       "  'n_truncated': 1000},\n",
       " 'meta_test': {'n_episode': 100000,\n",
       "  'batch_size': 1,\n",
       "  'fixed_depth': 3,\n",
       "  'maxn_attempt': 100,\n",
       "  'maxn_step': 2,\n",
       "  'exploration_rate': <function __main__.<lambda>(pep, pat)>,\n",
       "  'decay_rate': 0.9,\n",
       "  'dp_cap': 50}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MetaTrain(m_config, m_spec, m_interpreter, trans_neo, m_data, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Start Meta-Test...\n",
      "[Parameter containing:\n",
      "tensor([[ 0.0373,  0.0430,  0.0474,  ..., -0.1049,  0.1082,  0.0821],\n",
      "        [ 0.0052,  0.0099, -0.0649,  ...,  0.0613, -0.0507, -0.1411],\n",
      "        [ 0.0510, -0.0393,  0.0929,  ...,  0.0209,  0.0421,  0.0512],\n",
      "        ...,\n",
      "        [-0.1326,  0.1164, -0.0486,  ...,  0.1355,  0.0914, -0.0206],\n",
      "        [-0.1402, -0.1452, -0.0171,  ...,  0.0588, -0.0224, -0.0735],\n",
      "        [-0.0564,  0.0497,  0.1021,  ..., -0.0813, -0.0485,  0.0630]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0654, -0.0134,  0.0512,  0.1143, -0.1468, -0.1001,  0.1171, -0.0306,\n",
      "         0.0643,  0.0185, -0.0334, -0.0764,  0.0216,  0.0679, -0.0304, -0.0325,\n",
      "         0.0484, -0.0579, -0.1307,  0.1350, -0.0528, -0.0253,  0.0721, -0.1435,\n",
      "        -0.0375, -0.0046, -0.0409, -0.1334,  0.1323,  0.1440,  0.0038, -0.0047,\n",
      "         0.1283, -0.1271,  0.0947, -0.0917, -0.0039,  0.0954, -0.1022, -0.1358,\n",
      "         0.1148,  0.0016,  0.0096,  0.0730,  0.0168, -0.1195, -0.1370,  0.0840,\n",
      "        -0.1290, -0.0377,  0.0610, -0.0238,  0.1138,  0.1058, -0.0901,  0.0789,\n",
      "        -0.0531,  0.1030,  0.0602, -0.0440, -0.1448,  0.0829, -0.0827,  0.0069,\n",
      "         0.1469,  0.0338,  0.0856, -0.0779,  0.0098,  0.1046,  0.0630,  0.0169,\n",
      "         0.0786,  0.0598,  0.1230, -0.1351, -0.0891,  0.0318, -0.0359,  0.0196,\n",
      "         0.1089,  0.1471, -0.0889,  0.0688, -0.0625, -0.0548,  0.1001, -0.0273,\n",
      "        -0.0067, -0.0758, -0.0015,  0.0166, -0.0524, -0.0575,  0.0043,  0.0886,\n",
      "         0.0247, -0.0335,  0.0151, -0.0090,  0.1437,  0.1390,  0.0347, -0.1070,\n",
      "        -0.0798, -0.0096, -0.1180, -0.1413,  0.0251, -0.1362, -0.0760,  0.1025,\n",
      "        -0.1381,  0.0864,  0.0635,  0.0878,  0.0626, -0.1153, -0.0198,  0.0804,\n",
      "        -0.0468,  0.0325, -0.1319,  0.1249, -0.1295, -0.0103,  0.0061,  0.0614],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0077,  0.0602,  0.0795,  ...,  0.0379,  0.0181, -0.0823],\n",
      "        [-0.0528, -0.0078,  0.0333,  ...,  0.0181,  0.0353, -0.0075],\n",
      "        [-0.0730, -0.0251, -0.0633,  ...,  0.0659,  0.0312,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0821, -0.0714, -0.0559,  ..., -0.0626,  0.0041,  0.0351],\n",
      "        [-0.0520,  0.0681, -0.0202,  ...,  0.0425,  0.0305, -0.0474],\n",
      "        [ 0.0313, -0.0025, -0.0397,  ..., -0.0209, -0.0238, -0.0549]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0746,  0.0280, -0.0607,  0.0184,  0.0406, -0.0238, -0.0726,  0.0035,\n",
      "         0.0025, -0.0832, -0.0374,  0.0401,  0.0361,  0.0096, -0.0173,  0.0725,\n",
      "        -0.0549, -0.0397, -0.0280,  0.0632,  0.0402, -0.0138, -0.0857, -0.0164,\n",
      "        -0.0214,  0.0034,  0.0414,  0.0820,  0.0776,  0.0695, -0.0820,  0.0062,\n",
      "        -0.0492, -0.0349, -0.0208, -0.0104,  0.0237,  0.0293,  0.0767,  0.0357,\n",
      "         0.0472, -0.0373, -0.0731, -0.0737,  0.0809, -0.0588, -0.0278,  0.0728,\n",
      "        -0.0842,  0.0260, -0.0042, -0.0217, -0.0144, -0.0531, -0.0355, -0.0443,\n",
      "         0.0266,  0.0400, -0.0378,  0.0481, -0.0590,  0.0566, -0.0447, -0.0601,\n",
      "         0.0795, -0.0049, -0.0396,  0.0393, -0.0325, -0.0604, -0.0728, -0.0007,\n",
      "        -0.0655, -0.0557, -0.0037,  0.0504, -0.0195,  0.0547,  0.0681,  0.0486,\n",
      "         0.0760, -0.0616, -0.0422, -0.0827,  0.0516,  0.0856,  0.0713,  0.0030,\n",
      "         0.0534,  0.0561, -0.0761, -0.0062,  0.0105, -0.0557,  0.0381, -0.0169,\n",
      "        -0.0881,  0.0148, -0.0198,  0.0100,  0.0106, -0.0105, -0.0644,  0.0033,\n",
      "        -0.0772, -0.0722, -0.0774, -0.0295, -0.0149, -0.0850, -0.0459, -0.0648,\n",
      "        -0.0837, -0.0382,  0.0835,  0.0506, -0.0181,  0.0546, -0.0854,  0.0257],\n",
      "       device='cuda:0', requires_grad=True)]\n",
      "# AC/SK/EP:0/1/0, AT:99, SP:0, DN:50, avg.attempt:-1.00, er:0.00[Parameter containing:\n",
      "tensor([[ 0.0373,  0.0430,  0.0474,  ..., -0.1049,  0.1082,  0.0821],\n",
      "        [ 0.0052,  0.0099, -0.0649,  ...,  0.0613, -0.0507, -0.1411],\n",
      "        [ 0.0510, -0.0393,  0.0929,  ...,  0.0209,  0.0421,  0.0512],\n",
      "        ...,\n",
      "        [-0.1326,  0.1164, -0.0486,  ...,  0.1355,  0.0914, -0.0206],\n",
      "        [-0.1402, -0.1452, -0.0171,  ...,  0.0588, -0.0224, -0.0735],\n",
      "        [-0.0564,  0.0497,  0.1021,  ..., -0.0813, -0.0485,  0.0630]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0654, -0.0134,  0.0512,  0.1143, -0.1468, -0.1001,  0.1171, -0.0306,\n",
      "         0.0643,  0.0185, -0.0334, -0.0764,  0.0216,  0.0679, -0.0304, -0.0325,\n",
      "         0.0484, -0.0579, -0.1307,  0.1350, -0.0528, -0.0253,  0.0721, -0.1435,\n",
      "        -0.0375, -0.0046, -0.0409, -0.1334,  0.1323,  0.1440,  0.0038, -0.0047,\n",
      "         0.1283, -0.1271,  0.0947, -0.0917, -0.0039,  0.0954, -0.1022, -0.1358,\n",
      "         0.1148,  0.0016,  0.0096,  0.0730,  0.0168, -0.1195, -0.1370,  0.0840,\n",
      "        -0.1290, -0.0377,  0.0610, -0.0238,  0.1138,  0.1058, -0.0901,  0.0789,\n",
      "        -0.0531,  0.1030,  0.0602, -0.0440, -0.1448,  0.0829, -0.0827,  0.0069,\n",
      "         0.1469,  0.0338,  0.0856, -0.0779,  0.0098,  0.1046,  0.0630,  0.0169,\n",
      "         0.0786,  0.0598,  0.1230, -0.1351, -0.0891,  0.0318, -0.0359,  0.0196,\n",
      "         0.1089,  0.1471, -0.0889,  0.0688, -0.0625, -0.0548,  0.1001, -0.0273,\n",
      "        -0.0067, -0.0758, -0.0015,  0.0166, -0.0524, -0.0575,  0.0043,  0.0886,\n",
      "         0.0247, -0.0335,  0.0151, -0.0090,  0.1437,  0.1390,  0.0347, -0.1070,\n",
      "        -0.0798, -0.0096, -0.1180, -0.1413,  0.0251, -0.1362, -0.0760,  0.1025,\n",
      "        -0.1381,  0.0864,  0.0635,  0.0878,  0.0626, -0.1153, -0.0198,  0.0804,\n",
      "        -0.0468,  0.0325, -0.1319,  0.1249, -0.1295, -0.0103,  0.0061,  0.0614],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0077,  0.0602,  0.0795,  ...,  0.0379,  0.0181, -0.0823],\n",
      "        [-0.0528, -0.0078,  0.0333,  ...,  0.0181,  0.0353, -0.0075],\n",
      "        [-0.0730, -0.0251, -0.0633,  ...,  0.0659,  0.0312,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0821, -0.0714, -0.0559,  ..., -0.0626,  0.0041,  0.0351],\n",
      "        [-0.0520,  0.0681, -0.0202,  ...,  0.0425,  0.0305, -0.0474],\n",
      "        [ 0.0313, -0.0025, -0.0397,  ..., -0.0209, -0.0238, -0.0549]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0746,  0.0280, -0.0607,  0.0184,  0.0406, -0.0238, -0.0726,  0.0035,\n",
      "         0.0025, -0.0832, -0.0374,  0.0401,  0.0361,  0.0096, -0.0173,  0.0725,\n",
      "        -0.0549, -0.0397, -0.0280,  0.0632,  0.0402, -0.0138, -0.0857, -0.0164,\n",
      "        -0.0214,  0.0034,  0.0414,  0.0820,  0.0776,  0.0695, -0.0820,  0.0062,\n",
      "        -0.0492, -0.0349, -0.0208, -0.0104,  0.0237,  0.0293,  0.0767,  0.0357,\n",
      "         0.0472, -0.0373, -0.0731, -0.0737,  0.0809, -0.0588, -0.0278,  0.0728,\n",
      "        -0.0842,  0.0260, -0.0042, -0.0217, -0.0144, -0.0531, -0.0355, -0.0443,\n",
      "         0.0266,  0.0400, -0.0378,  0.0481, -0.0590,  0.0566, -0.0447, -0.0601,\n",
      "         0.0795, -0.0049, -0.0396,  0.0393, -0.0325, -0.0604, -0.0728, -0.0007,\n",
      "        -0.0655, -0.0557, -0.0037,  0.0504, -0.0195,  0.0547,  0.0681,  0.0486,\n",
      "         0.0760, -0.0616, -0.0422, -0.0827,  0.0516,  0.0856,  0.0713,  0.0030,\n",
      "         0.0534,  0.0561, -0.0761, -0.0062,  0.0105, -0.0557,  0.0381, -0.0169,\n",
      "        -0.0881,  0.0148, -0.0198,  0.0100,  0.0106, -0.0105, -0.0644,  0.0033,\n",
      "        -0.0772, -0.0722, -0.0774, -0.0295, -0.0149, -0.0850, -0.0459, -0.0648,\n",
      "        -0.0837, -0.0382,  0.0835,  0.0506, -0.0181,  0.0546, -0.0854,  0.0257],\n",
      "       device='cuda:0', requires_grad=True)]\n",
      "# AC/SK/EP:0/2/1, AT:99, SP:1, DN:50, avg.attempt:99.00, er:0.00[Parameter containing:\n",
      "tensor([[ 0.0373,  0.0430,  0.0474,  ..., -0.1049,  0.1082,  0.0821],\n",
      "        [ 0.0052,  0.0099, -0.0649,  ...,  0.0613, -0.0507, -0.1411],\n",
      "        [ 0.0510, -0.0393,  0.0929,  ...,  0.0209,  0.0421,  0.0512],\n",
      "        ...,\n",
      "        [-0.1326,  0.1164, -0.0486,  ...,  0.1355,  0.0914, -0.0206],\n",
      "        [-0.1402, -0.1452, -0.0171,  ...,  0.0588, -0.0224, -0.0735],\n",
      "        [-0.0564,  0.0497,  0.1021,  ..., -0.0813, -0.0485,  0.0630]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0654, -0.0134,  0.0512,  0.1143, -0.1468, -0.1001,  0.1171, -0.0306,\n",
      "         0.0643,  0.0185, -0.0334, -0.0764,  0.0216,  0.0679, -0.0304, -0.0325,\n",
      "         0.0484, -0.0579, -0.1307,  0.1350, -0.0528, -0.0253,  0.0721, -0.1435,\n",
      "        -0.0375, -0.0046, -0.0409, -0.1334,  0.1323,  0.1440,  0.0038, -0.0047,\n",
      "         0.1283, -0.1271,  0.0947, -0.0917, -0.0039,  0.0954, -0.1022, -0.1358,\n",
      "         0.1148,  0.0016,  0.0096,  0.0730,  0.0168, -0.1195, -0.1370,  0.0840,\n",
      "        -0.1290, -0.0377,  0.0610, -0.0238,  0.1138,  0.1058, -0.0901,  0.0789,\n",
      "        -0.0531,  0.1030,  0.0602, -0.0440, -0.1448,  0.0829, -0.0827,  0.0069,\n",
      "         0.1469,  0.0338,  0.0856, -0.0779,  0.0098,  0.1046,  0.0630,  0.0169,\n",
      "         0.0786,  0.0598,  0.1230, -0.1351, -0.0891,  0.0318, -0.0359,  0.0196,\n",
      "         0.1089,  0.1471, -0.0889,  0.0688, -0.0625, -0.0548,  0.1001, -0.0273,\n",
      "        -0.0067, -0.0758, -0.0015,  0.0166, -0.0524, -0.0575,  0.0043,  0.0886,\n",
      "         0.0247, -0.0335,  0.0151, -0.0090,  0.1437,  0.1390,  0.0347, -0.1070,\n",
      "        -0.0798, -0.0096, -0.1180, -0.1413,  0.0251, -0.1362, -0.0760,  0.1025,\n",
      "        -0.1381,  0.0864,  0.0635,  0.0878,  0.0626, -0.1153, -0.0198,  0.0804,\n",
      "        -0.0468,  0.0325, -0.1319,  0.1249, -0.1295, -0.0103,  0.0061,  0.0614],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0077,  0.0602,  0.0795,  ...,  0.0379,  0.0181, -0.0823],\n",
      "        [-0.0528, -0.0078,  0.0333,  ...,  0.0181,  0.0353, -0.0075],\n",
      "        [-0.0730, -0.0251, -0.0633,  ...,  0.0659,  0.0312,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0821, -0.0714, -0.0559,  ..., -0.0626,  0.0041,  0.0351],\n",
      "        [-0.0520,  0.0681, -0.0202,  ...,  0.0425,  0.0305, -0.0474],\n",
      "        [ 0.0313, -0.0025, -0.0397,  ..., -0.0209, -0.0238, -0.0549]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0746,  0.0280, -0.0607,  0.0184,  0.0406, -0.0238, -0.0726,  0.0035,\n",
      "         0.0025, -0.0832, -0.0374,  0.0401,  0.0361,  0.0096, -0.0173,  0.0725,\n",
      "        -0.0549, -0.0397, -0.0280,  0.0632,  0.0402, -0.0138, -0.0857, -0.0164,\n",
      "        -0.0214,  0.0034,  0.0414,  0.0820,  0.0776,  0.0695, -0.0820,  0.0062,\n",
      "        -0.0492, -0.0349, -0.0208, -0.0104,  0.0237,  0.0293,  0.0767,  0.0357,\n",
      "         0.0472, -0.0373, -0.0731, -0.0737,  0.0809, -0.0588, -0.0278,  0.0728,\n",
      "        -0.0842,  0.0260, -0.0042, -0.0217, -0.0144, -0.0531, -0.0355, -0.0443,\n",
      "         0.0266,  0.0400, -0.0378,  0.0481, -0.0590,  0.0566, -0.0447, -0.0601,\n",
      "         0.0795, -0.0049, -0.0396,  0.0393, -0.0325, -0.0604, -0.0728, -0.0007,\n",
      "        -0.0655, -0.0557, -0.0037,  0.0504, -0.0195,  0.0547,  0.0681,  0.0486,\n",
      "         0.0760, -0.0616, -0.0422, -0.0827,  0.0516,  0.0856,  0.0713,  0.0030,\n",
      "         0.0534,  0.0561, -0.0761, -0.0062,  0.0105, -0.0557,  0.0381, -0.0169,\n",
      "        -0.0881,  0.0148, -0.0198,  0.0100,  0.0106, -0.0105, -0.0644,  0.0033,\n",
      "        -0.0772, -0.0722, -0.0774, -0.0295, -0.0149, -0.0850, -0.0459, -0.0648,\n",
      "        -0.0837, -0.0382,  0.0835,  0.0506, -0.0181,  0.0546, -0.0854,  0.0257],\n",
      "       device='cuda:0', requires_grad=True)]\n",
      "# AC/SK/EP:0/2/2, AT:99, SP:1, DN:0, avg.attempt:99.00, er:0.00[Parameter containing:\n",
      "tensor([[ 0.0373,  0.0430,  0.0474,  ..., -0.1049,  0.1082,  0.0821],\n",
      "        [ 0.0052,  0.0099, -0.0649,  ...,  0.0613, -0.0507, -0.1411],\n",
      "        [ 0.0510, -0.0393,  0.0929,  ...,  0.0209,  0.0421,  0.0512],\n",
      "        ...,\n",
      "        [-0.1326,  0.1164, -0.0486,  ...,  0.1355,  0.0914, -0.0206],\n",
      "        [-0.1402, -0.1452, -0.0171,  ...,  0.0588, -0.0224, -0.0735],\n",
      "        [-0.0564,  0.0497,  0.1021,  ..., -0.0813, -0.0485,  0.0630]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0654, -0.0134,  0.0512,  0.1143, -0.1468, -0.1001,  0.1171, -0.0306,\n",
      "         0.0643,  0.0185, -0.0334, -0.0764,  0.0216,  0.0679, -0.0304, -0.0325,\n",
      "         0.0484, -0.0579, -0.1307,  0.1350, -0.0528, -0.0253,  0.0721, -0.1435,\n",
      "        -0.0375, -0.0046, -0.0409, -0.1334,  0.1323,  0.1440,  0.0038, -0.0047,\n",
      "         0.1283, -0.1271,  0.0947, -0.0917, -0.0039,  0.0954, -0.1022, -0.1358,\n",
      "         0.1148,  0.0016,  0.0096,  0.0730,  0.0168, -0.1195, -0.1370,  0.0840,\n",
      "        -0.1290, -0.0377,  0.0610, -0.0238,  0.1138,  0.1058, -0.0901,  0.0789,\n",
      "        -0.0531,  0.1030,  0.0602, -0.0440, -0.1448,  0.0829, -0.0827,  0.0069,\n",
      "         0.1469,  0.0338,  0.0856, -0.0779,  0.0098,  0.1046,  0.0630,  0.0169,\n",
      "         0.0786,  0.0598,  0.1230, -0.1351, -0.0891,  0.0318, -0.0359,  0.0196,\n",
      "         0.1089,  0.1471, -0.0889,  0.0688, -0.0625, -0.0548,  0.1001, -0.0273,\n",
      "        -0.0067, -0.0758, -0.0015,  0.0166, -0.0524, -0.0575,  0.0043,  0.0886,\n",
      "         0.0247, -0.0335,  0.0151, -0.0090,  0.1437,  0.1390,  0.0347, -0.1070,\n",
      "        -0.0798, -0.0096, -0.1180, -0.1413,  0.0251, -0.1362, -0.0760,  0.1025,\n",
      "        -0.1381,  0.0864,  0.0635,  0.0878,  0.0626, -0.1153, -0.0198,  0.0804,\n",
      "        -0.0468,  0.0325, -0.1319,  0.1249, -0.1295, -0.0103,  0.0061,  0.0614],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0077,  0.0602,  0.0795,  ...,  0.0379,  0.0181, -0.0823],\n",
      "        [-0.0528, -0.0078,  0.0333,  ...,  0.0181,  0.0353, -0.0075],\n",
      "        [-0.0730, -0.0251, -0.0633,  ...,  0.0659,  0.0312,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0821, -0.0714, -0.0559,  ..., -0.0626,  0.0041,  0.0351],\n",
      "        [-0.0520,  0.0681, -0.0202,  ...,  0.0425,  0.0305, -0.0474],\n",
      "        [ 0.0313, -0.0025, -0.0397,  ..., -0.0209, -0.0238, -0.0549]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0746,  0.0280, -0.0607,  0.0184,  0.0406, -0.0238, -0.0726,  0.0035,\n",
      "         0.0025, -0.0832, -0.0374,  0.0401,  0.0361,  0.0096, -0.0173,  0.0725,\n",
      "        -0.0549, -0.0397, -0.0280,  0.0632,  0.0402, -0.0138, -0.0857, -0.0164,\n",
      "        -0.0214,  0.0034,  0.0414,  0.0820,  0.0776,  0.0695, -0.0820,  0.0062,\n",
      "        -0.0492, -0.0349, -0.0208, -0.0104,  0.0237,  0.0293,  0.0767,  0.0357,\n",
      "         0.0472, -0.0373, -0.0731, -0.0737,  0.0809, -0.0588, -0.0278,  0.0728,\n",
      "        -0.0842,  0.0260, -0.0042, -0.0217, -0.0144, -0.0531, -0.0355, -0.0443,\n",
      "         0.0266,  0.0400, -0.0378,  0.0481, -0.0590,  0.0566, -0.0447, -0.0601,\n",
      "         0.0795, -0.0049, -0.0396,  0.0393, -0.0325, -0.0604, -0.0728, -0.0007,\n",
      "        -0.0655, -0.0557, -0.0037,  0.0504, -0.0195,  0.0547,  0.0681,  0.0486,\n",
      "         0.0760, -0.0616, -0.0422, -0.0827,  0.0516,  0.0856,  0.0713,  0.0030,\n",
      "         0.0534,  0.0561, -0.0761, -0.0062,  0.0105, -0.0557,  0.0381, -0.0169,\n",
      "        -0.0881,  0.0148, -0.0198,  0.0100,  0.0106, -0.0105, -0.0644,  0.0033,\n",
      "        -0.0772, -0.0722, -0.0774, -0.0295, -0.0149, -0.0850, -0.0459, -0.0648,\n",
      "        -0.0837, -0.0382,  0.0835,  0.0506, -0.0181,  0.0546, -0.0854,  0.0257],\n",
      "       device='cuda:0', requires_grad=True)]\n",
      "# AC/SK/EP:0/3/3, AT:99, SP:1, DN:50, avg.attempt:99.00, er:0.00[Parameter containing:\n",
      "tensor([[ 0.0373,  0.0430,  0.0474,  ..., -0.1049,  0.1082,  0.0821],\n",
      "        [ 0.0052,  0.0099, -0.0649,  ...,  0.0613, -0.0507, -0.1411],\n",
      "        [ 0.0510, -0.0393,  0.0929,  ...,  0.0209,  0.0421,  0.0512],\n",
      "        ...,\n",
      "        [-0.1326,  0.1164, -0.0486,  ...,  0.1355,  0.0914, -0.0206],\n",
      "        [-0.1402, -0.1452, -0.0171,  ...,  0.0588, -0.0224, -0.0735],\n",
      "        [-0.0564,  0.0497,  0.1021,  ..., -0.0813, -0.0485,  0.0630]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0654, -0.0134,  0.0512,  0.1143, -0.1468, -0.1001,  0.1171, -0.0306,\n",
      "         0.0643,  0.0185, -0.0334, -0.0764,  0.0216,  0.0679, -0.0304, -0.0325,\n",
      "         0.0484, -0.0579, -0.1307,  0.1350, -0.0528, -0.0253,  0.0721, -0.1435,\n",
      "        -0.0375, -0.0046, -0.0409, -0.1334,  0.1323,  0.1440,  0.0038, -0.0047,\n",
      "         0.1283, -0.1271,  0.0947, -0.0917, -0.0039,  0.0954, -0.1022, -0.1358,\n",
      "         0.1148,  0.0016,  0.0096,  0.0730,  0.0168, -0.1195, -0.1370,  0.0840,\n",
      "        -0.1290, -0.0377,  0.0610, -0.0238,  0.1138,  0.1058, -0.0901,  0.0789,\n",
      "        -0.0531,  0.1030,  0.0602, -0.0440, -0.1448,  0.0829, -0.0827,  0.0069,\n",
      "         0.1469,  0.0338,  0.0856, -0.0779,  0.0098,  0.1046,  0.0630,  0.0169,\n",
      "         0.0786,  0.0598,  0.1230, -0.1351, -0.0891,  0.0318, -0.0359,  0.0196,\n",
      "         0.1089,  0.1471, -0.0889,  0.0688, -0.0625, -0.0548,  0.1001, -0.0273,\n",
      "        -0.0067, -0.0758, -0.0015,  0.0166, -0.0524, -0.0575,  0.0043,  0.0886,\n",
      "         0.0247, -0.0335,  0.0151, -0.0090,  0.1437,  0.1390,  0.0347, -0.1070,\n",
      "        -0.0798, -0.0096, -0.1180, -0.1413,  0.0251, -0.1362, -0.0760,  0.1025,\n",
      "        -0.1381,  0.0864,  0.0635,  0.0878,  0.0626, -0.1153, -0.0198,  0.0804,\n",
      "        -0.0468,  0.0325, -0.1319,  0.1249, -0.1295, -0.0103,  0.0061,  0.0614],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0077,  0.0602,  0.0795,  ...,  0.0379,  0.0181, -0.0823],\n",
      "        [-0.0528, -0.0078,  0.0333,  ...,  0.0181,  0.0353, -0.0075],\n",
      "        [-0.0730, -0.0251, -0.0633,  ...,  0.0659,  0.0312,  0.0323],\n",
      "        ...,\n",
      "        [ 0.0821, -0.0714, -0.0559,  ..., -0.0626,  0.0041,  0.0351],\n",
      "        [-0.0520,  0.0681, -0.0202,  ...,  0.0425,  0.0305, -0.0474],\n",
      "        [ 0.0313, -0.0025, -0.0397,  ..., -0.0209, -0.0238, -0.0549]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0746,  0.0280, -0.0607,  0.0184,  0.0406, -0.0238, -0.0726,  0.0035,\n",
      "         0.0025, -0.0832, -0.0374,  0.0401,  0.0361,  0.0096, -0.0173,  0.0725,\n",
      "        -0.0549, -0.0397, -0.0280,  0.0632,  0.0402, -0.0138, -0.0857, -0.0164,\n",
      "        -0.0214,  0.0034,  0.0414,  0.0820,  0.0776,  0.0695, -0.0820,  0.0062,\n",
      "        -0.0492, -0.0349, -0.0208, -0.0104,  0.0237,  0.0293,  0.0767,  0.0357,\n",
      "         0.0472, -0.0373, -0.0731, -0.0737,  0.0809, -0.0588, -0.0278,  0.0728,\n",
      "        -0.0842,  0.0260, -0.0042, -0.0217, -0.0144, -0.0531, -0.0355, -0.0443,\n",
      "         0.0266,  0.0400, -0.0378,  0.0481, -0.0590,  0.0566, -0.0447, -0.0601,\n",
      "         0.0795, -0.0049, -0.0396,  0.0393, -0.0325, -0.0604, -0.0728, -0.0007,\n",
      "        -0.0655, -0.0557, -0.0037,  0.0504, -0.0195,  0.0547,  0.0681,  0.0486,\n",
      "         0.0760, -0.0616, -0.0422, -0.0827,  0.0516,  0.0856,  0.0713,  0.0030,\n",
      "         0.0534,  0.0561, -0.0761, -0.0062,  0.0105, -0.0557,  0.0381, -0.0169,\n",
      "        -0.0881,  0.0148, -0.0198,  0.0100,  0.0106, -0.0105, -0.0644,  0.0033,\n",
      "        -0.0772, -0.0722, -0.0774, -0.0295, -0.0149, -0.0850, -0.0459, -0.0648,\n",
      "        -0.0837, -0.0382,  0.0835,  0.0506, -0.0181,  0.0546, -0.0854,  0.0257],\n",
      "       device='cuda:0', requires_grad=True)]\n",
      "# AC/SK/EP:0/3/4, AT:6, SP:1, DN:32, avg.attempt:99.00, er:0.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cdc6b9d424ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMetaTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_interpreter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_neo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-c6aae36b791a>\u001b[0m in \u001b[0;36mMetaTest\u001b[0;34m(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mvar_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps_current\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mmap_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamb_get_simp_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_current\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mmap_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamb_get_simp_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/MorpheusInterpreter.py\u001b[0m in \u001b[0;36mcamb_get_simp_abs\u001b[0;34m(self, p_obj, verbose)\u001b[0m\n\u001b[1;32m    838\u001b[0m     '''\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcamb_get_simp_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0mnp_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamb_get_np_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0mone_hot_nrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCAMB_NROW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Trinity/MorpheusInterpreter.py\u001b[0m in \u001b[0;36mcamb_get_np_obj\u001b[0;34m(self, p_obj)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;31m# \"data frame with 0 columns and 10 rows\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0mdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrow({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m             \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ncol({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0mnp_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStrSexpVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_ae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_globalenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__rname__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__rname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    822\u001b[0m                             '1 positional argument')\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m_rpy2py_sexpclosure\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdefault_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSexpClosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_rpy2py_sexpclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignatureTranslatedFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sexp, init_prm_translate, on_conflict, symbol_r2python, symbol_check_after)\u001b[0m\n\u001b[1;32m    161\u001b[0m              \u001b[0mconflicts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m              \u001b[0mresolutions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_symbols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                  \u001b[0mformals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                  \u001b[0mtranslation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprm_translate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                  \u001b[0msymbol_r2python\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msymbol_r2python\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/sexp.py\u001b[0m in \u001b[0;36mnames\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Sexp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# TODO: force finding function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobalenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'names'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/conversion.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cdata_res_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# TODO: test cdata is of the expected CType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cdata_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m             call_r = rmemory.protect(\n\u001b[1;32m    765\u001b[0m                 _rinterface.build_rcall(self.__sexp__._cdata, args,\n\u001b[0;32m--> 766\u001b[0;31m                                         kwargs.items()))\n\u001b[0m\u001b[1;32m    767\u001b[0m             res = rmemory.protect(\n\u001b[1;32m    768\u001b[0m                 openrlib.rlib.R_tryEval(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/memorymanagement.py\u001b[0m in \u001b[0;36mprotect\u001b[0;34m(self, cdata)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \"\"\"Pass-through function that adds the R object to the short-term\n\u001b[1;32m     26\u001b[0m         stack of objects protected from garbase collection.\"\"\"\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenrlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRf_protect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MetaTest(m_config, m_spec, m_interpreter, m_generator, trans_neo, optimizer, writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
