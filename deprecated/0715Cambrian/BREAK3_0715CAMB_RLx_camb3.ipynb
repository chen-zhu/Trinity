{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransNeo\n",
    "- AlphaNeo using pre-trained TransE embeddings\n",
    "- Stage: Cambrian\n",
    "- Version: Charniodiscus\n",
    "- **0713: with DeepPath style rollback at training**\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.interpreter import Interpreter, PostOrderInterpreter, GeneralError, InterpreterError\n",
    "from tyrell.enumerator import Enumerator, SmtEnumerator, RandomEnumerator, DesignatedEnumerator, RandomEnumeratorS, ExhaustiveEnumerator\n",
    "from tyrell.decider import Example, ExampleConstraintPruningDecider, ExampleDecider, TestDecider\n",
    "from tyrell.synthesizer import Synthesizer\n",
    "from tyrell.logger import get_logger\n",
    "from sexpdata import Symbol\n",
    "from tyrell import dsl as D\n",
    "from typing import Callable, NamedTuple, List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morpheus Version\n",
    "from utils_morpheus import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBG_PS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueEncoder(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(ValueEncoder, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.vocab_size = self.config[\"val\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"val\"][\"embd_dim\"]\n",
    "        self.embedding = nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embd_dim,\n",
    "            self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels = self.config[\"val\"][\"embd_dim\"],\n",
    "            out_channels = self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            kernel_size = self.config[\"val\"][\"conv_kernel_size\"],\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = self.config[\"val\"][\"pool_kernel_size\"],\n",
    "            padding = self.config[\"val\"][\"IDX_PAD\"],\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            self.config[\"val\"][\"conv_n_kernels\"],\n",
    "            self.config[\"embd_dim\"],\n",
    "        )\n",
    "        \n",
    "    def forward(self, bp_map):\n",
    "        # batched maps, (B, map_r, map_c)\n",
    "        # in this version, every value only contains 1 map\n",
    "        B = bp_map.shape[0]\n",
    "        \n",
    "        # (B, map_r, map_c, val_embd_dim) -> (B, val_embd_dim, map_r, map_c)\n",
    "        d_embd = self.embedding(bp_map).permute(0,3,1,2)\n",
    "        \n",
    "        # (B, n_kernel, map_r, 1)\n",
    "        d_conv = F.relu(self.conv(d_embd))\n",
    "        \n",
    "        # (B, n_kernel)\n",
    "        d_pool = self.pool(d_conv).view(B,self.config[\"val\"][\"conv_n_kernels\"])\n",
    "        \n",
    "        # (B, embd_dim)\n",
    "        d_out = torch.sigmoid(\n",
    "            self.fc(d_pool)\n",
    "        )\n",
    "        \n",
    "        return d_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorphTransE(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(MorphTransE, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.value_encoder = ValueEncoder(p_config=p_config)\n",
    "        \n",
    "        self.fn_vocab_size = self.config[\"fn\"][\"vocab_size\"]\n",
    "        self.embd_dim = self.config[\"embd_dim\"]\n",
    "        \n",
    "        self.fn_embedding = nn.Embedding(\n",
    "            self.fn_vocab_size,\n",
    "            self.embd_dim,\n",
    "        )\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fn_embedding.weight.data)\n",
    "        self.fn_embedding.weight.data = F.normalize(\n",
    "            self.fn_embedding.weight.data, p=2, dim=1,\n",
    "        )\n",
    "# ----> skip the forward part since we don't need it <---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(TransNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        # predict a fixed number of shells\n",
    "#         self.policy = nn.Linear(\n",
    "#             self.config[\"embd_dim\"],\n",
    "#             self.config[\"fn\"][\"vocab_size\"],\n",
    "#         )\n",
    "        \n",
    "        # deeper\n",
    "        self.policy0 = nn.Linear(\n",
    "            self.config[\"embd_dim\"],\n",
    "            2048,\n",
    "        )\n",
    "        self.policy1 = nn.Linear(\n",
    "            2048,\n",
    "            self.config[\"fn\"][\"vocab_size\"],\n",
    "        )\n",
    "        \n",
    "        self.mte = MorphTransE(p_config=p_config)\n",
    "        # then load the parameters\n",
    "        self.mte.load_state_dict(torch.load(self.config[\"mte_path\"]))\n",
    "        \n",
    "    def forward(self, p_mapin, p_mapout):\n",
    "        # p_mapin/p_mapout: (B, map_r, map_c)\n",
    "        v_in = self.mte.value_encoder(p_mapin).detach() # (B, embd_dim)\n",
    "        v_out= self.mte.value_encoder(p_mapout).detach() # (B, embd_dim)\n",
    "        v_delta = v_out - v_in\n",
    "#         tmp_out = torch.log_softmax(\n",
    "#             self.policy(v_delta),dim=1\n",
    "#         )\n",
    "        tmp_out = torch.log_softmax(\n",
    "            self.policy1(\n",
    "                F.relu(\n",
    "                    self.policy0(\n",
    "                        v_delta\n",
    "                    )\n",
    "                )\n",
    "            ),dim=1\n",
    "        )\n",
    "        \n",
    "        return tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_program(p_config, p_interpreter, p_generator):\n",
    "    # initialize a program first\n",
    "    while True:\n",
    "        p_input = p_interpreter.random_table()\n",
    "        p_prog, p_example = p_generator.generate(\n",
    "            fixed_depth=p_config[\"fixed_depth\"],\n",
    "            example=Example(input=[p_input], output=None),\n",
    "        )\n",
    "        # make sure at least one function call\n",
    "        if p_prog is not None and p_prog.is_apply():\n",
    "            break\n",
    "    return p_prog, p_example\n",
    "\n",
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))\n",
    "\n",
    "def TransNeoTrainer(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer):\n",
    "    global DBG_PS\n",
    "    nth_attempt = 0 # tell whether to back-prop or not\n",
    "    batch_lossA_list = []\n",
    "    batch_lossD_list = []\n",
    "    \n",
    "    n_solved = 0 # track the number of solved problem\n",
    "    n_attempt_list = [] # track the number of attempts in every episode\n",
    "    \n",
    "    selected_neurons = []\n",
    "    dead_neurons = [] # DeepPath: store node with execution error\n",
    "    \n",
    "    # in every episode, generate a new program(maze/ps) to learn\n",
    "#     p_prog, p_example = get_new_program(\n",
    "#         p_config, p_interpreter, p_generator,\n",
    "#     )\n",
    "\n",
    "    saved_model = copy.deepcopy(p_model)\n",
    "    \n",
    "    for d_episode in range(p_config[\"n_episode\"]):\n",
    "        \n",
    "        # ######## SPECIAL ######## #\n",
    "        # 10000 hints, so when d_episode==9999, save fix the saved_model\n",
    "        if d_episode<1000:\n",
    "            saved_model = copy.deepcopy(p_model)\n",
    "        else:\n",
    "            p_model = copy.deepcopy(saved_model)\n",
    "        \n",
    "        p_model.train()\n",
    "        \n",
    "        # in every episode, generate a new program(maze/ps) to learn\n",
    "        p_prog, p_example = get_new_program(\n",
    "            p_config, p_interpreter, p_generator,\n",
    "        )\n",
    "        \n",
    "        ps_solution = ProgramSpace(\n",
    "            p_spec, p_interpreter, p_example.input, p_example.output,\n",
    "        )\n",
    "        ps_solution.init_by_prog(p_prog) # this constructs a solution for this problem\n",
    "#         print(\"\\n#### Episode Program Shells: {}\".format(ps_solution.shells))\n",
    "        DBG_PS = ps_solution\n",
    "        \n",
    "        is_solved = False\n",
    "        \n",
    "        for d_attempt in range(p_config[\"max_attempts\"]):\n",
    "            if is_solved:\n",
    "                # already solved in the last attempt, stop\n",
    "                break\n",
    "            \n",
    "            nth_attempt += 1\n",
    "            attempt_reward = None\n",
    "            \n",
    "            # in every new attempt, initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, p_example.input, p_example.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "                \n",
    "            d_step = 0\n",
    "            # for d_step in range(p_config[\"max_steps\"]):\n",
    "            while d_step<p_config[\"max_steps\"]:\n",
    "                \n",
    "                # print the training progress\n",
    "                print(\"\\r# AC/EP:{}/{}, AT:{}, SP:{}, DN:{}, avg.attempt:{:.2f}, er:{:.2f}\".format(\n",
    "                    n_solved, d_episode, d_attempt, d_step, \n",
    "                    len(dead_neurons),\n",
    "                    sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else -1,\n",
    "                    p_config[\"exploration_rate\"](d_episode,d_attempt),\n",
    "                ),end=\"\")\n",
    "                \n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                # print(\"frontiers:{}\".format(ps_current.get_frontiers()))\n",
    "                # input(\"PAUSE\")\n",
    "                id_current = ps_current.get_frontiers()[0]\n",
    "                var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "                var_output = p_example.output\n",
    "                \n",
    "                map_current = camb_get_abs(var_current)\n",
    "                map_output = camb_get_abs(var_output)\n",
    "                \n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                \n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.long)).cuda()\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.long)).cuda()\n",
    "                else:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.long))\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.long))\n",
    "                    \n",
    "                # (B=1, fn_vocab_size)\n",
    "                # fn_vocab_size\n",
    "                td_pred = p_model(td_current, td_output)\n",
    "                \n",
    "                if random.random()<=p_config[\"hint_rate\"](d_episode):\n",
    "                    # print(\"hint!\")\n",
    "                    # give some hints\n",
    "                    tmp_id = current_shell_list.index(ps_solution.shells[d_step])\n",
    "                else:\n",
    "                    # no hints\n",
    "                    if random.random()<=p_config[\"exploration_rate\"](d_episode,d_attempt):\n",
    "                        # exploration\n",
    "                        tmp_id = random.choice(range(len(current_shell_list)))\n",
    "                    else:\n",
    "                        # exploitation\n",
    "                        tmp_id = torch.multinomial(td_pred.exp().flatten(), 1).cpu().flatten().numpy()[0]\n",
    "                \n",
    "                # print(\"shell to add:{}\".format(current_shell_list[tmp_id]))\n",
    "                # input(\"PAUSE-2\")\n",
    "                \n",
    "                # update ps_current\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if update_status:\n",
    "                    # record selected neuron\n",
    "                    selected_neurons.append(td_pred[0,tmp_id])\n",
    "                    d_step += 1\n",
    "                    \n",
    "                    # succeed\n",
    "                    if ps_current.check_eq() is not None:\n",
    "#                     if str(ps_current.node_list[-1])==str(ps_solution.node_list[-1]):\n",
    "#                         print(\"# adding: {}, succeeded&correct\".format(current_shell_list[tmp_id]))\n",
    "                        # and solved!\n",
    "                        is_solved = True\n",
    "                        n_solved += 1\n",
    "                        attempt_reward = 1.0\n",
    "                        break\n",
    "#                     else: \n",
    "                        # not yet solved, just move to next step\n",
    "#                         print(\"# adding: {}, succeeded&wrong\".format(current_shell_list[tmp_id]))\n",
    "                else:\n",
    "#                     print(\"# adding: {}, failed\".format(current_shell_list[tmp_id]))\n",
    "                    # DeepPath: fail, add to dead list\n",
    "                    dead_neurons.append(td_pred[0,tmp_id])\n",
    "                    # break\n",
    "            \n",
    "            # <END_FOR_STEP>\n",
    "            \n",
    "            # check the attempt_reward\n",
    "            if attempt_reward is None:\n",
    "                # means either failure in execution or exceeding max_step\n",
    "                attempt_reward = -1.\n",
    "            \n",
    "            # compute the loss (sequential selected)\n",
    "            # attempt_loss = 0.\n",
    "            for i in range(len(selected_neurons)):\n",
    "                d_decay = p_config[\"decay_rate\"]**(len(selected_neurons)-1-i)\n",
    "                # attempt_loss += d_decay*attempt_reward*(-selected_neurons[i])    \n",
    "                batch_lossA_list.append(\n",
    "                    d_decay*attempt_reward*(-selected_neurons[i]) \n",
    "                )\n",
    "            # batch_loss += attempt_loss\n",
    "            \n",
    "            # compute the loss (dead neurons)\n",
    "            # dead_loss = 0.\n",
    "            for i in range(len(dead_neurons)):\n",
    "                # dead_loss += (-1.)*(-dead_neurons[i])\n",
    "                batch_lossD_list.append(\n",
    "                    (-1.)*(-dead_neurons[i])\n",
    "                )\n",
    "            # batch_loss += dead_loss\n",
    "            \n",
    "            if is_solved or nth_attempt>=p_config[\"batch_size\"]:\n",
    "                # directly do the back-prop\n",
    "                if len(batch_lossD_list)>0:\n",
    "                    batch_lossD = sum(batch_lossD_list)/len(batch_lossD_list)\n",
    "                    p_optim.zero_grad()\n",
    "                    batch_lossD.backward()\n",
    "                    p_optim.step()\n",
    "            \n",
    "                batch_lossA = sum(batch_lossA_list)/len(batch_lossA_list)\n",
    "                p_optim.zero_grad()\n",
    "                batch_lossA.backward()\n",
    "                p_optim.step()\n",
    "                \n",
    "#                 print(\"\\n##$$## Back-Prop!!! Loss:{}\".format(batch_loss))\n",
    "            \n",
    "                nth_attempt = 0\n",
    "                # batch_loss = 0.\n",
    "                batch_lossA_list = []\n",
    "                batch_lossD_list = []\n",
    "                selected_neurons = []\n",
    "                dead_neurons = []\n",
    "                \n",
    "        # <END_FOR_ATTEMPT>     \n",
    "        \n",
    "        # after all the attempts\n",
    "        n_attempt_list.append(d_attempt)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\n",
    "                'avg.attempt',\n",
    "                sum(n_attempt_list)/len(n_attempt_list) if len(n_attempt_list)>0 else 0,\n",
    "                len(n_attempt_list),\n",
    "            )\n",
    "        \n",
    "#         if d_episode%100==0:\n",
    "#             # save the model\n",
    "#             torch.save(\n",
    "#                 p_model.state_dict(),\n",
    "#                 \"./saved_models/0713CAMB_RL2_camb3_ep{}.pt\".format(d_episode)\n",
    "#             )\n",
    "            \n",
    "    # <END_FOR_EPISODE>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb3.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    "    sfn=m_interpreter.sanity_check,\n",
    ")\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")\n",
    "\n",
    "m_config = {\n",
    "    \"val\":{\n",
    "        \"vocab_size\": len(CAMB_LIST),\n",
    "        \"embd_dim\": 16, # embedding dim of CAMB abstract token\n",
    "        \"conv_n_kernels\": 512,\n",
    "        \"conv_kernel_size\": (1,CAMB_NCOL), \n",
    "        \"pool_kernel_size\": (CAMB_NROW,1), \n",
    "        \"IDX_PAD\": 0,\n",
    "    },\n",
    "    \"fn\":{\n",
    "        \"vocab_size\": len(m_ps.get_neighboring_shells())\n",
    "    },\n",
    "    \"embd_dim\": 128,\n",
    "    \"mte_path\": \"./saved_models/0712CAMB_TransE_camb3_ep{}.pt\".format(150),\n",
    "    \"batch_size\": 1, # number of steps between every back-prop by n_attempt\n",
    "    \"fixed_depth\": 3, # means size of 3\n",
    "    \"n_episode\": 100000000,\n",
    "    \"max_attempts\": 100, # max number of attepmts in every episode\n",
    "    \"max_steps\": 2, # max number of function calls\n",
    "    # \"exploration_rate\": 0.1, # fixed exp rate\n",
    "    # \"exploration_rate\": lambda x:0.9-0.8*(min(1,x/2500)), # from 0.9 to 0.1\n",
    "    # \"exploration_rate\": lambda xep,xat:(0.9-0.8*(min(1,xep/300)))*(1-xat/5), # from 0.9 to 0.1\n",
    "    \"exploration_rate\": lambda xep,xat:0.1,\n",
    "    \"decay_rate\": 0.9,\n",
    "    # \"hint_rate\": lambda x:1 if x<1000 and x%2==0 else 0, # first 100 episodes have hints\n",
    "    \"hint_rate\": lambda x:1 if x<1000 else 0, # first 100 episodes have hints\n",
    "    # \"hint_rate\": lambda x:0,\n",
    "}\n",
    "\n",
    "trans_neo = TransNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    trans_neo = trans_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(trans_neo.parameters()))\n",
    "# writer = SummaryWriter(\"runs/0713CAMB_RL2_camb3\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.0303e-02, -6.5965e-03, -6.5842e-03,  ...,  5.9683e-02,\n",
       "         -5.4392e-03, -5.1002e-03],\n",
       "        [ 4.6349e-03,  8.7917e-03,  1.1091e-02,  ...,  6.3994e-02,\n",
       "          4.7744e-03,  1.6289e-03],\n",
       "        [-1.9186e-03, -3.3905e-04, -3.8896e-03,  ...,  6.8064e-02,\n",
       "         -6.4670e-03, -4.9763e-03],\n",
       "        ...,\n",
       "        [ 1.2340e-05, -5.3839e-04, -5.2963e-06,  ..., -6.5772e-04,\n",
       "         -1.9673e-05,  1.7740e-05],\n",
       "        [ 2.9358e-04,  6.5901e-04,  2.0551e-04,  ...,  1.6284e-03,\n",
       "          1.6959e-04,  2.5717e-04],\n",
       "        [-5.6687e-04, -1.3238e-03, -3.9525e-04,  ..., -3.6496e-03,\n",
       "          1.9869e-04,  2.6587e-03]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_neo.mte.fn_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val': {'vocab_size': 150,\n",
       "  'embd_dim': 16,\n",
       "  'conv_n_kernels': 512,\n",
       "  'conv_kernel_size': (1, 15),\n",
       "  'pool_kernel_size': (15, 1),\n",
       "  'IDX_PAD': 0},\n",
       " 'fn': {'vocab_size': 120},\n",
       " 'embd_dim': 128,\n",
       " 'mte_path': './saved_models/0712CAMB_TransE_camb3_ep150.pt',\n",
       " 'batch_size': 1,\n",
       " 'fixed_depth': 3,\n",
       " 'n_episode': 100000000,\n",
       " 'max_attempts': 100,\n",
       " 'max_steps': 2,\n",
       " 'exploration_rate': <function __main__.<lambda>(xep, xat)>,\n",
       " 'decay_rate': 0.9,\n",
       " 'hint_rate': <function __main__.<lambda>(x)>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AC/EP:1088/1461, AT:88, SP:0, DN:0, avg.attempt:28.52, er:0.10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SexpCapsule.__del__ at 0x7fcd0bd05e18>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\", line 102, in __del__\n",
      "    _release(self._cdata)\n",
      "  File \"/home/ju-ucsb/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\", line 62, in _release\n",
      "    del(_R_PRESERVED[addr])\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AC/EP:1088/1461, AT:89, SP:1, DN:12, avg.attempt:28.52, er:0.10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-629b7a4b982f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTransNeoTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_interpreter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_neo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-0024381bb169>\u001b[0m in \u001b[0;36mTransNeoTrainer\u001b[0;34m(p_config, p_spec, p_interpreter, p_generator, p_model, p_optim, p_writer)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mtd_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmap_current\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                     \u001b[0mtd_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmap_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mtd_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmap_current\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TransNeoTrainer(m_config, m_spec, m_interpreter, m_generator, trans_neo, optimizer, writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
