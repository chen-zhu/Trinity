{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behaviral Law Engine\n",
    "- Stage: Cambrian\n",
    "- Version: Pomoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramDataset(Dataset):\n",
    "    def __init__(self, p_config=None, pn_program=None, p_generator=None, p_sourceps=None):\n",
    "        self.config = p_config\n",
    "        self.n_program = pn_program\n",
    "        self.generator = p_generator\n",
    "        self.source_ps = p_sourceps\n",
    "        \n",
    "        self.shell_list = self.source_ps.get_neighboring_shells()\n",
    "        self.shell_dict = {\n",
    "            self.shell_list[i]:i for i in range(len(self.shell_list))\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_program\n",
    "    \n",
    "    '''\n",
    "    shortened method: only valid for size 1 programs\n",
    "    '''\n",
    "    def __getitem__(self, p_ind):\n",
    "        # d_solution = self.generator.get_new_chain_program(2)\n",
    "        d_solution = None\n",
    "        while d_solution is None:\n",
    "            d_solution = self.generator.get_new_size1_program()\n",
    "        d_shell = d_solution.shells[0]\n",
    "        dind_shell = self.shell_dict[d_shell]\n",
    "        dabs_input = d_solution.interpreter.camb_get_ventogyrus(d_solution.inputs[0])\n",
    "        return (np.array(dind_shell), np.array(dabs_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLE(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(BLE,self).__init__()\n",
    "        self.config = p_config\n",
    "        self.fc1 = nn.Linear(\n",
    "            self.config[\"BLE\"][\"input_size\"],\n",
    "            2048,\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            2048,\n",
    "            self.config[\"BLE\"][\"output_size\"],\n",
    "        )\n",
    "    def forward(self, p_abs):\n",
    "        # p_abs: (B, 15*7+1)\n",
    "        out1 = F.relu(self.fc1(p_abs))\n",
    "        out2 = torch.log_softmax(self.fc2(out1),dim=1)\n",
    "        return out2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLETrain(p_config, p_engine, pld_data, p_optim, p_lossfn):\n",
    "    for d_ep in range(p_config[\"BLE\"][\"n_epoch\"]):\n",
    "        ep_loss_list = []\n",
    "        for batch_idx, (b_ind, b_input) in enumerate(pld_data):\n",
    "            p_engine.train()\n",
    "            if use_cuda:\n",
    "                tb_ind = Variable(b_ind).long().cuda()\n",
    "                tb_input = Variable(b_input).float().cuda()\n",
    "            else:\n",
    "                tb_ind = Variable(b_ind).long()\n",
    "                tb_input = Variable(b_input).float()\n",
    "            \n",
    "            tb_preds = p_engine(tb_input) # (B, output_size)\n",
    "            tb_loss = p_lossfn(tb_preds, tb_ind)\n",
    "            ep_loss_list.append(tb_loss)\n",
    "            p_optim.zero_grad()\n",
    "            tb_loss.backward()\n",
    "            p_optim.step()\n",
    "            \n",
    "            print(\"\\r# Train Ep:{}, B:{}, epLoss:{:.2f}\".format(\n",
    "                d_ep, batch_idx, sum(ep_loss_list)/len(ep_loss_list)\n",
    "            ),end=\"\")\n",
    "        print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLEManualTest(p_engine, p_sourceps):\n",
    "    p_engine.eval()\n",
    "    p_shell_list = p_sourceps.get_neighboring_shells()\n",
    "    output_id = -1\n",
    "    while output_id<150:\n",
    "        output_id += 1\n",
    "        r_table = p_sourceps.interpreter.random_table()\n",
    "#         p_sourceps.interpreter.print_obj(r_table)\n",
    "        r_abs = p_sourceps.interpreter.camb_get_ventogyrus(r_table)\n",
    "        if use_cuda:\n",
    "            tr_abs = Variable(torch.tensor([r_abs],dtype=torch.float)).cuda()\n",
    "        else:\n",
    "            tr_abs = Variable(torch.tensor([r_abs],dtype=torch.float))\n",
    "        tr_preds = p_engine(tr_abs)\n",
    "        r_preds = tr_preds.data.cpu().numpy().flatten()\n",
    "        arg_preds = np.argsort(r_preds)[::-1]\n",
    "        # then visualize them out\n",
    "        f = open(\"./outputs/0811BLE/0811BLE_input_{}.txt\".format(output_id),\"w\")\n",
    "        f.write(str(p_sourceps.interpreter.renv(r_table)))\n",
    "        f.write(\"\\n\")\n",
    "        for i in range(len(arg_preds)):\n",
    "            did_shell = p_shell_list[arg_preds[i]]\n",
    "            d_name = p_sourceps.prod_list[did_shell[0]].name\n",
    "            d_param = []\n",
    "            for pp in did_shell[1]:\n",
    "                d_param.append(str(p_sourceps.node_list[pp]))\n",
    "            d_ps = p_sourceps.make_copy()\n",
    "            d_ps.inputs = [r_table]\n",
    "            d_sts = d_ps.add_neighboring_shell(p_shell_list[arg_preds[i]])\n",
    "            if d_sts:\n",
    "                d_ps.output = d_ps.node_list[-1].ps_data\n",
    "                d_snty= d_ps.interpreter.sanity_check(d_ps)\n",
    "            else:\n",
    "                d_snty= (False,None)\n",
    "#             print(\"({}/{})#{}, {}, {}\".format(\n",
    "#                 \"✓\" if d_sts else \"x\",\n",
    "#                 \"✓\" if d_snty[0] else \"x\",\n",
    "#                 i, d_name, \",\".join(d_param)\n",
    "#             ))\n",
    "            # output to file\n",
    "            f.write(\"({}/{}/{:.4f})#{}, {}, {}\\n\".format(\n",
    "                \"✓\" if d_sts else \"x\",\n",
    "                \"✓\" if d_snty[0] else \"x\",\n",
    "                r_preds[arg_preds[i]],\n",
    "                i, d_name, \",\".join(d_param)\n",
    "            ))\n",
    "            \n",
    "        f.close()\n",
    "#         input(\"======== PAUSE ========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb6.tyrell')\n",
    "m_generator = MorpheusGenerator(m_spec, m_interpreter)\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_config = {\n",
    "    \"BLE\":{\n",
    "        \"ntrain_program\":1600,\n",
    "        \"input_size\": 15*7+1,\n",
    "        \"output_size\": len(m_ps.get_neighboring_shells()),\n",
    "        \"n_epoch\": 80,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pd = ProgramDataset(\n",
    "    p_config=m_config, \n",
    "    pn_program=m_config[\"BLE\"][\"ntrain_program\"], \n",
    "    p_generator=m_generator, \n",
    "    p_sourceps=m_ps\n",
    ")\n",
    "ld_pd = DataLoader(dataset=dt_pd, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ble = BLE(p_config=m_config)\n",
    "m_lossfn = nn.NLLLoss()\n",
    "m_optim = torch.optim.Adam(ble.parameters())\n",
    "if use_cuda:\n",
    "    ble = ble.cuda()\n",
    "    m_lossfn = m_lossfn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train Ep:0, B:99, epLoss:5.10\n",
      "# Train Ep:1, B:99, epLoss:4.55\n",
      "# Train Ep:2, B:99, epLoss:4.27\n",
      "# Train Ep:3, B:99, epLoss:4.19\n",
      "# Train Ep:4, B:99, epLoss:4.11\n",
      "# Train Ep:5, B:99, epLoss:4.07\n",
      "# Train Ep:6, B:99, epLoss:4.02\n",
      "# Train Ep:7, B:99, epLoss:4.03\n",
      "# Train Ep:8, B:99, epLoss:3.96\n",
      "# Train Ep:9, B:99, epLoss:3.95\n",
      "# Train Ep:10, B:99, epLoss:3.99\n",
      "# Train Ep:11, B:99, epLoss:3.91\n",
      "# Train Ep:12, B:99, epLoss:3.99\n",
      "# Train Ep:13, B:99, epLoss:3.87\n",
      "# Train Ep:14, B:99, epLoss:3.89\n",
      "# Train Ep:15, B:99, epLoss:3.88\n",
      "# Train Ep:16, B:99, epLoss:3.91\n",
      "# Train Ep:17, B:99, epLoss:3.91\n",
      "# Train Ep:18, B:99, epLoss:3.85\n",
      "# Train Ep:19, B:99, epLoss:3.82\n",
      "# Train Ep:20, B:99, epLoss:3.85\n",
      "# Train Ep:21, B:99, epLoss:3.84\n",
      "# Train Ep:22, B:99, epLoss:3.88\n",
      "# Train Ep:23, B:99, epLoss:3.80\n",
      "# Train Ep:24, B:99, epLoss:3.89\n",
      "# Train Ep:25, B:99, epLoss:3.75\n",
      "# Train Ep:26, B:99, epLoss:3.82\n",
      "# Train Ep:27, B:99, epLoss:3.75\n",
      "# Train Ep:28, B:99, epLoss:3.79\n",
      "# Train Ep:29, B:99, epLoss:3.85\n",
      "# Train Ep:30, B:99, epLoss:3.80\n",
      "# Train Ep:31, B:99, epLoss:3.82\n",
      "# Train Ep:32, B:99, epLoss:3.78\n",
      "# Train Ep:33, B:99, epLoss:3.83\n",
      "# Train Ep:34, B:99, epLoss:3.82\n",
      "# Train Ep:35, B:99, epLoss:3.85\n",
      "# Train Ep:36, B:99, epLoss:3.83\n",
      "# Train Ep:37, B:99, epLoss:3.77\n",
      "# Train Ep:38, B:99, epLoss:3.79\n",
      "# Train Ep:39, B:99, epLoss:3.78\n",
      "# Train Ep:40, B:99, epLoss:3.73\n",
      "# Train Ep:41, B:99, epLoss:3.82\n",
      "# Train Ep:42, B:99, epLoss:3.79\n",
      "# Train Ep:43, B:99, epLoss:3.77\n",
      "# Train Ep:44, B:99, epLoss:3.80\n",
      "# Train Ep:45, B:99, epLoss:3.82\n",
      "# Train Ep:46, B:99, epLoss:3.81\n",
      "# Train Ep:47, B:99, epLoss:3.76\n",
      "# Train Ep:48, B:99, epLoss:3.83\n",
      "# Train Ep:49, B:99, epLoss:3.74\n",
      "# Train Ep:50, B:99, epLoss:3.75\n",
      "# Train Ep:51, B:99, epLoss:3.75\n",
      "# Train Ep:52, B:99, epLoss:3.77\n",
      "# Train Ep:53, B:99, epLoss:3.72\n",
      "# Train Ep:54, B:99, epLoss:3.78\n",
      "# Train Ep:55, B:99, epLoss:3.79\n",
      "# Train Ep:56, B:99, epLoss:3.73\n",
      "# Train Ep:57, B:99, epLoss:3.69\n",
      "# Train Ep:58, B:99, epLoss:3.76\n",
      "# Train Ep:59, B:99, epLoss:3.74\n",
      "# Train Ep:60, B:99, epLoss:3.73\n",
      "# Train Ep:61, B:99, epLoss:3.75\n",
      "# Train Ep:62, B:99, epLoss:3.73\n",
      "# Train Ep:63, B:99, epLoss:3.74\n",
      "# Train Ep:64, B:99, epLoss:3.75\n",
      "# Train Ep:65, B:99, epLoss:3.74\n",
      "# Train Ep:66, B:99, epLoss:3.72\n",
      "# Train Ep:67, B:99, epLoss:3.77\n",
      "# Train Ep:68, B:99, epLoss:3.72\n",
      "# Train Ep:69, B:99, epLoss:3.73\n",
      "# Train Ep:70, B:99, epLoss:3.71\n",
      "# Train Ep:71, B:99, epLoss:3.72\n",
      "# Train Ep:72, B:99, epLoss:3.75\n",
      "# Train Ep:73, B:99, epLoss:3.73\n",
      "# Train Ep:74, B:99, epLoss:3.71\n",
      "# Train Ep:75, B:99, epLoss:3.70\n",
      "# Train Ep:76, B:99, epLoss:3.71\n",
      "# Train Ep:77, B:99, epLoss:3.73\n",
      "# Train Ep:78, B:99, epLoss:3.74\n",
      "# Train Ep:79, B:99, epLoss:3.73\n"
     ]
    }
   ],
   "source": [
    "BLETrain(m_config, ble, ld_pd, m_optim, m_lossfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLEManualTest(ble, m_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ble.state_dict(),\"./saved_models/0811CambBLE_Newton_ep80.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
