{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeqNeo\n",
    "- Stage: Cambrian\n",
    "- Version: Pomoria\n",
    "\n",
    "#### Related Commands\n",
    "- tensorboard --logdir runs\n",
    "- nohup jupyter lab > jupyter.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"use_cuda: {}\".format(use_cuda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tyrell.spec as S\n",
    "from tyrell.decider import Example\n",
    "\n",
    "# Morpheus Version\n",
    "from MorpheusInterpreter import *\n",
    "from ProgramSpace import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqNeo(nn.Module):\n",
    "    def __init__(self, p_config=None):\n",
    "        super(SeqNeo, self).__init__()\n",
    "        self.config = p_config\n",
    "        \n",
    "        self.fn_embedding = nn.Embedding(\n",
    "            self.config[\"fn_vocab_size\"],\n",
    "            self.config[\"fn_dim\"],\n",
    "            padding_idx=0,\n",
    "        )\n",
    "        \n",
    "        self.encoder1 = nn.Linear(\n",
    "            self.config[\"encoder\"][\"input_dim\"],\n",
    "            2048,\n",
    "        )\n",
    "        self.encoder2 = nn.Linear(\n",
    "            2048,\n",
    "            self.config[\"encoder\"][\"output_dim\"],\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.GRUCell(\n",
    "            self.config[\"decoder\"][\"input_dim\"],\n",
    "            self.config[\"decoder\"][\"hidden_dim\"],\n",
    "            bias=True,\n",
    "        )\n",
    "        self.classifier = nn.Linear(\n",
    "            self.config[\"decoder\"][\"hidden_dim\"],\n",
    "            self.config[\"decoder\"][\"output_dim\"],\n",
    "        )\n",
    "        \n",
    "    def decode(self, pin_exp, pout_exp, p_hidden, pfn_context):\n",
    "        tmp_exp = self.encode(pin_exp, pout_exp) # (B=1, encoder_output_dim)\n",
    "        tmp_fn = self.fn_embedding(pfn_context) # (B=1, fn_dim)\n",
    "        tmp_input = torch.cat([tmp_exp,tmp_fn],dim=1)\n",
    "        \n",
    "        if p_hidden is None:\n",
    "            # very first\n",
    "            tmp_hidden = self.decoder(tmp_input)\n",
    "        else:\n",
    "            # not the very first\n",
    "            tmp_hidden = self.decoder(tmp_input, p_hidden)\n",
    "        # (B=1, decoder_hidden_dim)\n",
    "        \n",
    "        tmp_output = torch.log_softmax(\n",
    "            self.classifier(tmp_hidden),\n",
    "            dim=1\n",
    "        ) # (B=1, decoder_output_dim)\n",
    "        \n",
    "        # first hidden, then output\n",
    "        return (tmp_hidden, tmp_output)\n",
    "        \n",
    "        \n",
    "    def encode(self, pin_exp, pout_exp):\n",
    "        # pin_exp/pout_exp: (B=1, abs_dim)\n",
    "        tmp_exp = torch.cat([pin_exp,pout_exp],dim=1) # (B=1, encoder_input_dim=abs_dim*2)\n",
    "        tmp_out1 = F.relu(self.encoder1(tmp_exp))\n",
    "        tmp_out2 = F.relu(self.encoder2(tmp_out1))\n",
    "        return tmp_out2 # (B=1, encoder_output_dim)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace certain node id with certain value\n",
    "def modify_shell(p_shell, p_id_from, p_id_to):\n",
    "    d_prod = p_shell[0]\n",
    "    d_rhs = p_shell[1]\n",
    "    ld_rhs = [p_id_to if d_rhs[i]==p_id_from else d_rhs[i]\n",
    "             for i in range(len(d_rhs))]\n",
    "    return (d_prod, tuple(ld_rhs))\n",
    "\n",
    "def SeqTrain(p_config, p_sourceps, p_model, p_dataset, p_optim):\n",
    "    print(\"# Start SeqTrain...\")\n",
    "    \n",
    "    for d_epoch in range(p_config[\"train\"][\"n_epoch\"]):\n",
    "        epoch_loss_list = []\n",
    "        for d_episode in range(p_config[\"train\"][\"n_episode\"]):\n",
    "            print(\"\\r# EP:{}/{}, loss:{:.2f}\".format(\n",
    "                d_epoch, d_episode,\n",
    "                sum(epoch_loss_list)/len(epoch_loss_list) if len(epoch_loss_list)>0 else -1,\n",
    "            ),end=\"\")\n",
    "            p_model.train()\n",
    "            \n",
    "            if isinstance(p_dataset,list):\n",
    "                # ====== option 1: sample from dataset ====== #\n",
    "                eid = random.choice(range(len(p_dataset)))\n",
    "                data_prog, data_str_example = p_dataset[eid]\n",
    "                data_example = Example(\n",
    "                    input=[p_sourceps.interpreter.load_data_into_var(p) for p in data_str_example.input],\n",
    "                    output=p_sourceps.interpreter.load_data_into_var(data_str_example.output),\n",
    "                )\n",
    "                ps_solution = ProgramSpace(\n",
    "                    p_sourceps.spec, p_sourceps.interpreter, data_example.input, data_example.output,\n",
    "                )\n",
    "                ps_solution.init_by_prog(data_prog)\n",
    "            else:\n",
    "                # ====== option 2: sample from generator ====== #\n",
    "                ps_solution = p_dataset.get_new_chain_program(\n",
    "                    p_config[\"train\"][\"n_size\"] + 1 # depth=size+1\n",
    "                )\n",
    "\n",
    "            # solution self-check\n",
    "            if ps_solution.check_eq() is None:\n",
    "                continue\n",
    "                print(\"ERROR, SOLUTION NOT CONSISTENT!\")\n",
    "\n",
    "            selected_neurons = []\n",
    "\n",
    "            # initialize a new Program Space\n",
    "            ps_current = ProgramSpace(\n",
    "                p_spec, p_interpreter, ps_solution.inputs, ps_solution.output,\n",
    "            )\n",
    "            # then initialize a shell template\n",
    "            tmp_shell_list = ps_current.get_neighboring_shells()\n",
    "            tmp_node_to_replace = ps_current.node_dict[\"ParamNode\"][0] # for chain only\n",
    "            # replace the Param Node id in shells with -1 to make them templates\n",
    "            template_list = [\n",
    "                modify_shell(tmp_shell_list[i],tmp_node_to_replace,-1)\n",
    "                for i in range(len(tmp_shell_list))\n",
    "            ]\n",
    "\n",
    "            hidden_current = None # hidden state, initialized to None\n",
    "            if use_cuda:\n",
    "                fn_context = Variable(torch.tensor([0],dtype=torch.long)).cuda()\n",
    "            else:\n",
    "                fn_context = Variable(torch.tensor([0],dtype=torch.long))\n",
    "                \n",
    "            for d_step in range(len(ps_solution.shells)):\n",
    "\n",
    "                # ### assume chain execution, so only 1 possible returns\n",
    "                # ### at d_step=0, this should be input[0]\n",
    "                id_current = ps_current.get_strict_frontiers()[0]\n",
    "                var_current = ps_current.node_list[id_current].ps_data # need the real var name in r env\n",
    "                var_output = ps_current.output\n",
    "\n",
    "                map_current = p_interpreter.camb_get_ventogyrus(var_current)\n",
    "                map_output = p_interpreter.camb_get_ventogyrus(var_output)\n",
    "\n",
    "                # make current shell list\n",
    "                current_shell_list = [\n",
    "                    modify_shell(template_list[i],-1,id_current)\n",
    "                    for i in range(len(template_list))\n",
    "                ]\n",
    "                current_shell_list = [None] + current_shell_list # None for <SOS> in nn embedding\n",
    "\n",
    "                # wrap in B=1\n",
    "                if use_cuda:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float)).cuda()\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float)).cuda()\n",
    "                else:\n",
    "                    td_current = Variable(torch.tensor([map_current],dtype=torch.float))\n",
    "                    td_output = Variable(torch.tensor([map_output],dtype=torch.float))\n",
    "\n",
    "                # (B=1, fn_vocab_size)\n",
    "                hidden_current, td_pred = p_model.decode(td_current, td_output, hidden_current, fn_context)\n",
    "                # supervised, assign selection directly\n",
    "                tmp_id = current_shell_list.index(ps_solution.shells[d_step])\n",
    "\n",
    "                # update ps_current\n",
    "                update_status = ps_current.add_neighboring_shell(\n",
    "                    current_shell_list[tmp_id]\n",
    "                )\n",
    "                \n",
    "                if not update_status:\n",
    "                    # something wrong\n",
    "                    raise Exception(\"Can't even update PS under supervision?\")\n",
    "                \n",
    "                selected_neurons.append(td_pred[0,tmp_id])\n",
    "\n",
    "            # <END_FOR_STEP>\n",
    "            if ps_current.check_eq() is None:\n",
    "                # something wrong, should've been solved under supervision\n",
    "                raise Exception(\"Can't even solve under supervision?\")\n",
    "\n",
    "            episode_loss_list = []\n",
    "            for i in range(len(selected_neurons)):\n",
    "                episode_loss_list.append(\n",
    "                    (+1.0)*(-selected_neurons[i])\n",
    "                )\n",
    "            episode_loss = sum(episode_loss_list)\n",
    "            epoch_loss_list.append(episode_loss)\n",
    "            p_optim.zero_grad()\n",
    "            episode_loss.backward()\n",
    "            p_optim.step()\n",
    "\n",
    "                \n",
    "        # <END_FOR_EPISODE>  \n",
    "        print()\n",
    "            \n",
    "    # <END_FOR_EPOCH>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interpreter = MorpheusInterpreter()\n",
    "m_spec = S.parse_file('./example/camb6.tyrell')\n",
    "m_generator = MorpheusGenerator(\n",
    "    spec=m_spec,\n",
    "    interpreter=m_interpreter,\n",
    ")\n",
    "# dumb variable to help infer the shells\n",
    "m_ps = ProgramSpace(\n",
    "    m_spec, m_interpreter, [None], None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_config = {\n",
    "    \"abs_dim\": 15*7+1,\n",
    "    \"fn_dim\": 128,\n",
    "    \"fn_vocab_size\": len(m_ps.get_neighboring_shells())+1, # with one more <SOS>\n",
    "    \"encoder\":{\n",
    "        \"input_dim\": None,\n",
    "        \"output_dim\": 1024, # hidden state\n",
    "    },\n",
    "    \"decoder\":{\n",
    "        \"input_dim\": None,\n",
    "        \"hidden_dim\": None,\n",
    "        \"output_dim\": None,\n",
    "    },\n",
    "    \"train\":{\n",
    "        \"n_epoch\":100, # #epoches in total\n",
    "        \"n_episode\": 50, # #problems per epoch\n",
    "        \"n_size\": 3,\n",
    "    },\n",
    "}\n",
    "m_config[\"encoder\"][\"input_dim\"] = m_config[\"abs_dim\"]*2\n",
    "m_config[\"decoder\"][\"input_dim\"] = \\\n",
    "    m_config[\"encoder\"][\"output_dim\"] + \\\n",
    "    m_config[\"fn_dim\"]\n",
    "m_config[\"decoder\"][\"hidden_dim\"] = m_config[\"encoder\"][\"output_dim\"]\n",
    "m_config[\"decoder\"][\"output_dim\"] = m_config[\"fn_vocab_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_neo = SeqNeo(p_config=m_config)\n",
    "if use_cuda:\n",
    "    seq_neo = seq_neo.cuda()\n",
    "optimizer = torch.optim.Adam(list(seq_neo.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeqTrain(m_config, m_ps, seq_neo, m_generator, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
